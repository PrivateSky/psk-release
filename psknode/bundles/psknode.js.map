{"version":3,"sources":["node_modules/browser-pack/_prelude.js","builds/tmp/psknode_intermediar.js","modules/adler32/lib/Hash.js","modules/adler32/lib/algorithm.js","modules/adler32/lib/register.js","modules/bar/lib/Archive.js","modules/bar/lib/ArchiveConfigurator.js","modules/bar/lib/Brick.js","modules/bar/lib/FileBarMap.js","modules/bar/lib/FileBrickStorage.js","modules/bar/lib/FolderBarMap.js","modules/bar/lib/FolderBrickStorage.js","modules/bar/lib/Seed.js","modules/bar/lib/transforms/BrickTransform.js","modules/bar/lib/transforms/BrickTransformFactory.js","modules/bar/lib/transforms/CompressionEncryptionGenerator.js","modules/bar/lib/transforms/CompressionGenerator.js","modules/bar/lib/transforms/EncryptionGenerator.js","modules/bar/utils/AsyncDispatcher.js","modules/bar/utils/isStream.js","modules/bar/utils/utilities.js","modules/blockchain/OBFT/OBFTImplementation.js","modules/blockchain/OBFT/PulseUtil.js","modules/blockchain/OBFT/transactionsUtil.js","modules/blockchain/blockchainSwarmTypes/asset_swarm_template.js","modules/blockchain/blockchainSwarmTypes/transaction_swarm_template.js","modules/blockchain/defaultConstitution/assets/ACLScope.js","modules/blockchain/defaultConstitution/assets/Agent.js","modules/blockchain/defaultConstitution/assets/Backup.js","modules/blockchain/defaultConstitution/assets/BarAnchor.js","modules/blockchain/defaultConstitution/assets/CSBMeta.js","modules/blockchain/defaultConstitution/assets/DomainReference.js","modules/blockchain/defaultConstitution/assets/FileAnchor.js","modules/blockchain/defaultConstitution/assets/Key.js","modules/blockchain/defaultConstitution/assets/index.js","modules/blockchain/defaultConstitution/transactions/agentTransaction.js","modules/blockchain/defaultConstitution/transactions/domainTransaction.js","modules/blockchain/defaultConstitution/transactions/index.js","modules/blockchain/defaultConstitution/transactions/sharedPhases.js","modules/blockchain/defaultConstitution/transactions/standardCSBTransactions.js","modules/blockchain/defaultConstitution/transactions/transactions.js","modules/blockchain/moduleConstants.js","modules/blockchain/pskdb/Blockchain.js","modules/blockchain/pskdb/index.js","modules/blockchain/pskdb/pskdb.js","modules/blockchain/pskdb/securityParadigms/localExecutionCache.js","modules/blockchain/pskdb/securityParadigms/securityParadigmRegistry.js","modules/blockchain/signsensus/SignSensusImplementation.js","modules/blockchain/strategies/consensusAlgortims/consensusAlgoritmsRegistry.js","modules/blockchain/strategies/historyStorages/BarHistoryStorage.js","modules/blockchain/strategies/historyStorages/FsHistoryStorage.js","modules/blockchain/strategies/historyStorages/LatestHashTracker.js","modules/blockchain/strategies/historyStorages/MemoryHistoryStorage.js","modules/blockchain/strategies/historyStorages/historyStoragesRegistry.js","modules/blockchain/strategies/networkCommunication/networkCommunicationStrategiesRegistry.js","modules/blockchain/strategies/signatureProvidersRegistry/signatureProvidersRegistry.js","modules/blockchain/strategies/votingStrategies/votingStrategiesRegistry.js","modules/blockchain/strategies/worldStateCaches/worldStateCacheRegistry.js","modules/csb/lib/RawCSB.js","modules/edfs-brick-storage/EDFSBrickQueue.js","modules/edfs-brick-storage/EDFSBrickStorage.js","modules/edfs/flows/BricksManager.js","modules/edfs/lib/EDFSClient.js","modules/edfs/lib/EDFSMiddleware.js","modules/foldermq/lib/folderMQ.js","modules/interact/lib/interactionSpaceImpl/SoundPubSubMQBasedInteractionSpace.js","modules/interact/lib/interactionSpaceImpl/WebViewMQInteractionSpace.js","modules/interact/lib/interactionSpaceImpl/WindowMQInteractionSpace.js","modules/interact/lib/interactionSpaceImpl/folderMQBasedInteractionSpace.js","modules/interact/lib/interactionSpaceImpl/httpInteractionSpace.js","modules/interact/lib/interactionSpaceImpl/specificMQImpl/ChildWebViewMQ.js","modules/interact/lib/interactionSpaceImpl/specificMQImpl/ChildWndMQ.js","modules/interact/lib/swarmInteraction.js","modules/node-fd-slicer/modules/node-pend/index.js","modules/psk-http-client/lib/psk-abstract-client.js","modules/psk-http-client/lib/psk-browser-client.js","modules/psk-http-client/lib/psk-node-client.js","modules/pskwallet/libraries/BackupEngine.js","modules/pskwallet/libraries/CSBCache.js","modules/pskwallet/libraries/CSBIdentifier.js","modules/pskwallet/libraries/RawCSB.js","modules/pskwallet/libraries/RootCSB.js","modules/pskwallet/libraries/backupResolvers/EVFSResolver.js","modules/pskwallet/libraries/flows/addBackup.js","modules/pskwallet/libraries/flows/addCsb.js","modules/pskwallet/libraries/flows/attachFile.js","modules/pskwallet/libraries/flows/createCsb.js","modules/pskwallet/libraries/flows/extractFile.js","modules/pskwallet/libraries/flows/index.js","modules/pskwallet/libraries/flows/listCSBs.js","modules/pskwallet/libraries/flows/receive.js","modules/pskwallet/libraries/flows/resetPin.js","modules/pskwallet/libraries/flows/restore.js","modules/pskwallet/libraries/flows/saveBackup.js","modules/pskwallet/libraries/flows/setPin.js","modules/pskwallet/utils/AsyncDispatcher.js","modules/pskwallet/utils/DseedCage.js","modules/pskwallet/utils/HashCage.js","modules/pskwallet/utils/flowsUtils.js","modules/pskwallet/utils/utils.js","modules/pskwallet/utils/validator.js","node_modules/source-map/lib/array-set.js","node_modules/source-map/lib/base64-vlq.js","node_modules/source-map/lib/base64.js","node_modules/source-map/lib/binary-search.js","node_modules/source-map/lib/mapping-list.js","node_modules/source-map/lib/quick-sort.js","node_modules/source-map/lib/source-map-consumer.js","node_modules/source-map/lib/source-map-generator.js","node_modules/source-map/lib/source-node.js","node_modules/source-map/lib/util.js","modules/adler32/index.js","modules/bar/index.js","modules/blockchain/index.js","modules/buffer-crc32/index.js","node_modules/buffer-from/index.js","modules/csb/index.js","modules/edfs-brick-storage/index.js","modules/edfs/index.js","modules/foldermq/index.js","modules/interact/index.js","modules/node-fd-slicer/index.js","modules/psk-http-client/index.js","modules/pskwallet/index.js","node_modules/source-map-support/source-map-support.js","node_modules/source-map/source-map.js","modules/yauzl/index.js","modules/yazl/index.js","modules/zmq_adapter/index.js"],"names":[],"mappings":"AAAA;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACj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pBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACtIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC5HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpFA;AACA;AACA;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7cA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5eA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC5FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC9GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC3bA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACnHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AClLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AChPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1jCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;;ACNA;AACA;AACA;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;;ACNA;AACA;AACA;AACA;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACxSA;AACA;AACA;AACA;AACA;AACA;AACA;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvj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zyBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC5oBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"generated.js","sourceRoot":"../..","sourcesContent":["(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c=\"function\"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error(\"Cannot find module '\"+i+\"'\");throw a.code=\"MODULE_NOT_FOUND\",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u=\"function\"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()","global.psknodeLoadModules = function(){ \n\t$$.__runtimeModules[\"source-map-support\"] = require(\"source-map-support\");\n\t$$.__runtimeModules[\"source-map\"] = require(\"source-map\");\n\t$$.__runtimeModules[\"buffer-from\"] = require(\"buffer-from\");\n\t$$.__runtimeModules[\"yazl\"] = require(\"yazl\");\n\t$$.__runtimeModules[\"yauzl\"] = require(\"yauzl\");\n\t$$.__runtimeModules[\"pskwallet\"] = require(\"pskwallet\");\n\t$$.__runtimeModules[\"foldermq\"] = require(\"foldermq\");\n\t$$.__runtimeModules[\"buffer-crc32\"] = require(\"buffer-crc32\");\n\t$$.__runtimeModules[\"node-fd-slicer\"] = require(\"node-fd-slicer\");\n\t$$.__runtimeModules[\"interact\"] = require(\"interact\");\n\t$$.__runtimeModules[\"psk-http-client\"] = require(\"psk-http-client\");\n\t$$.__runtimeModules[\"edfs\"] = require(\"edfs\");\n\t$$.__runtimeModules[\"adler32\"] = require(\"adler32\");\n\t$$.__runtimeModules[\"bar\"] = require(\"bar\");\n\t$$.__runtimeModules[\"csb\"] = require(\"csb\");\n\t$$.__runtimeModules[\"edfs-brick-storage\"] = require(\"edfs-brick-storage\");\n\t$$.__runtimeModules[\"blockchain\"] = require(\"blockchain\");\n\t$$.__runtimeModules[\"zmq_adapter\"] = require(\"zmq_adapter\");\n}\nif (false) {\n\tpsknodeLoadModules();\n}; \nglobal.psknodeRequire = require;\nif (typeof $$ !== \"undefined\") {            \n    $$.requireBundle(\"psknode\");\n    };\n    require('source-map-support').install({});\n    ","\"use strict\";\n\nvar util = require('util');\nvar Transform = require('stream').Transform;\nvar crypto = require('crypto');\nvar algorithm = require('./algorithm');\n\n// Provides a node.js Hash style interface for _sum32: http://nodejs.org/api/crypto.html#crypto_class_hash\nvar Hash = module.exports = function Hash(options)\n{\n\tif (!(this instanceof Hash))\n\t\treturn new Hash(options);\n\n\tTransform.call(this, options);\n\n\tthis._sum = 1;\n};\n\nutil.inherits(Hash, Transform);\n\nHash.prototype.update = function(data, encoding)\n{\n\tif (this._done)\n\t\tthrow new TypeError('HashUpdate fail');\n\n\tencoding = encoding || crypto.DEFAULT_ENCODING;\n\n\tif (!(data instanceof Buffer)) {\n\t\tdata = new Buffer(''+data, encoding === 'buffer' ? 'binary' : encoding);\n\t}\n\n\tthis._sum = algorithm.sum(data, this._sum);\n\n\treturn this;\n};\n\nHash.prototype.digest = function(encoding)\n{\n\tif (this._done)\n\t\tthrow new Error('Not initialized');\n\t\n\tthis._done = true;\n\n\tvar buf = new Buffer(4);\n\tbuf.writeUInt32BE(this._sum, 0);\n\n\tencoding = encoding || crypto.DEFAULT_ENCODING;\n\n\tif (encoding === 'buffer')\n\t\treturn buf;\n\telse\n\t\treturn buf.toString(encoding);\n};\n\nHash.prototype._transform = function(chunk, encoding, callback)\n{\n\tthis.update(chunk, encoding);\n\tcallback();\n};\n\nHash.prototype._flush = function(callback)\n{\n\tvar encoding = this._readableState.encoding || 'buffer';\n\tthis.push(this.digest(encoding), encoding);\n\tcallback();\n};","\"use strict\";\n\n/**\n * Largest prime smaller than 2^16 (65536)\n */\nvar BASE = 65521;\n\n/**\n * Largest value n such that 255n(n+1)/2 + (n+1)(BASE-1) <= 2^32-1\n *\n * NMAX is just how often modulo needs to be taken of the two checksum word halves to prevent overflowing a 32 bit\n * integer. This is an optimization. We \"could\" take the modulo after each byte, and it must be taken before each\n * digest.\n */\nvar NMAX = 5552;\n\nexports.sum = function(buf, sum)\n{\n\tif (sum == null)\n\t\tsum = 1;\n\n\tvar a = sum & 0xFFFF,\n\t\tb = (sum >>> 16) & 0xFFFF,\n\t\ti = 0,\n\t\tmax = buf.length,\n\t\tn, value;\n\n\twhile (i < max)\n\t{\n\t\tn = Math.min(NMAX, max - i);\n\n\t\tdo\n\t\t{\n\t\t\ta += buf[i++]<<0;\n\t\t\tb += a;\n\t\t}\n\t\twhile (--n);\n\n\t\ta %= BASE;\n\t\tb %= BASE;\n\t}\n\n\treturn ((b << 16) | a) >>> 0;\n};\n\nexports.roll = function(sum, length, oldByte, newByte)\n{\n\tvar a = sum & 0xFFFF,\n\t\tb = (sum >>> 16) & 0xFFFF;\n\n\tif (newByte != null)\n\t{\n\t\ta = (a - oldByte + newByte + BASE) % BASE;\n\t\tb = (b - ((length * oldByte) % BASE) + a - 1 + BASE) % BASE;\n\t}\n\telse\n\t{\n\t\ta = (a - oldByte + BASE) % BASE;\n\t\tb = (b - ((length * oldByte) % BASE) - 1 + BASE) % BASE;\n\t}\n\n\treturn ((b << 16) | a) >>> 0;\n};","\"use strict\";\n\nmodule.exports = function()\n{\n\tvar crypto = require('crypto');\n\tvar Hash = require('./Hash');\n\n\t// Silently abort if the adler32 algorithm is already supported by the\n\t// crypto module.\n\tif (crypto.getHashes().indexOf('adler32') != -1)\n\t\treturn;\n\n\tcrypto.getHashes = function()\n\t{\n\t\treturn this().concat(['adler32']);\n\t}\n\t.bind(crypto.getHashes.bind(crypto));\n\n\tcrypto.createHash = function(algorithm)\n\t{\n\t\tif (algorithm === 'adler32')\n\t\t\treturn new Hash();\n\t\telse\n\t\t\treturn this(algorithm);\n\t}\n\t.bind(crypto.createHash.bind(this));\n};","const Brick = require('./Brick');\nconst path = require(\"path\");\nconst isStream = require(\"../utils/isStream\");\nconst AsyncDispatcher = require(\"../utils/AsyncDispatcher\");\nconst crypto = require('pskcrypto');\nconst adler32 = require('adler32');\n\nfunction Archive(archiveConfigurator) {\n\n    const archiveFsAdapter = archiveConfigurator.getFsAdapter();\n    const storageProvider = archiveConfigurator.getStorageProvider();\n    let barMap;\n\n    this.setSeed = (seed) => {\n        archiveConfigurator.setSeed(seed);\n    };\n\n    this.getSeed = () => {\n        return archiveConfigurator.getSeed();\n    };\n\n    this.update = (fsPath, callback) => {\n        let blocksPositions = {};\n        let checksSumMap = barMap.getDictionaryObject();\n        let fileNameHashes = __setFromHashList();\n        let fileState = {};\n        loadBarMapThenExecute(__update, callback);\n\n        /**\n         * in this function, i do a directory traversal and process every file that i find, looking for blocks that already exists in our archive\n         * @private\n         */\n\n        function __setFromHashList() {\n            let folderHashList = {};\n            barMap.getFileList().forEach((file) => {\n                folderHashList[file.slice(file.indexOf('/'))] = new Set(barMap.getHashList(file));\n            });\n            return folderHashList;\n        }\n\n        function __readDirectoryRecursively(folderPath, sign, callback) {\n            archiveFsAdapter.getNextFile(folderPath, sign, __readFileChk);\n\n            function __readFileChk(err, file) {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (typeof file === 'undefined') {\n                    return callback(undefined, blocksPositions, fileNameHashes);\n                }\n\n                const goodPath = path.posix.normalize(path.join(path.dirname(folderPath), file).split(path.sep).join(path.posix.sep));\n                archiveFsAdapter.getFileSize(goodPath, (err, size) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    __readBlock(goodPath, goodPath.slice(goodPath.indexOf('/')), size, 0, archiveConfigurator.getBufferSize(), undefined, undefined, barMap.isInHeader(goodPath), (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n                        __readDirectoryRecursively(folderPath, false, callback);\n                    });\n                });\n\n            }\n\n            function __readBlock(file, cutFile, fileSize, index, blockSize, currentBlockCheckSum, firstByte, alreadyInBarMap, callback) {\n                if (index >= fileSize) {\n                    if (blocksPositions[file] === undefined) {\n                        blocksPositions[file] = [];\n                    }\n                    blocksPositions[file].push({start: fileSize, end: fileSize});\n                    return callback();\n                }\n                archiveFsAdapter.readBlockFromFile(file, index, index + blockSize - 1, (err, data) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    if (currentBlockCheckSum === undefined) {\n                        currentBlockCheckSum = adler32.sum(data);\n                    } else {\n                        currentBlockCheckSum = adler32.roll(currentBlockCheckSum, blockSize, firstByte, data[blockSize - 1]);\n                    }\n                    let matchFound = false;\n                    if (checksSumMap[currentBlockCheckSum] !== undefined) {\n                        let hardDigest = crypto.pskHash(data).toString('hex');\n                        for (let k = 0; k < checksSumMap[currentBlockCheckSum].length; k++) {\n                            if (checksSumMap[currentBlockCheckSum][k] === hardDigest) {\n                                if (blocksPositions[file] === undefined) {\n                                    blocksPositions[file] = [];\n                                }\n                                blocksPositions[file].push({start: index, end: index + blockSize});\n                                // if(alreadyInBarMap === false){\n                                //     let tempBrick = new Brick();\n                                //     tempBrick.setTransformedData(data);\n                                // }\n                                fileState[file] = alreadyInBarMap;\n                                if (typeof fileNameHashes[cutFile] !== 'undefined') {\n                                    fileNameHashes[cutFile].delete(hardDigest);\n                                }\n                                matchFound = true;\n                                break;\n                            }\n                        }\n                    }\n                    if (matchFound === false) {\n                        __readBlock(file, cutFile, fileSize, index + 1, blockSize, currentBlockCheckSum, data[0], alreadyInBarMap, callback);\n                    } else {\n                        __readBlock(file, cutFile, fileSize, index + blockSize, blockSize, undefined, undefined, alreadyInBarMap, callback);\n                    }\n                });\n            }\n\n        }\n\n        function iterateThroughOffsets(fileName, goodPath, precedence, iteratorIndex, filePositions, callback) {\n            if (iteratorIndex >= filePositions.length) {\n                return callback();\n            }\n            let positionObj = filePositions[iteratorIndex];\n            if (positionObj === undefined) {\n                return callback();\n            }\n            if (positionObj.start > precedence) {\n                archiveFsAdapter.readBlockFromFile(goodPath, precedence, positionObj.end - 1, (err, blockData) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    let bufferSize = archiveConfigurator.getBufferSize();\n                    for (let index = 0; index < blockData.length; index += bufferSize) {\n                        let brick = new Brick();\n                        brick.setTransformedData(blockData.slice(index, index + bufferSize));\n                        barMap.add(fileName, brick);\n                        storageProvider.putBrick(brick, (err) => {\n                            if (err) {\n                                return callback(err);\n                            }\n                            if (index + bufferSize >= blockData.length) {\n                                iterateThroughOffsets(fileName, goodPath, positionObj.end, iteratorIndex + 1, filePositions, callback);\n                            }\n                        });\n                    }\n                });\n            } else {\n                if (fileState[goodPath] === false) {\n                    archiveFsAdapter.readBlockFromFile(goodPath, positionObj.start, positionObj.end - 1, (err, blockData) => {\n                        if (err) {\n                            return callback(err);\n                        }\n                        let brick = new Brick();\n                        brick.setTransformedData(blockData);\n                        barMap.add(fileName, brick);\n                        iterateThroughOffsets(fileName, goodPath, positionObj.end, iteratorIndex + 1, filePositions, callback);\n                    });\n                } else {\n                    iterateThroughOffsets(fileName, goodPath, positionObj.end, iteratorIndex + 1, filePositions, callback);\n                }\n            }\n        }\n\n        function __addBricks(positions, callback) {\n            let precedence;\n            const asyncDispatcher = new AsyncDispatcher((errs, results) => {\n                return callback();\n            });\n            asyncDispatcher.dispatchEmpty(Object.keys(positions).length);\n            Object.keys(positions).forEach((fileName) => {\n                precedence = 0;\n                let goodPath = path.posix.normalize(fileName.split(path.sep).join(path.posix.sep));\n\n                iterateThroughOffsets(fileName, goodPath, precedence, 0, positions[fileName], (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    asyncDispatcher.markOneAsFinished(undefined, fileName);\n                });\n            });\n        }\n\n        function __deleteBricks(deletions) {\n            //de adaugat, barMap.removeBrick(filePath,brickHash);\n            Object.keys(deletions).forEach((fileName) => {\n                deletions[fileName].forEach((brickHash) => {\n                    barMap.removeBrick(fileName, brickHash);\n                });\n            });\n        }\n\n        function __update() {\n            __readDirectoryRecursively(fsPath, true, (err, positions, deletions) => {\n                if (err) {\n                    return callback(err);\n                }\n                __addBricks(positions, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    __deleteBricks(deletions);\n                    storageProvider.putBarMap(barMap, callback);\n                });\n            });\n        }\n    };\n\n    this.writeFile = (filePath, data, callback) => {\n        loadBarMapThenExecute(__addData, callback);\n\n        function __addData() {\n            const brick = new Brick(archiveConfigurator);\n            if (typeof data === \"string\") {\n                data = Buffer.from(data);\n            }\n\n            if (!Buffer.isBuffer(data)) {\n                return callback(Error(`Type of data is ${typeof data}. Expected Buffer.`));\n            }\n\n            brick.setRawData(data);\n            barMap.add(filePath, brick);\n            storageProvider.putBrick(brick, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                storageProvider.putBarMap(barMap, (err, digest) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    callback(undefined, digest);\n                });\n            });\n        }\n    };\n\n    this.readFile = (barPath, callback) => {\n        loadBarMapThenExecute(__readFile, callback);\n\n        function __readFile() {\n            let fileData = Buffer.alloc(0);\n            let brickIds;\n            try {\n                brickIds = barMap.getHashList(barPath);\n            } catch (err) {\n                return callback(err);\n            }\n\n            getFileRecursively(0, callback);\n\n            function getFileRecursively(brickIndex, callback) {\n                const brickId = brickIds[brickIndex];\n                storageProvider.getBrick(brickId, (err, brick) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    brick.setConfig(archiveConfigurator);\n                    brick.setTransformParameters(barMap.getTransformParameters(brickId));\n                    fileData = Buffer.concat([fileData, brick.getRawData()]);\n                    ++brickIndex;\n\n                    if (brickIndex < brickIds.length) {\n                        getFileRecursively(brickIndex, callback);\n                    } else {\n                        callback(undefined, fileData);\n                    }\n                });\n            }\n        }\n    };\n\n    this.addFile = (fsFilePath, barPath, callback) => {\n        if (typeof barPath === \"function\") {\n            callback = barPath;\n            barPath = fsFilePath;\n        }\n        loadBarMapThenExecute(__addFile, callback);\n\n        function __addFile() {\n            readFileAsBlocks(fsFilePath, barPath, archiveConfigurator.getBufferSize(), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                barMap.setConfig(archiveConfigurator);\n                if (archiveConfigurator.getMapEncryptionKey()) {\n                    barMap.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n                }\n\n                storageProvider.putBarMap(barMap, callback);\n            });\n        }\n    };\n\n    this.extractFile = (fsFilePath, barPath, callback) => {\n        if (typeof barPath === \"function\") {\n            callback = barPath;\n            barPath = fsFilePath;\n        }\n\n        loadBarMapThenExecute(__extractFile, callback);\n\n        function __extractFile() {\n            const brickIds = barMap.getHashList(barPath);\n            getFileRecursively(0, callback);\n\n            function getFileRecursively(brickIndex, callback) {\n                const brickId = brickIds[brickIndex];\n                storageProvider.getBrick(brickId, (err, brick) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    brick.setConfig(archiveConfigurator);\n                    brick.setTransformParameters(barMap.getTransformParameters(brickId));\n                    archiveFsAdapter.appendBlockToFile(fsFilePath, brick.getRawData(), (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        ++brickIndex;\n                        if (brickIndex < brickIds.length) {\n                            getFileRecursively(brickIndex, callback);\n                        } else {\n                            callback();\n                        }\n                    });\n                });\n            }\n        }\n    };\n\n    this.appendToFile = (filePath, data, callback) => {\n\n        loadBarMapThenExecute(__appendToFile, callback);\n\n        function __appendToFile() {\n            filePath = path.normalize(filePath);\n\n            if (typeof data === \"string\") {\n                data = Buffer.from(data);\n            }\n            if (Buffer.isBuffer(data)) {\n                const dataBrick = new Brick(data);\n                storageProvider.putBrick(dataBrick, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    barMap.add(filePath, dataBrick);\n                    putBarMap(callback);\n                });\n                return;\n            }\n\n            if (isStream.isReadable(data)) {\n                data.on('error', (err) => {\n                    return callback(err);\n                }).on('data', (chunk) => {\n                    const dataBrick = new Brick(chunk);\n                    barMap.add(filePath, dataBrick);\n                    storageProvider.putBrick(dataBrick, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n                    });\n                }).on(\"end\", () => {\n                    putBarMap(callback);\n                });\n                return;\n            }\n            callback(new Error(\"Invalid type of parameter data\"));\n        }\n    };\n\n\n    this.replaceFile = (fileName, stream, callback) => {\n        if (typeof stream !== 'object') {\n            return callback(new Error('Wrong stream!'));\n        }\n\n        loadBarMapThenExecute(__replaceFile, callback);\n\n        function __replaceFile() {\n            fileName = path.normalize(fileName);\n            stream.on('error', () => {\n                return callback(new Error(\"File does not exist!\"));\n            }).on('open', () => {\n                storageProvider.deleteFile(fileName, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    barMap.emptyList(fileName);\n                });\n            }).on('data', (chunk) => {\n                let tempBrick = new Brick(chunk);\n                barMap.add(fileName, tempBrick);\n                storageProvider.putBrick(tempBrick, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    putBarMap(callback);\n                });\n            });\n        }\n    };\n\n    this.deleteFile = (filePath, callback) => {\n        loadBarMapThenExecute(() => {\n            storageProvider.deleteFile(filePath, callback);\n        }, callback);\n    };\n\n    this.addFolder = (fsFolderPath, barPath, callback) => {\n        if (typeof barPath === \"function\") {\n            callback = barPath;\n            barPath = fsFolderPath;\n        }\n\n        loadBarMapThenExecute(__addFolder, callback);\n\n        function __addFolder() {\n\n            archiveFsAdapter.getNextFile(fsFolderPath, readFileCb);\n\n            function readFileCb(err, file) {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (typeof file !== \"undefined\") {\n\n                    readFileAsBlocks(path.join(path.dirname(fsFolderPath), file), path.join(path.dirname(barPath), file), archiveConfigurator.getBufferSize(), (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        archiveFsAdapter.getNextFile(fsFolderPath, readFileCb);\n                    });\n                } else {\n                    storageProvider.putBarMap(barMap, (err, mapDigest) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        archiveConfigurator.setMapDigest(mapDigest);\n                        callback(undefined, mapDigest);\n                    });\n                }\n            }\n        }\n    };\n    this.extractFolder = (fsFolderPath, barPath, callback) => {\n        if (typeof fsFolderPath === \"function\") {\n            callback = fsFolderPath;\n            fsFolderPath = undefined;\n        }\n        if (typeof barPath === \"function\") {\n            callback = barPath;\n            barPath = undefined;\n        }\n\n        loadBarMapThenExecute(() => {\n            const filePaths = barMap.getFileList(barPath);\n            const asyncDispatcher = new AsyncDispatcher(() => {\n                callback();\n            });\n            asyncDispatcher.dispatchEmpty(filePaths.length);\n            filePaths.forEach(filePath => {\n                let actualPath;\n                if (fsFolderPath) {\n                    if (fsFolderPath.includes(filePath)) {\n                        actualPath = fsFolderPath;\n                    }else{\n                        actualPath = path.join(fsFolderPath, filePath);\n                    }\n\n                }else{\n                    actualPath = filePath;\n                }\n\n                this.extractFile(actualPath, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    asyncDispatcher.markOneAsFinished();\n                });\n            });\n        }, callback);\n    };\n\n    this.store = (callback) => {\n        storageProvider.putBarMap(barMap, callback);\n    };\n\n    this.list = (callback) => {\n        loadBarMapThenExecute(() => {\n            callback(undefined, barMap.getFileList());\n        }, callback);\n    };\n\n    this.clone = (targetStorage, preserveKeys = true, callback) => {\n        targetStorage.getBarMap((err, targetBarMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            targetBarMap.setConfig(archiveConfigurator);\n            targetBarMap.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n            loadBarMapThenExecute(__cloneBricks, callback);\n\n            function __cloneBricks() {\n                const fileList = barMap.getFileList();\n                __getFilesRecursively(fileList, 0, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    targetStorage.putBarMap(targetBarMap, callback);\n                });\n            }\n\n            function __getFilesRecursively(fileList, fileIndex, callback) {\n                const filePath = fileList[fileIndex];\n                __getBricksRecursively(filePath, barMap.getHashList(filePath), 0, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    ++fileIndex;\n                    if (fileIndex === fileList.length) {\n                        return callback();\n                    }\n\n                    __getFilesRecursively(fileList, fileIndex, callback);\n                });\n            }\n\n            function __getBricksRecursively(filePath, brickList, brickIndex, callback) {\n                storageProvider.getBrick(brickList[brickIndex], (err, brick) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    if (barMap.getTransformParameters(brickList[brickIndex]).key) {\n                        brick.setTransformParameters({key: barMap.getTransformParameters(brickList[brickIndex]).key});\n                    }\n                    __addBrickToTarget(brick, callback);\n                });\n\n                function __addBrickToTarget(brick, callback) {\n                    brick.setConfig(archiveConfigurator);\n                    if (!preserveKeys) {\n                        brick.createNewTransform();\n                    }\n\n                    ++brickIndex;\n                    targetBarMap.add(filePath, brick);\n                    targetStorage.putBrick(brick, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        if (brickIndex === brickList.length) {\n                            return callback();\n                        }\n\n                        __getBricksRecursively(filePath, brickList, brickIndex, callback);\n                    });\n                }\n            }\n        });\n    };\n\n    //------------------------------------------- internal methods -----------------------------------------------------\n\n    function putBarMap(callback) {\n        if (typeof archiveConfigurator.getMapDigest() !== \"undefined\") {\n            storageProvider.deleteFile(archiveConfigurator.getMapDigest(), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                __putBarMap(callback);\n            });\n            return;\n        }\n        __putBarMap(callback);\n    }\n\n    function __putBarMap(callback) {\n        storageProvider.putBarMap(barMap, (err, newMapDigest) => {\n            if (err) {\n                return callback(err);\n            }\n\n            archiveConfigurator.setMapDigest(newMapDigest);\n            callback(undefined, archiveConfigurator.getMapDigest());\n        });\n    }\n\n    function readFileAsBlocks(fsFilePath, barPath, blockSize, callback) {\n\n        archiveFsAdapter.getFileSize(fsFilePath, (err, fileSize) => {\n            if (err) {\n                return callback(err);\n            }\n\n            let noBlocks = Math.floor(fileSize / blockSize);\n            if (fileSize % blockSize > 0) {\n                ++noBlocks;\n            }\n\n            __readBlocksRecursively(0, callback);\n\n            function __readBlocksRecursively(blockIndex, callback) {\n                archiveFsAdapter.readBlockFromFile(fsFilePath, blockIndex * blockSize, (blockIndex + 1) * blockSize - 1, (err, blockData) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    const brick = new Brick(archiveConfigurator);\n\n                    brick.setRawData(blockData);\n                    barMap.add(barPath, brick);\n\n                    storageProvider.putBrick(brick, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        ++blockIndex;\n                        if (blockIndex < noBlocks) {\n                            __readBlocksRecursively(blockIndex, callback);\n                        } else {\n                            callback();\n                        }\n                    });\n                });\n            }\n        });\n    }\n\n    function loadBarMapThenExecute(functionToBeExecuted, callback) {\n        storageProvider.getBarMap(archiveConfigurator.getMapDigest(), (err, map) => {\n            if (err) {\n                return callback(err);\n            }\n\n            if (!map.getTransformParameters() && archiveConfigurator.getMapEncryptionKey()) {\n                map.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n            }\n\n            if (!map.getConfig()) {\n                map.setConfig(archiveConfigurator);\n            }\n\n            map.load();\n            barMap = map;\n            storageProvider.setBarMap(barMap);\n            functionToBeExecuted();\n        });\n    }\n}\n\nmodule.exports = Archive;\n","const storageProviders = {};\nconst fsAdapters = {};\nconst Seed = require(\"./Seed\");\n\nfunction ArchiveConfigurator() {\n    const config = {};\n\n    let self = this;\n    this.setBufferSize = (bufferSize) => {\n        config.bufferSize = bufferSize;\n    };\n\n    this.getBufferSize = () => {\n        return config.bufferSize;\n    };\n\n    this.setStorageProvider = (storageProviderName, ...args) => {\n        if (!storageProviders[storageProviderName]) {\n            throw new Error(storageProviderName + \" is not registered! Did you forget to register it?\");\n        }\n        config.storageProvider = storageProviders[storageProviderName](...args);\n    };\n\n    this.getStorageProvider = () => {\n        return config.storageProvider;\n    };\n\n    this.setFsAdapter = (fsAdapterName, ...args) => {\n        config.fsAdapter = fsAdapters[fsAdapterName](...args);\n    };\n\n    this.getFsAdapter = () => {\n        return config.fsAdapter;\n    };\n\n    this.setMapDigest = (mapDigest) => {\n        config.mapDigest = mapDigest;\n    };\n\n    this.getMapDigest = () => {\n        return config.mapDigest;\n    };\n\n    this.setEncryptionAlgorithm = (algorithm) => {\n        if (!config.encryption) {\n            config.encryption = {};\n        }\n\n        config.encryption.algorithm = algorithm;\n    };\n\n    this.getEncryptionAlgorithm = () => {\n        if (!config.encryption) {\n            return;\n        }\n        return config.encryption.algorithm;\n    };\n\n    this.setEncryptionOptions = (options) => {\n        if (!config.encryption) {\n            config.encryption = {};\n        }\n\n        config.encryption.encOptions = options;\n    };\n\n    this.getEncryptionOptions = () => {\n        if (!config.encryption) {\n            return;\n        }\n        return config.encryption.encOptions;\n    };\n\n    this.setCompressionAlgorithm = (algorithm) => {\n        if (!config.compression) {\n            config.compression = {};\n        }\n\n        config.compression.algorithm = algorithm;\n    };\n\n    this.getCompressionAlgorithm = () => {\n        if (!config.compression) {\n            return;\n        }\n\n        return config.compression.algorithm;\n\n    };\n\n    this.setCompressionOptions = (options) => {\n        if (!config.compression) {\n            config.compression = {};\n        }\n\n        config.compression.options = options;\n    };\n\n    this.getCompressionOptions = () => {\n        if (!config.compression) {\n            return;\n        }\n        return config.compression.options;\n    };\n\n    this.setAuthTagLength = (authTagLength = 16) => {\n        const encOptions = this.getEncryptionOptions();\n        if (!encOptions) {\n            config.encryption.encOptions = {};\n        }\n\n        config.encryption.encOptions.authTagLength = authTagLength;\n    };\n\n    this.getAuthTagLength = () => {\n        if (!config.encryption || !config.encryption.encOptions) {\n            return;\n        }\n\n        return config.encryption.encOptions.authTagLength;\n    };\n\n    this.setSeedEndpoint = (endpoint) => {\n        config.seedEndpoint = endpoint;\n        this.setStorageProvider(\"EDFSBrickStorage\", endpoint);\n    };\n\n    this.setSeedId = (id) => {\n        config.seed.setId(id);\n        this.setMapDigest(id);\n    };\n\n    this.setSeedLocation = (location) => {\n\n    };\n\n    this.setSeed = (compactSeed, seedId, seedEndpoint) => {\n        config.seed = new Seed(compactSeed, seedId, seedEndpoint);\n        const endpoint = config.seed.getEndpoint();\n        if (endpoint) {\n            this.setStorageProvider(\"EDFSBrickStorage\", endpoint);\n        }\n        this.setMapDigest(config.seed.getId());\n    };\n\n    this.getSeed = () => {\n        loadSeed();\n        if (config.seed) {\n            return config.seed.getCompactForm();\n        }\n    };\n\n    this.getMapEncryptionKey = () => {\n        loadSeed();\n        if (!config.seed) {\n            return;\n        }\n\n        if (!config.encryption) {\n            return;\n        }\n\n        return config.seed.getEncryptionKey(config.encryption.algorithm);\n    };\n\n    //--------------------------\n    function loadSeed(){\n        if (!config.seed ) {\n            config.seed = new Seed(undefined, config.seedId, config.seedEndpoint, !!config.encryption);\n            if (config.seed.getId()) {\n                self.setMapDigest(config.seed.getId());\n            }\n        }\n    }\n}\n\nArchiveConfigurator.prototype.registerStorageProvider = (storageProviderName, factory) => {\n    storageProviders[storageProviderName] = factory;\n};\n\nArchiveConfigurator.prototype.registerFsAdapter = (fsAdapterName, factory) => {\n    fsAdapters[fsAdapterName] = factory;\n};\n\nmodule.exports = ArchiveConfigurator;","const crypto = require('pskcrypto');\nconst BrickTransformFactory = require(\"./transforms/BrickTransformFactory\");\nconst transformFactory = new BrickTransformFactory();\nconst adler32 = require('adler32');\n\nfunction Brick(config) {\n    let rawData;\n    let transformedData;\n    let hash;\n    let transformParameters;\n    let transform = transformFactory.createBrickTransform(config);\n\n    this.setConfig = (newConfig)=> {\n        config = newConfig;\n        if (transform) {\n            transform.setConfig(newConfig);\n        }else{\n            transform = transformFactory.createBrickTransform(config);\n        }\n    };\n\n    this.createNewTransform = ()=> {\n        transform = transformFactory.createBrickTransform(config);\n        transformParameters = undefined;\n        transformData();\n    };\n\n    this.getHash = ()=> {\n        if (!hash) {\n            hash = crypto.pskHash(this.getTransformedData()).toString(\"hex\");\n        }\n\n        return hash;\n    };\n\n    this.getId = () => {\n        return config.getMapDigest();\n    };\n\n    this.setId = (id) => {\n        config.setSeedId(id);\n    };\n\n    this.getSeed = () => {\n        return config.getSeed().toString();\n    };\n    this.getAdler32 = ()=> {\n        return adler32.sum(this.getTransformedData());\n    };\n\n    this.setRawData = function (data) {\n        rawData = data;\n        if (!transform) {\n            transformedData = rawData;\n        }\n    };\n\n    this.getRawData = ()=> {\n        if (rawData) {\n            return rawData;\n        }\n\n        if (transformedData) {\n            if (!transform) {\n                return transformedData;\n            }\n\n            rawData = transform.applyInverseTransform(transformedData, transformParameters);\n            if (rawData) {\n                return rawData;\n            }\n\n            return transformedData;\n        }\n\n        throw new Error(\"The brick does not contain any data.\");\n    };\n\n    this.setTransformedData = (data)=> {\n        transformedData = data;\n    };\n\n    this.getTransformedData = ()=> {\n        if (!transformedData) {\n            transformData();\n        }\n\n        if (transformedData) {\n            return transformedData;\n        }\n\n        if (rawData) {\n            return rawData;\n        }\n\n        throw new Error(\"The brick does not contain any data.\");\n    };\n\n    this.getTransformParameters = ()=> {\n        if (!transformedData) {\n            transformData();\n        }\n        return transformParameters;\n    };\n\n    this.setTransformParameters =  (newTransformParams) =>{\n        if (!newTransformParams) {\n            return;\n        }\n\n        if (!transformParameters) {\n            transformParameters = newTransformParams;\n            return;\n        }\n\n        Object.keys(newTransformParams).forEach(key => {\n            transformParameters[key] = newTransformParams[key];\n        });\n    };\n\n    this.getRawSize = ()=> {\n        return rawData.length;\n    };\n\n    this.getTransformedSize = ()=> {\n        if (!transformedData) {\n            return rawData.length;\n        }\n\n        return transformedData.length;\n    };\n\n//----------------------------------------------- internal methods -----------------------------------------------------\n    function transformData() {\n        if (!transform) {\n            throw new Error(\"transform undefined\");\n        }\n\n        if (rawData) {\n            transformedData = transform.applyDirectTransform(rawData, transformParameters);\n            if (!transformedData) {\n                transformedData = rawData;\n            }\n        }\n\n        transformParameters = transform.getTransformParameters();\n    }\n\n}\n\nmodule.exports = Brick;\n","const Brick = require(\"./Brick\");\nconst util = require(\"../utils/utilities\");\nconst path = require('path');\n\nfunction FileBarMap(header) {\n    header = header || {};\n\n    let brickOffset = util.getBarMapOffsetSize();\n    let archiveConfig;\n    let encryptionKey;\n\n    this.add = (filePath, brick) => {\n        filePath = filePath.split(path.sep).join(path.posix.sep);\n        this.load();\n        if (typeof header[filePath] === \"undefined\") {\n            header[filePath] = [];\n        }\n\n        const brickObj = {\n            checkSum: brick.getAdler32(),\n            offset: brickOffset,\n            hash: brick.getHash()\n        };\n\n        const encKey = brick.getTransformParameters() ? brick.getTransformParameters().key : undefined;\n        if (encKey) {\n            brickObj.key = encKey;\n        }\n\n        header[filePath].push(brickObj);\n        brickOffset += brick.getTransformedSize();\n    };\n\n    this.getHashList = (filePath) => {\n        this.load();\n        return header[filePath].map(brickObj => brickObj.offset);\n    };\n\n    this.getFileList = (folderBarPath) => {\n        this.load();\n        if (!folderBarPath) {\n            return Object.keys(header);\n        }\n        return Object.keys(header).filter(fileName => fileName.includes(folderBarPath));\n    };\n\n    this.getDictionaryObject = () => {\n        let objectDict = {};\n        Object.keys(header).forEach((fileName) => {\n            let brickObjects = header[fileName];\n            for (let j = 0; j < brickObjects.length; j++) {\n                if (typeof objectDict[brickObjects[j]['checkSum']] === 'undefined') {\n                    objectDict[brickObjects[j]['checkSum']] = [];\n                }\n                objectDict[brickObjects[j]['checkSum']].push(brickObjects[j]['hash']);\n            }\n        });\n        return objectDict;\n    };\n\n    this.getTransformParameters = (brickId) => {\n        if (!brickId) {\n            return encryptionKey ? {key: encryptionKey} : {};\n        }\n\n        this.load();\n        let bricks = [];\n        const files = this.getFileList();\n\n        files.forEach(filePath => {\n            bricks = bricks.concat(header[filePath]);\n        });\n\n        const brickObj = bricks.find(brick => {\n            return brick.offset === brickId;\n        });\n\n        const addTransformData = {};\n        if (brickObj.key) {\n            addTransformData.key = Buffer.from(brickObj.key);\n        }\n\n        return addTransformData;\n    };\n\n    this.toBrick = () => {\n        this.load();\n        const brick = new Brick(archiveConfig);\n        brick.setTransformParameters({key: encryptionKey});\n        brick.setRawData(Buffer.from(JSON.stringify(header)));\n        return brick;\n    };\n\n    this.load = () => {\n        if (header instanceof Brick) {\n            header.setConfig(archiveConfig);\n            if (encryptionKey) {\n                header.setTransformParameters({key: encryptionKey});\n            }\n            header = JSON.parse(header.getRawData().toString());\n        }\n    };\n\n    this.setConfig = (config) => {\n        archiveConfig = config;\n    };\n\n    this.getConfig = () => {\n        return archiveConfig;\n    };\n\n    this.setEncryptionKey = (encKey) => {\n        encryptionKey = encKey;\n    };\n\n    this.removeFile = (filePath) => {\n        this.load();\n        delete header[filePath];\n    };\n}\n\nmodule.exports = FileBarMap;","const BarMap = require(\"./FileBarMap\");\nconst util = require(\"../utils/utilities\");\nconst fs = require(\"fs\");\nconst Brick = require(\"./Brick\");\nconst AsyncDispatcher = require(\"../utils/AsyncDispatcher\");\n\nfunction FileBrickStorage(filePath) {\n\n    let isFirstBrick = true;\n    let map;\n    let mapOffset;\n\n    this.setBarMap = (barMap) => {\n        map = barMap;\n    };\n\n    this.putBrick = (brick, callback) => {\n        if (isFirstBrick) {\n            isFirstBrick = false;\n            const writeStream = fs.createWriteStream(filePath, {start: util.getBarMapOffsetSize()});\n            writeStream.on(\"error\", (err) => {\n                return callback(err);\n            });\n\n            writeStream.write(brick.getTransformedData(), callback);\n        } else {\n            fs.appendFile(filePath, brick.getTransformedData(), callback);\n        }\n    };\n\n    this.getBrick = (brickId, callback) => {\n        this.getBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n            let brickOffsets = [];\n            const fileList = barMap.getFileList();\n            fileList.forEach(file => {\n                brickOffsets = brickOffsets.concat(barMap.getHashList(file));\n            });\n\n            const brickIndex = brickOffsets.findIndex(el => {\n                return el === brickId;\n            });\n\n            let nextBrickId = brickOffsets[brickIndex + 1];\n            if (!nextBrickId) {\n                nextBrickId = Number(mapOffset);\n            }\n\n            readBrick(brickId, nextBrickId, callback);\n        });\n\n    };\n\n    this.deleteFile = (fileName, callback) => {\n        this.getBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            barMap.removeFile(fileName);\n            this.putBarMap(barMap, callback);\n        });\n    };\n\n\n    this.putBarMap = (barMap, callback) => {\n        map = barMap;\n        readBarMapOffset((err, offset) => {\n            if(offset) {\n                offset = Number(offset);\n                fs.truncate(filePath, offset, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    __writeBarMap(offset);\n                });\n            }else{\n                fs.stat(filePath, (err, stats) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    const barMapOffset = stats.size;\n\n                    const bufferBarMapOffset = Buffer.alloc(util.getBarMapOffsetSize());\n                    bufferBarMapOffset.writeBigUInt64LE(BigInt(barMapOffset));\n                    mapOffset = barMapOffset;\n                    const offsetWriteStream = fs.createWriteStream(filePath, {flags: \"r+\", start: 0});\n\n                    offsetWriteStream.on(\"error\", (err) => {\n                        return callback(err);\n                    });\n\n                    offsetWriteStream.write(bufferBarMapOffset, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        __writeBarMap(barMapOffset);\n                    });\n                });\n            }\n        });\n\n        function __writeBarMap(offset) {\n            const mapWriteStream = fs.createWriteStream(filePath, {flags: \"r+\", start: offset});\n            mapWriteStream.on(\"error\", (err) => {\n                return callback(err);\n            });\n\n            const mapBrick = barMap.toBrick();\n            mapBrick.setTransformParameters(barMap.getTransformParameters());\n            mapWriteStream.write(mapBrick.getTransformedData(), callback);\n        }\n\n    };\n\n    this.getBarMap = (mapDigest, callback) => {\n        if (typeof mapDigest === \"function\") {\n            callback = mapDigest;\n        }\n\n        if (map) {\n            return callback(undefined, map);\n        }\n\n        readBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            map = barMap;\n            callback(undefined, barMap);\n        });\n    };\n\n    //------------------------------------------ Internal functions ---------------------------------------------------\n\n    function readBarMapOffset(callback) {\n        const readStream = fs.createReadStream(filePath, {start: 0, end: util.getBarMapOffsetSize() - 1});\n\n        const buffer = Buffer.alloc(util.getBarMapOffsetSize());\n        let offsetBuffer = 0;\n\n        readStream.on(\"data\", (chunk) => {\n            chunk.copy(buffer, offsetBuffer);\n            offsetBuffer += chunk.length;\n        });\n\n        readStream.on(\"end\", () => {\n            callback(undefined, buffer.readBigUInt64LE());\n        });\n\n        readStream.on(\"error\", (err) => {\n            return callback(err);\n        });\n    }\n\n    function readBarMap(callback) {\n        readBarMapOffset((err, barMapOffset) => {\n            if (err) {\n                if (err.code === \"ENOENT\") {\n                    return callback(undefined, new BarMap());\n                }\n\n                return callback(err)\n            }\n\n            mapOffset = barMapOffset;\n            const readStream = fs.createReadStream(filePath, {start: Number(barMapOffset)});\n            let barMapData = Buffer.alloc(0);\n\n            readStream.on(\"data\", (chunk) => {\n                barMapData = Buffer.concat([barMapData, chunk]);\n            });\n\n            readStream.on(\"error\", (err) => {\n                return callback(err);\n            });\n\n            readStream.on(\"end\", () => {\n                const mapBrick = new Brick();\n                mapBrick.setTransformedData(barMapData);\n                callback(undefined, new BarMap(mapBrick));\n            });\n        });\n    }\n\n    function readBrick(brickOffsetStart, brickOffsetEnd, callback) {\n        const readStream = fs.createReadStream(filePath, {start: brickOffsetStart, end: brickOffsetEnd - 1});\n        let brickData = Buffer.alloc(0);\n\n        readStream.on(\"data\", (chunk) => {\n            brickData = Buffer.concat([brickData, chunk]);\n        });\n\n        readStream.on(\"error\", (err) => {\n            return callback(err);\n        });\n\n        readStream.on(\"end\", () => {\n            const brick = new Brick();\n            brick.setTransformedData(brickData);\n            callback(undefined, brick);\n        });\n    }\n}\n\nmodule.exports = {\n    createFileBrickStorage(filePath) {\n        return new FileBrickStorage(filePath);\n    }\n};","const Brick = require(\"./Brick\");\nconst path = require('path');\n\nfunction FolderBarMap(header) {\n    header = header || {};\n\n    let archiveConfig;\n    let encryptionKey;\n\n    this.add = (filePath, brick) => {\n        filePath = filePath.split(path.sep).join(path.posix.sep);\n        this.load();\n        if (typeof header[filePath] === \"undefined\") {\n            header[filePath] = [];\n        }\n\n        const brickObj = {\n            checkSum: brick.getAdler32(),\n            hash: brick.getHash()\n        };\n\n        const encKey = brick.getTransformParameters() ? brick.getTransformParameters().key : undefined;\n        if (encKey) {\n            brickObj.key = encKey;\n        }\n        header[filePath].push(brickObj);\n    };\n\n    this.isInHeader = (filePath) => {\n        return header[filePath] !== undefined;\n    };\n\n    this.removeBrick = (filePath, brickHash) => {\n        let indexToRemove = header[filePath].findIndex(brickObj => brickObj.hash === brickHash);\n        header[filePath].splice(indexToRemove, 1);\n    };\n\n    this.getDictionaryObject = () => {\n        let objectDict = {};\n        Object.keys(header).forEach((fileName) => {\n            let brickObjects = header[fileName];\n            for (let j = 0; j < brickObjects.length; j++) {\n                if (typeof objectDict[brickObjects[j]['checkSum']] === 'undefined') {\n                    objectDict[brickObjects[j]['checkSum']] = [];\n                }\n                objectDict[brickObjects[j]['checkSum']].push(brickObjects[j]['hash']);\n            }\n        });\n        return objectDict;\n    };\n\n    this.getHashList = (filePath) => {\n        this.load();\n        return header[filePath].map(brickObj => brickObj.hash);\n    };\n\n    this.getCheckSumList = (filePath) => {\n        this.load();\n        return header[filePath].map(brickObj => brickObj.checkSum);\n    };\n\n    this.emptyList = (filePath) => {\n        header[filePath] = [];\n    };\n\n\n    this.toBrick = () => {\n        this.load();\n        const brick = new Brick(archiveConfig);\n        if (encryptionKey) {\n            brick.setTransformParameters({key: encryptionKey});\n        }\n        brick.setRawData(Buffer.from(JSON.stringify(header)));\n        return brick;\n    };\n\n\n    this.getFileList = (folderBarPath) => {\n        this.load();\n        if (!folderBarPath) {\n            return Object.keys(header);\n        }\n        return Object.keys(header).filter(fileName => fileName.includes(folderBarPath));\n    };\n\n    this.getTransformParameters = (brickId) => {\n        this.load();\n        if (!brickId) {\n            return encryptionKey ? {key: encryptionKey} : undefined;\n        }\n        let bricks = [];\n        const files = this.getFileList();\n        files.forEach(file => {\n            bricks = bricks.concat(header[file]);\n        });\n\n        const brickObj = bricks.find(brick => {\n            return brick.hash === brickId;\n        });\n\n        const addTransformData = {};\n        if (brickObj.key) {\n            addTransformData.key = Buffer.from(brickObj.key);\n        }\n\n        return addTransformData;\n    };\n\n    this.load = () => {\n        if (header instanceof Brick) {\n            header.setConfig(archiveConfig);\n            header.setTransformParameters({key: encryptionKey});\n            header = JSON.parse(header.getRawData().toString());\n        }\n    };\n\n    this.setConfig = (config) => {\n        archiveConfig = config;\n    };\n\n    this.getConfig = () => {\n        return archiveConfig;\n    };\n\n    this.setEncryptionKey = (encKey) => {\n        encryptionKey = encKey;\n    };\n\n    this.removeFile = (filePath) => {\n        this.load();\n        delete header[filePath];\n    };\n}\n\nmodule.exports = FolderBarMap;","const fs = require(\"fs\");\nconst path = require(\"path\");\nconst BarMap = require(\"./FolderBarMap\");\nconst Brick = require(\"./Brick\");\n\nfunction FolderBrickStorage(location) {\n    let map;\n\n    this.setBarMap = (barMap) => {\n        map = barMap;\n    };\n\n    this.putBrick = (brick, callback) => {\n        const writeStream = fs.createWriteStream(path.join(location, brick.getHash()));\n        writeStream.write(brick.getTransformedData(), (...args) => {\n            writeStream.end();\n            callback(...args);\n        });\n    };\n\n    this.getBrick = (brickHash, callback) => {\n        fs.readFile(path.join(location, brickHash), (err, brickData) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const brick = new Brick();\n            brick.setTransformedData(brickData);\n            callback(err, brick);\n        });\n    };\n\n    this.deleteFile = (filePath, callback) => {\n        this.getBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            fs.unlink(path.join(location, barMap.toBrick().getHash()), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                barMap.removeFile(filePath);\n                this.putBarMap(barMap, callback);\n            });\n        });\n    };\n\n    this.putBarMap = (barMap, callback) => {\n        map = barMap;\n        const barMapBrick = barMap.toBrick();\n        barMapBrick.setTransformParameters(barMap.getTransformParameters());\n       \n        let brickId = barMapBrick.getId();\n        if (!brickId) {\n            brickId = barMapBrick.getHash();\n        }\n\n        barMapBrick.setId(brickId);\n        const writeStream = fs.createWriteStream(path.join(location, brickId));\n        writeStream.write(barMapBrick.getTransformedData(), (err) => {\n            writeStream.end();\n            callback(err, barMapBrick.getSeed());\n        });\n    };\n\n    this.getBarMap = (mapDigest, callback) => {\n        if (typeof mapDigest === \"function\") {\n            callback = mapDigest;\n            mapDigest = undefined;\n        }\n\n        if (map) {\n            return callback(undefined, map);\n        }\n\n        if (typeof mapDigest === \"undefined\") {\n            return callback(undefined, new BarMap());\n        }\n\n        this.getBrick(mapDigest, (err, mapBrick) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const barMap = new BarMap(mapBrick);\n            map = barMap;\n            callback(undefined, barMap);\n        });\n    }\n}\n\nmodule.exports = {\n    createFolderBrickStorage(location) {\n        return new FolderBrickStorage(location);\n    }\n};","const crypto = require(\"pskcrypto\");\n\nfunction Seed(compactSeed, id, endpoint, usedForEncryption  = true, randomLength = 32) {\n    let seed;\n\n    init();\n\n    this.getCompactForm = () => {\n        if (!seed) {\n            throw Error(\"Cannot return seed\");\n        }\n\n        return generateCompactForm(seed);\n    };\n\n    this.getLocation = () => {\n        if (!seed) {\n            throw Error(\"Cannot retrieve location\");\n        }\n\n        return seed.endpoint + \"/\" + seed.id.toString(\"hex\");\n    };\n\n    this.getEndpoint = () => {\n        if (!seed) {\n            throw Error(\"Cannot retrieve endpoint\");\n        }\n\n        return seed.endpoint.toString();\n    };\n\n    this.getId = () => {\n        if (!seed.id) {\n            return;\n        }\n        return seed.id.toString(\"hex\");\n    };\n\n    this.setId = (localId) => {\n        seed.id = localId;\n    };\n\n    this.getEncryptionKey = (algorithm) => {\n        if (seed.tag === 'r') {\n            return;\n        }\n\n        return crypto.deriveKey(algorithm, generateCompactForm(seed));\n    };\n\n    //--------------------------------------- internal methods --------------------------------------------\n    function init() {\n        if (!compactSeed) {\n            seed = create();\n        } else {\n            load(compactSeed);\n        }\n    }\n\n    function create() {\n        const localSeed = {};\n        localSeed.id = id;\n        if (!id && usedForEncryption) {\n            localSeed.id = crypto.randomBytes(randomLength);\n        }\n\n        if (endpoint) {\n            localSeed.endpoint = endpoint;\n        }\n\n        if (usedForEncryption === true) {\n            localSeed.flag = 'e';\n        }else{\n            localSeed.flag = 'r';\n        }\n\n        return localSeed;\n    }\n\n    function generateCompactForm(expandedSeed) {\n        if (typeof expandedSeed === \"string\") {\n            return expandedSeed;\n        }\n\n        if(!expandedSeed.id){\n            throw Error(\"The seed does not contain an id\");\n        }\n        let compactSeed = expandedSeed.id.toString('base64');\n        if (expandedSeed.endpoint) {\n            compactSeed += '|' + Buffer.from(JSON.stringify(expandedSeed.endpoint)).toString('base64');\n        }\n\n        compactSeed += expandedSeed.flag;\n        return Buffer.from(encodeURIComponent(compactSeed));\n    }\n\n    function load(compactFormSeed) {\n        if (typeof compactFormSeed === \"undefined\") {\n            throw new Error(`Expected type string or Buffer. Received undefined`);\n        }\n\n        if (typeof compactFormSeed !== \"string\") {\n            if (typeof compactFormSeed === \"object\" && !Buffer.isBuffer(compactFormSeed)) {\n                compactFormSeed = Buffer.from(compactFormSeed);\n            }\n\n            compactFormSeed = compactFormSeed.toString();\n        }\n\n        const decodedCompactSeed = decodeURIComponent(compactFormSeed);\n        const localSeed = {};\n        const splitCompactSeed = decodedCompactSeed.split('|');\n\n        localSeed.flag = splitCompactSeed[splitCompactSeed.length - 1];\n        localSeed.id = Buffer.from(splitCompactSeed[0], 'base64');\n\n        if (splitCompactSeed[1] && splitCompactSeed[1].length > 0) {\n            localSeed.endpoint = JSON.parse(Buffer.from(splitCompactSeed[1], 'base64').toString());\n        }\n\n        return localSeed;\n    }\n}\n\nmodule.exports = Seed;","function BrickTransform(transformGenerator) {\n    let directTransform;\n    let inverseTransform;\n\n    this.getTransformParameters = () => {\n        return directTransform ? directTransform.transformParameters : undefined;\n    };\n\n    this.applyDirectTransform = (data, transformParameters) => {\n        if (!directTransform) {\n            directTransform = transformGenerator.createDirectTransform(transformParameters);\n        }\n\n        if (!directTransform) {\n            return undefined;\n        }\n\n        let transformedData = directTransform.transform(data);\n\n        if(directTransform.transformParameters){\n            if (directTransform.transformParameters.iv) {\n                transformedData = Buffer.concat([transformedData, directTransform.transformParameters.iv]);\n            }\n\n            if (directTransform.transformParameters.aad) {\n                transformedData = Buffer.concat([transformedData, directTransform.transformParameters.aad]);\n            }\n\n            if (directTransform.transformParameters.tag) {\n                transformedData = Buffer.concat([transformedData, directTransform.transformParameters.tag]);\n            }\n        }\n\n        return transformedData;\n    };\n\n    this.applyInverseTransform = (data, transformParameters) => {\n        const inverseTransformParams = transformGenerator.getInverseTransformParameters(data);\n        if(inverseTransformParams.params) {\n            Object.keys(inverseTransformParams.params).forEach(param => transformParameters[param] = inverseTransformParams.params[param]);\n        }\n\n        if (!inverseTransform) {\n            inverseTransform = transformGenerator.createInverseTransform(transformParameters);\n        }\n\n        return inverseTransform ? inverseTransform.transform(inverseTransformParams.data) : undefined;\n    };\n}\n\nmodule.exports = BrickTransform;\n\n","const CompressionGenerator = require(\"./CompressionGenerator\");\nconst EncryptionGenerator= require(\"./EncryptionGenerator\");\nconst CompressionEncryptionGenerator = require(\"./CompressionEncryptionGenerator\");\nconst BrickTransform = require(\"./BrickTransform\");\n\nfunction BrickTransformFactory() {\n    this.createBrickTransform = function (config) {\n        if (!config) {\n            return;\n        }\n\n        const encryption = config.getEncryptionAlgorithm();\n        const compression = config.getCompressionAlgorithm();\n\n        let generator;\n        if (!encryption && !compression) {\n            return;\n        }\n\n        if (compression) {\n            if (encryption) {\n                generator = new CompressionEncryptionGenerator(config);\n            } else {\n                generator = new CompressionGenerator(config);\n            }\n        }else{\n            generator = new EncryptionGenerator(config);\n        }\n\n        return new BrickTransform(generator);\n    }\n}\n\nmodule.exports = BrickTransformFactory;\n\n","const CompressionGenerator = require(\"./CompressionGenerator\");\nconst EncryptionGenerator = require(\"./EncryptionGenerator\");\n\nfunction CompressionEncryptionGenerator(config) {\n    let compressionGenerator = new CompressionGenerator(config);\n    let encryptionGenerator = new EncryptionGenerator(config);\n\n    this.getInverseTransformParameters = (transformedData) => {\n        return encryptionGenerator.getInverseTransformParameters(transformedData);\n    };\n\n    this.createDirectTransform = (transformParameters) => {\n        const compression = compressionGenerator.createDirectTransform();\n        const encryption = encryptionGenerator.createDirectTransform(transformParameters);\n        const compressionEncryption = {};\n        Object.keys(encryption).forEach(key => {\n            compressionEncryption[key] = encryption[key]\n        });\n\n        compressionEncryption.transform = (data) => {\n            return encryption.transform(compression.transform(data));\n        };\n\n        return compressionEncryption;\n    };\n\n    this.createInverseTransform = (transformParameters) => {\n        const decompression = compressionGenerator.createInverseTransform();\n        const decryption = encryptionGenerator.createInverseTransform(transformParameters);\n        const compressionEncryption = {};\n        Object.keys(decompression).forEach(key => {\n            compressionEncryption[key] = decompression[key]\n        });\n        compressionEncryption.transform = (data) => {\n            return decompression.transform(decryption.transform(data));\n        };\n\n        return compressionEncryption;\n    };\n}\n\nmodule.exports = CompressionEncryptionGenerator;","const zlib = require(\"zlib\");\n\nfunction CompressionGenerator(config) {\n\n    this.getInverseTransformParameters = (transformedData) => {\n        return {data: transformedData};\n    };\n\n    this.createDirectTransform = () => {\n        return getCompression(true);\n    };\n\n    this.createInverseTransform = () => {\n        return getCompression(false);\n    };\n\n    function getCompression(isCompression) {\n        const algorithm = config.getCompressionAlgorithm();\n        switch (algorithm) {\n            case \"gzip\":\n                return __createCompress(zlib.gzipSync, zlib.gunzipSync, isCompression);\n            case \"br\":\n                return __createCompress(zlib.brotliCompressSync, zlib.brotliDecompressSync, isCompression);\n            case \"deflate\":\n                return __createCompress(zlib.deflateSync, zlib.inflateSync, isCompression);\n            case \"deflateRaw\":\n                return __createCompress(zlib.deflateRawSync, zlib.inflateRawSync, isCompression);\n            default:\n                return;\n        }\n    }\n\n    function __createCompress(compress, decompress, isCompression) {\n        const options = config.getCompressionOptions();\n        if (!isCompression) {\n            return {\n                transform(data) {\n                    return decompress(data, options);\n                }\n            }\n        }\n\n        return {\n            transform(data) {\n                return compress(data, options);\n            }\n        }\n    }\n}\n\nmodule.exports = CompressionGenerator;\n\n","const crypto = require(\"pskcrypto\");\n\nfunction EncryptionGenerator(config) {\n    let key;\n    const pskEncryption = crypto.createPskEncryption(config.getEncryptionAlgorithm());\n    this.setConfig = (newConfig) => {\n        config = newConfig;\n    };\n\n    this.getInverseTransformParameters = (transformedData) => {\n        let decryptionParameters = pskEncryption.getDecryptionParameters(transformedData);\n        const data = decryptionParameters.data;\n        delete decryptionParameters.data;\n        return {\n            data: data,\n            params:decryptionParameters\n        };\n    };\n\n    this.createDirectTransform = (transformParameters) => {\n        return getEncryption(transformParameters);\n    };\n\n    this.createInverseTransform = (transformParameters) => {\n        return getDecryption(transformParameters);\n    };\n\n    //--------------------------------------- internal methods ------------------------------------------------------\n    function getEncryption(transformParameters) {\n        const algorithm = config.getEncryptionAlgorithm();\n        if (!algorithm) {\n            return;\n        }\n\n        const encOptions = config.getEncryptionOptions();\n        if(transformParameters && transformParameters.key){\n            key = transformParameters.key;\n        }else{\n            key = pskEncryption.generateEncryptionKey(algorithm);\n        }\n\n\n        const ret = {\n            transform(data) {\n                const encData = pskEncryption.encrypt(data, key, encOptions);\n                ret.transformParameters = pskEncryption.getEncryptionParameters();\n                return encData;\n            }\n        };\n\n        return ret;\n    }\n\n\n    function getDecryption(transformConfig) {\n        const algorithm = config.getEncryptionAlgorithm();\n        if (!algorithm) {\n            return;\n        }\n        const encOptions = config.getEncryptionOptions();\n        let authTagLength = 0;\n        if (!config.getEncryptionOptions() || !config.getAuthTagLength()) {\n            authTagLength = 16;\n        } else {\n            authTagLength = config.getAuthTagLength();\n        }\n\n        return {\n            transform(data) {\n                return pskEncryption.decrypt(data, transformConfig.key, authTagLength, encOptions);\n            }\n        }\n    }\n\n}\n\nmodule.exports = EncryptionGenerator;","\nfunction AsyncDispatcher(finalCallback) {\n\tlet results = [];\n\tlet errors = [];\n\n\tlet started = 0;\n\n\tfunction markOneAsFinished(err, res) {\n\t\tif(err) {\n\t\t\terrors.push(err);\n\t\t}\n\n\t\tif(arguments.length > 2) {\n\t\t\targuments[0] = undefined;\n\t\t\tres = arguments;\n\t\t}\n\n\t\tif(typeof res !== \"undefined\") {\n\t\t\tresults.push(res);\n\t\t}\n\n\t\tif(--started <= 0) {\n            return callCallback();\n\t\t}\n\t}\n\n\tfunction dispatchEmpty(amount = 1) {\n\t\tstarted += amount;\n\t}\n\n\tfunction callCallback() {\n\t    if(errors && errors.length === 0) {\n\t        errors = undefined;\n        }\n\n\t    if(results && results.length === 0) {\n\t        results = undefined;\n        }\n\n        finalCallback(errors, results);\n    }\n\n\treturn {\n\t\tdispatchEmpty,\n\t\tmarkOneAsFinished\n\t};\n}\n\nmodule.exports = AsyncDispatcher;","function isStream(stream){\n    return stream !== null && typeof stream === 'object' && typeof stream.pipe === 'function';\n}\n\nfunction isWritable(stream) {\n    return isStream(stream) &&\n        stream.writable !== false &&\n        typeof stream._write === 'function' &&\n        typeof stream._writableState === 'object';\n\n}\n\nfunction isReadable(stream) {\n    return isStream(stream) &&\n        stream.readable !== false &&\n        typeof stream._read === 'function' &&\n        typeof stream._readableState === 'object';\n}\n\nfunction isDuplex(stream){\n    return isWritable(stream) &&\n        isReadable(stream);\n}\n\nmodule.exports = {\n    isStream,\n    isReadable,\n    isWritable,\n    isDuplex\n};\n","const fs = require('fs');\nconst OFFSET_SIZE = 8;\n\nfunction getBarMapOffsetSize() {\n    return OFFSET_SIZE;\n}\n\nfunction ensureFileDoesNotExist(filePath, callback) {\n    fs.access(filePath, (err) => {\n        if (!err) {\n            fs.unlink(filePath, callback);\n        } else {\n            return callback();\n        }\n    });\n}\n\nmodule.exports = {getBarMapOffsetSize, ensureFileDoesNotExist};","let pskcrypto = require(\"pskcrypto\");\nlet fs = require(\"fs\");\n\nlet consUtil = require(\"./transactionsUtil\");\n\n\n\nlet detailedDebug = false;\n\n\n\n\nlet OBFTPSwarm = $$.flow.describe(\"OBFTProcess\", {\n    start: function (delegatedAgentName, communicationOutlet, pdsAdapter, pulsePeriodicity, latency, votingBox) {\n\n        this.lset = {}; // digest -> transaction - localy generated set of transactions (`createTransactionFromSwarm` stores each transaction; `beat` resets `lset`)\n        /*this.dset = {}; // digest -> transaction - remotely delivered set of transactions that will be next participate in consensus\n        this.pset = {}; // digest -> transaction - consensus pending set */\n\n        this.CP = 0;\n        this.CI = undefined;\n        this.LAST = 0;\n        this.TOP = this.LAST+2*latency;\n        this.NEXT = this.TOP+latency;\n        this.NTOP = this.TOP+2*latency;\n\n        this.pulsesHistory = new PulseHistory();\n\n        this.vsd = pdsAdapter.getHashLatestBlock();\n\n\n        this.currentBlock = 0;\n        this.nodeName               = delegatedAgentName;\n        this.communicationOutlet    = communicationOutlet;\n        this.pds                    = pdsAdapter;\n        this.PP                     = pulsePeriodicity;\n        this.LATENCY                = latency;\n        this.votingBox              = votingBox;\n        this.explictPhase           = \"default\"; /* default, boot, late, broken*/\n\n        this.bootNode();\n    },\n    /*\n    * @param {transaction}\n    */\n    receiveTransaction:function(t){\n        this.lset[t.digest] = t;\n    },\n    /*\n     * @param {}\n    */\n    sendPulse: function () {\n        switch(this.explictPhase){\n            case \"boot\": break;\n            case \"late\": break;\n            case \"ntop\": this.sendAtNTOP(); break;\n            case \"broken\":this.whenBroken_HumanInterventionIsRequired(); break\n            default:\n                if(this.CP <= this.TOP) this.sendUntilTOP(); else\n                if(this.CP < this.NEXT) this.sendUntilNEXT(); else\n                if(this.CP == this.NEXT) this.sendAtNEXT(); else\n                if(this.CP < this.NTOP) this.sendUntilNTOP(); else\n                if(this.CP == this.NTOP) this.sendAtNTOP(); else\n                    console.log(\"Should not happen\");\n        }\n        setTimeout(this.sendPulse, this.PP);   //self invocation of the phase\n    },\n    /*\n     * @param {}\n    */\n    sendUntilTOP: function () {\n        communicationOutlet.newPulse()\n    },\n    /*\n     * @param {}\n    */\n    sendUntilNEXT: function () {\n\n    },\n    /*\n     * @param {}\n    */\n    sendAtNEXT: function () {\n\n    },\n    /*\n     * @param {}\n    */\n    sendUntilNTOP: function () {\n\n    },\n    /*\n     * @param {}\n    */\n    sendAtNTOP: function () {\n\n    },\n    /*\n     * @param {}\n    */\n    whenSlowNode: function () {\n\n    },\n    /*\n     * @param {}\n    */\n    whenSlowNetwork: function () {\n\n    },\n    /*\n     * @param {}\n    */\n    whenBroken_HumanInterventionIsRequired: function () {\n\n    },\n    /*\n     * @param {pulse}\n    */\n    receivePulse:function(pulse){\n\n    },\n    /*\n     * @param {}\n    */\n    bootNode: function () {\n        this.explictPhase = \"BOOT\";\n    },\n     /*\n     * @param {Pulse} pulse e.g. new Pulse(this.nodeName, this.currentPulse, ......)\n     */\n    recordPulse: function (pulse) {\n    },\n    /*\n         * @param {}\n        */\n    requestMissingPulse: function () {\n\n    }\n});\n\n\n/**\n * @param {String} delegatedAgentName e.g. 'Node 0', or 'agent_007'\n * @param {Object} communicationOutlet e.g. object to be used in phase `beat` of the returned \"pulseSwarm\" flow\n *  - it should have a property: `broadcastPulse`: function(from, pulse) {...}\n *      - {String} `from` e.g. `delegatedAgentName`\n *      - {Pulse} `pulse` (see 'transactionsUtil.js')\n * @param {InMemoryPDS} pdsAdapter e.g. require(\"pskdb/lib/InMemoryPDS\").newPDS(null);\n * @param {Number} pulsePeriodicity e.g. 300\n * \n * @returns {SwarmDescription} A new instance of \"pulseSwarm\" flow, with phase `start` already running\n */\nexports.createConsensusManager = function (delegatedAgentName, communicationOutlet, pdsAdapter, pulsePeriodicity, votingBox) {\n    let instance = pulseSwarm();\n    instance.start(delegatedAgentName, communicationOutlet, pdsAdapter, pulsePeriodicity, votingBox);\n    return instance;\n}\n","function PulseUtil(signer, currentPulseNumber, block, newTransactions, vsd, top, last) {\n    this.signer         = signer;               //a.k.a. delegatedAgentName\n    this.currentPulse   = currentPulseNumber;\n    this.lset           = newTransactions;      //digest -> transaction\n    this.ptBlock        = block;                //array of digests\n    this.vsd            = vsd;\n    this.top            = top;                  // a.k.a. topPulseConsensus\n    this.last           = last;                 // a.k.a. lastPulseAchievedConsensus\n}\n\n\nmodule.exports.createPulse = function (signer, CP, CI, lset, top, last) {\n    return new PulseUtil(signer, CP, CI, lset, vsd, top, last);\n}\n\n\nfunction PulseHistory(){\n\n}\n\nmodule.exports.createPulseHistory = function () {\n    return new PulseHistory();\n}","/*\nconsensus helper functions when working with transactions\n*/\n\nlet  pskcrypto = require(\"pskcrypto\");\n\n\nmodule.exports.orderCRTransactions = function (pset) { //order in place the pset array\n    var arr = [];\n    for (let d in pset) {\n        arr.push(pset[d]);\n    }\n\n    arr.sort(function (t1, t2) {\n        if (t1.transactionPulse < t2.transactionPulse) return -1;\n        if (t1.transactionPulse > t2.transactionPulse) return 1;\n        if (t1.second < t2.second) return -1;\n        if (t1.second > t2.second) return 1;\n        if (t1.nanosecod < t2.nanosecod) return -1;\n        if (t1.nanosecod > t2.nanosecod) return 1;\n        if (t1.digest < t2.digest) return -1;\n        if (t1.digest > t2.digest) return 1;\n        return 0; //only for identical transactions...\n    })\n    return arr;\n}\n","var callflowModule = require(\"callflow\");\nvar CNST = require(\"../moduleConstants\");\n\nexports.createForObject = function(valueObject, thisObject, localId){\n\tvar ret = callflowModule.createStandardAPIsForSwarms(valueObject, thisObject, localId);\n\n\tret.swarm           = null;\n\tret.onReturn        = null;\n\tret.onResult        = null;\n\tret.asyncReturn     = null;\n\tret.return          = null;\n\tret.home            = null;\n\n\tret.autoInit        = function(blockchain){\n\t\tif(!blockchain) {\n\t\t\t$$.warn(\"Initialisation asset outside of a blockchain context\");\n\t\t\treturn;\n\t\t}\n\t\tlet sp = thisObject.getMetadata(CNST.SECURITY_PARADIGM);\n\t\tthisObject.securityParadigm = blockchain.getSPRegistry().getSecurityParadigm(thisObject);\n\t\tif(sp == undefined){\n\t\t\tlet ctor = valueObject.myFunctions[CNST.CTOR];\n\t\t\tif(ctor){\n\t\t\t\tctor.apply(thisObject);\n\t\t\t}\n\t\t}\n\t};\n\n\tret.getSwarmId = function(){\n\t\treturn \tthisObject.getMetadata(CNST.SWARMID);\n\t}\n\n\tret.getSwarmType = function(){\n\t\treturn \tthisObject.getMetadata(CNST.SWARMTYPE);\n\t}\n\n\tret.__reinit = function(blockchain){\n\t\tret.autoInit(blockchain);\n\t}\n\treturn ret;\n};","let callflowModule = require(\"callflow\");\nlet CNST = require(\"../moduleConstants\");\n\nexports.createForObject = function(valueObject, thisObject, localId){\n\tlet _blockchain = undefined;\n\n\tlet ret = callflowModule.createStandardAPIsForSwarms(valueObject, thisObject, localId);\n\tret.swarm           = null;\n\tret.onReturn        = null;\n\tret.onResult        = null;\n\tret.asyncReturn     = null;\n\t//ret.return          = null;\n\tret.home            = null;\n\tret.autoInit        = function(blockchain){\n\t\t_blockchain = blockchain;\n\t\tthisObject.transaction = blockchain.beginTransaction(thisObject);\n\t};\n\n\tret.commit = function () {\n\t\t_blockchain.commit(thisObject.transaction);\n\t};\n\n\tret.onCommit = function (callback) {\n\t\tthisObject.observe((event) => {\n\t\t\tcallback(event.err);\n\t\t});\n\t};\n\n\treturn ret;\n};","\n$$.asset.describe(\"ACLScope\", {\n    public:{\n        concern:\"string:key\",\n        db:\"json\"\n    },\n    init:function(concern){\n        this.concern = concern;\n    },\n    addResourceParent : function(resourceId, parentId){\n\n    },\n    addZoneParent : function(zoneId, parentId){\n\n    },\n    grant :function(agentId,  resourceId){\n\n    },\n    allow :function(agentId,  resourceId){\n        return true;\n    }\n});","\n$$.asset.describe(\"Agent\", {\n    public:{\n        alias:\"string:key\",\n        publicKey:\"string\"\n    },\n    init:function(alias, value){\n        this.alias      = alias;\n        this.publicKey  = value;\n    },\n    update:function(value){\n        this.publicKey = value;\n    },\n    addAgent: function () {\n        throw new Error('Not Implemented');\n    },\n    listAgent: function () {\n        throw new Error('Not Implemented');\n\n    },\n    removeAgent: function () {\n        throw new Error('Not Implemented');\n\n    }\n});","\n$$.asset.describe(\"Backup\", {\n    public:{\n        id:  \"string\",\n        url: \"string\"\n    },\n\n    init:function(id, url){\n        this.id = id;\n        this.url = url;\n    }\n});\n","$$.asset.describe(\"BarAnchor\", {\n    public: {\n        alias: \"string\",\n        mountPoint: \"string\",\n        barMapDigest: \"string\",\n        readList: \"array\", //encrypted seeds with public keys\n        writeList: \"array\", //agentIds\n    },\n    init: function (mountPoint, barMapDigest) {\n        this.mountPoint = mountPoint;\n        this.barMapDigest = barMapDigest;\n    },\n    updateReadList: function (encryptedSeed) {\n        if (!this.readList) {\n            this.readList = [];\n        }\n        this.readList.push(encryptedSeed);\n    },\n    updateWriteList: function (agentId) {\n        if (!this.writeList) {\n            this.writeList = [];\n        }\n\n        this.writeList.push(agentId);\n    }\n});","\n$$.asset.describe(\"CSBMeta\", {\n\tpublic:{\n\t\tisMaster:\"string\",\n\t\talias:\"string:key\",\n\t\tdescription: \"string\",\n\t\tcreationDate: \"string\",\n\t\tupdatedDate : \"string\",\n\t\tid: \"string\",\n\t\ticon: \"string\"\n\t},\n\tinit:function(id){\n\t\tthis.alias = \"meta\";\n\t\tthis.id = id;\n\t},\n\n\tsetIsMaster: function (isMaster) {\n\t\tthis.isMaster = isMaster;\n\t}\n\n});\n","\n$$.asset.describe(\"DomainReference\", {\n    public:{\n        role:\"string:index\",\n        alias:\"string:key\",\n        addresses:\"map\",\n        constitution:\"string\",\n        workspace:\"string\",\n        remoteInterfaces:\"map\",\n        localInterfaces:\"map\",\n        communicationInterfaces: \"map\",\n        maximumNumberOfWorkers: \"number\",\n        workerStrategy: \"string\"\n    },\n    init:function(role, alias){\n        this.role = role;\n        this.alias = alias;\n        this.addresses = {};\n        this.remoteInterfaces = {};\n        this.localInterfaces = {};\n        this.communicationInterfaces = {};\n        this.workerStrategy = 'threads';\n    },\n    updateDomainAddress:function(replicationAgent, address){\n        if(!this.addresses){\n            this.addresses = {};\n        }\n        this.addresses[replicationAgent] = address;\n    },\n    removeDomainAddress:function(replicationAgent){\n        this.addresses[replicationAgent] = undefined;\n        delete this.addresses[replicationAgent];\n    },\n    addRemoteInterface:function(alias, remoteEndPoint){\n        if(!this.remoteInterfaces){\n            this.remoteInterfaces = {};\n        }\n        this.remoteInterfaces[alias] = remoteEndPoint;\n    },\n    removeRemoteInterface:function(alias){\n        if(this.remoteInterface){\n            this.remoteInterfaces[alias] = undefined;\n            delete this.remoteInterfaces[alias];\n        }\n    },\n    addLocalInterface:function(alias, path){\n        if(!this.localInterfaces){\n            this.localInterfaces = {};\n        }\n        this.localInterfaces[alias] = path;\n    },\n    removeLocalInterface:function(alias){\n        if(this.localInterfaces){\n            this.localInterfaces[alias] = undefined;\n            delete this.localInterfaces[alias];\n        }\n    },\n    setConstitution:function(pathOrUrlOrCSB){\n        this.constitution = pathOrUrlOrCSB;\n    },\n    getConstitution:function(){\n        return this.constitution;\n    },\n    setWorkspace:function(path){\n        this.workspace = path;\n    },\n    getWorkspace:function(){\n        return this.workspace;\n    },\n    addCommunicationInterface(alias, virtualMQEndpoint, zeroMQEndpoint) {\n        if (!this.communicationInterfaces) {\n            this.communicationInterfaces = {};\n        }\n        this.communicationInterfaces[alias] = {virtualMQ: virtualMQEndpoint, zeroMQ: zeroMQEndpoint};\n    },\n    setMaximumNumberOfWorkers: function(maximumNumberOfWorkers) {\n        this.maximumNumberOfWorkers = maximumNumberOfWorkers;\n    },\n    setWorkerStrategy: function(workerStrategy) {\n        this.workerStrategy = workerStrategy;\n    }\n});","$$.asset.describe(\"FileAnchor\", {\n    public: {\n        alias: \"string\",\n        mountPoint: \"string\",\n        digest: \"string\", //csb digest after file addition\n        readList: \"array\", //encrypted seeds with public keys\n        writeList: \"array\", //agentIds\n    },\n    init: function (mountPoint, digest) {\n        this.mountPoint = mountPoint;\n        this.digest = digest;\n    }\n});","\n$$.asset.describe(\"key\", {\n    public:{\n        alias:\"string\"\n    },\n    init:function(alias, value){\n        this.alias = alias;\n        this.value = value;\n    },\n    update:function(value){\n        this.value = value;\n    }\n});","module.exports = $$.library(function(){\n    require(\"./DomainReference\");\n    require(\"./Agent\");\n    require(\"./Backup\");\n    require(\"./ACLScope\");\n    require(\"./Key\");\n    require(\"../transactions/transactions\");\n    require(\"./BarAnchor\");\n    require(\"./FileAnchor\");\n    require('./CSBMeta');\n});","//const sharedPhases = require('./sharedPhases');\n\n$$.transaction.describe(\"Agents\", {\n    add: function (alias, publicKey) {\n        let agent = $$.blockchain.lookup(\"Agent\", alias);\n        if(!agent){\n            agent = $$.asset.start(\"Agent\", \"init\", alias, publicKey);\n        }else{\n            $$.exception(`Agent with ${alias} already exists!`);\n        }\n\n        this.transaction.add(agent);\n        this.commit();\n    }\n});\n","const sharedPhases = require('./sharedPhases');\n\n$$.transaction.describe(\"Domain\", {\n    add: function (alias, role, workspace, constitution, localInterface) {\n        let domain = this.transaction.lookup(\"DomainReference\", alias);\n\n        if(!domain){\n            domain = this.transaction.createAsset(\"DomainReference\", \"init\", role, alias);\n        }else{\n            $$.exception(`Domain with ${alias} already exists!`);\n        }\n\n        if(typeof workspace !== \"undefined\"){\n            domain.setWorkspace(workspace);\n        }\n\n        if(typeof constitution !== \"undefined\"){\n            domain.setConstitution(constitution);\n        }\n\n        if(typeof localInterface !== \"undefined\"){\n            domain.addLocalInterface('local', localInterface);\n        }\n\n        this.transaction.add(domain);\n        this.commit();\n    },\n    connectDomainLocally: function(alias, localInterface){\n        let domain = this.transaction.lookup(\"DomainReference\", alias);\n        domain.addLocalInterface('local', localInterface);\n\n        this.transaction.add(domain);\n        this.commit();\n    },\n    setWorkspaceForDomain: function(alias, workspace){\n        let domain = this.transaction.lookup(\"DomainReference\", alias);\n        domain.setWorkspace(workspace);\n\n        this.transaction.add(domain);\n        this.commit();\n    },\n    setConstitutionForDomain: function(alias, constitution){\n        let domain = this.transaction.lookup(\"DomainReference\", alias);\n        domain.setConstitution(constitution);\n\n        this.transaction.add(domain);\n        this.commit();\n    },\n    getDomainDetails:function(alias){\n        let domain = this.transaction.lookup(\"DomainReference\", alias);\n        return domain.toJson();\n    },\n    connectDomainToRemote(domainName, alias, remoteEndPoint){\n        let domain = this.transaction.lookup(\"DomainReference\", domainName);\n        domain.addRemoteInterface(alias, remoteEndPoint);\n\n        this.transaction.add(domain);\n        this.commit();\n    },\n    setWorkerStrategy: function (alias, workerStrategy) {\n        const domainReference =  this.transaction.lookup(\"DomainReference\", alias);\n        if(!domainReference) {\n            $$.exception(`Domain with alias ${alias} does not exist!`);\n        }\n\n        domainReference.setWorkerStrategy(workerStrategy);\n\n        this.transaction.add(domainReference);\n        this.commit();\n    },\n    setMaximumNumberOfWorkers: function (alias, maximumNumberOfWorkers) {\n        const domainReference =  this.transaction.lookup(\"DomainReference\", alias);\n        if(!domainReference) {\n            $$.exception(`Domain with alias ${alias} does not exist!`);\n        }\n\n        domainReference.setMaximumNumberOfWorkers(maximumNumberOfWorkers);\n\n        this.transaction.add(domainReference);\n        this.commit();\n    },\n    getDomainDetails: sharedPhases.getAssetFactory('global.DomainReference'),\n    getDomains: sharedPhases.getAllAssetsFactory('global.DomainReference')\n});\n","require('./domainTransaction');\nrequire('./agentTransaction');\nrequire('./standardCSBTransactions');","const beesHealer = require(\"swarmutils\").beesHealer;\n\nmodule.exports = {\n    getAssetFactory: function(assetType) {\n        return function(alias) {\n            const transaction = $$.blockchain.beginTransaction({});\n            const domainReferenceSwarm = transaction.lookup(assetType, alias);\n\n            if(!domainReferenceSwarm) {\n                this.return(new Error(`Could not find swarm named \"${assetType}\"`));\n                return;\n            }\n\n            this.return(undefined, beesHealer.asJSON(domainReferenceSwarm));\n        }\n    },\n    getAllAssetsFactory: function(assetType) {\n        return function() {\n            const transaction = $$.blockchain.beginTransaction({});\n            const domains = transaction.loadAssets(assetType) || [];\n\n            this.return(undefined, domains.map(domain => beesHealer.asJSON(domain)));\n        };\n    }\n};","$$.transaction.describe(\"StandardCSBTransactions\", {\n    addBarAnchor: function (mountPoint, barMapDigest) {\n        this.transaction.createAsset(\"BarAnchor\", \"init\", mountPoint, barMapDigest);\n        this.commit();\n    },\n\n    addFileAnchor: function (digest) {\n        this.transaction.createAsset(\"FileAnchor\", \"init\", digest);\n        this.commit();\n    }\n});","$$.transaction.describe(\"transactions\", {\n    updateKey: function (key, value) {\n        var transaction = $$.blockchain.beginTransaction(this);\n        var key = transction.lookup(\"Key\", key);\n        var keyPermissions = transaction.lookup(\"ACLScope\", \"KeysConcern\");\n        if (keyPermissions.allow(this.agentId, key)) {\n            key.update(value);\n            transaction.add(key);\n            $$.blockchain.commit(transaction);\n        } else {\n            this.securityError(\"Agent \" + this.agentId + \" denied to change key \" + key);\n        }\n    },\n    addChild: function (alias) {\n        var transaction = $$.blockchain.beginTransaction();\n        var reference = $$.contract.start(\"DomainReference\", \"init\", \"child\", alias);\n        transaction.add(reference);\n        $$.blockchain.commit(transaction);\n    },\n    addParent: function (value) {\n        var reference = $$.contract.start(\"DomainReference\", \"init\", \"child\", alias);\n        this.transaction.save(reference);\n        $$.blockchain.persist(this.transaction);\n    },\n    addAgent: function (alias, publicKey) {\n        var reference = $$.contract.start(\"Agent\", \"init\", alias, publicKey);\n        this.transaction.save(reference);\n        $$.blockchain.persist(this.transaction);\n    },\n    updateAgent: function (alias, publicKey) {\n        let agent = this.transaction.lookup(\"Agent\", alias);\n        agent.update(publicKey);\n        this.transaction.save(agent);\n        $$.blockchain.persist(this.transaction);\n    }\n});\n\n\n$$.newTransaction = function(transactionFlow,ctor,...args){\n    var transaction = $$.swarm.start( transactionFlow);\n    transaction.meta(\"agentId\", $$.currentAgentId);\n    transaction.meta(\"command\", \"runEveryWhere\")\n    transaction.meta(\"ctor\", ctor);\n    transaction.meta(\"args\", args);\n    transaction.sign();\n    //$$.blockchain.sendForConsent(transaction);\n    //temporary until consent layer is activated\n    transaction[ctor].apply(transaction,args);\n}\n\n/*\nusages:\n    $$.newTransaction(\"domain.transactions\", \"updateKey\", \"key\", \"value\")\n\n */\n","module.exports = {\n    ALIAS:\"alias\",\n    ALIASES : '/aliases',\n    SECURITY_PARADIGM:\"SecurityParadigm\",\n    RESTRICTED:\"Restricted\",\n    CONSTITUTIONAL:\"Constitutional\",\n    PREDICATIVE:\"Predicative\",\n    CTOR:\"ctor\",\n    COMMAND_ARGS:\"COMMAND_ARGS\",\n    SIGNING_AGENT:\"SIGNING_AGENT\",\n    INTIALISATION_CONTEXT:\"intialisationContext\",\n    SWARMID:\"swarmId\",\n    SWARMTYPE:\"swarmTypeName\"\n};","const beesHealer = require(\"swarmutils\").beesHealer;\nvar CNST = require(\"../moduleConstants\");\n\nfunction AliasIndex(assetType, pdsHandler, worldStateCache) {\n    this.create = function (alias, uid) {\n        const assetAliases = this.getAliases();\n\n        if (typeof assetAliases[alias] !== \"undefined\") {\n            $$.exception(`Alias ${alias} for assets of type ${assetType} already exists`);\n        }\n\n        assetAliases[alias] = uid;\n\n        worldStateCache.writeKey(assetType + CNST.ALIASES, J(assetAliases));\n    };\n\n    this.getUid = function (alias) {\n        const assetAliases = this.getAliases();\n        //console.log(\"assetAliases\", assetAliases);\n        return assetAliases[alias];\n    };\n\n    this.getAliases = function () {\n        let aliases = worldStateCache.readKey(assetType + CNST.ALIASES);\n        return aliases ? JSON.parse(aliases) : {};\n    }\n}\n\nfunction createLoadAssets(blockchain, pdsHandler, worldStateCache) {\n    return function (assetType) {\n        assetType = $$.fixSwarmName(assetType);\n        const assets = [];\n\n        const aliasIndex = new AliasIndex(assetType, pdsHandler, worldStateCache);\n        Object.keys(aliasIndex.getAliases()).forEach(alias => {\n            assets.push(blockchain.lookup(assetType, alias));\n        });\n\n        return assets;\n    };\n}\n\nfunction createLookup(blockchain, pdsHandler, SPRegistry, worldStateCache) {\n    function hasAliases(spaceName) {\n        let ret = !!worldStateCache.readKey(spaceName + CNST.ALIASES);\n        return ret;\n    }\n\n    return function (assetType, aid) { // aid == alias or id\n\n        let localUid = aid;\n        assetType = $$.fixSwarmName(assetType);\n\n        if (hasAliases(assetType)) {\n            const aliasIndex = new AliasIndex(assetType, pdsHandler, worldStateCache);\n            localUid = aliasIndex.getUid(aid) || aid;\n        }\n\n        const value = pdsHandler.readKey(assetType + '/' + localUid, true);\n\n        if (!value) {\n            $$.log(\"Lookup fail, asset not found: \", assetType, \" with alias\", aid, value);\n            //pdsHandler.dump();\n            //return $$.asset.start(assetType);\n            return null;\n        } else {\n            const asset = $$.asset.continue(assetType, JSON.parse(value));\n            asset.__reinit(blockchain);\n            return asset;\n        }\n    };\n}\n\nfunction Blockchain(pskdb, consensusAlgorithm, worldStateCache, signatureProvider) {\n    let spr = require(\"./securityParadigms/securityParadigmRegistry\").getRegistry(this);\n    let self = this;\n\n    consensusAlgorithm.setPSKDB(pskdb);\n\n    this.beginTransaction = function (transactionSwarm, handler) {\n        if (!transactionSwarm) {\n            $$.exception(\"Can't begin a transaction outside of a swarm instance from transactions namespace\");\n        }\n        if (!handler) {\n            handler = pskdb.getHandler();\n        }\n        return new Transaction(self, handler, transactionSwarm, worldStateCache, spr);\n    };\n\n\n    this.start = function (reportBootingFinishedCallback) {\n        pskdb.initialise(function (err, res) {\n            reportBootingFinishedCallback(err, self);\n        });\n    };\n\n\n    this.lookup = function (assetType, aid) {\n        let newLookup = createLookup(self, pskdb.getHandler(), spr, worldStateCache);\n        return newLookup(assetType, aid);\n    };\n\n    this.loadAssets = createLoadAssets(self, pskdb.getHandler(), worldStateCache);\n\n    this.getSPRegistry = function () {\n        return spr;\n    };\n\n    this.signAs = function (agentId, msg) {\n        return signatureProvider.signAs(agentId, msg);\n    };\n\n    this.verifySignature = function (msg, signatures) {\n        return signatureProvider.verify(msg, signatures);\n    };\n\n\n    this.registerSecurityParadigm = function (SPName, apiName, factory) {\n        return spr.register(SPName, apiName, factory);\n    };\n\n\n    this.startCommandAs = function (agentId, transactionSwarmType, ...args) {\n        const bm = require('blockchain');\n        let t = bm.createCRTransaction(transactionSwarmType, args, null, null, consensusAlgorithm.getCurrentPulse());\n        t.signatures = [this.signAs(agentId, t.digest)];\n        consensusAlgorithm.commit(t);\n    };\n\n    this.startTransactionAs = function (agentId, transactionSwarmType, ...args) {\n        let swarm = $$.transaction.startWithContext(self, transactionSwarmType, ...args);\n        swarm.setMetadata(CNST.COMMAND_ARGS, args);\n        swarm.setMetadata(CNST.SIGNING_AGENT, agentId);\n        return swarm;\n        //console.log(swarm);\n    };\n\n    this.commit = function (transaction) {\n        let swarm = transaction.getSwarm();\n        let handler = transaction.getHandler();\n        const diff = handler.computeSwarmTransactionDiff(swarm);\n        //console.log(\"Diff is\", diff.output);\n        const bm = require('blockchain');\n        const t = bm.createCRTransaction(swarm.getMetadata(\"swarmTypeName\"), swarm.getMetadata(CNST.COMMAND_ARGS), diff.input, diff.output, consensusAlgorithm.getCurrentPulse());\n        t.signatures = [self.signAs(swarm.getMetadata(CNST.SIGNING_AGENT), t.digest)];\n        consensusAlgorithm.commit(t, (err, status) => {\n            swarm.notify({err});\n        });\n    };\n\n    this.dump = function () {\n        pskdb.getHandler().dump();\n    };\n}\n\nfunction Transaction(blockchain, pdsHandler, transactionSwarm, worldStateCache, spr) {\n\n    let self = this;\n\n    this.getSwarm = function () {\n        return transactionSwarm;\n    };\n\n    this.getHandler = function () {\n        return pdsHandler;\n    };\n\n    this.add = function (asset) {\n        const swarmTypeName = asset.getMetadata('swarmTypeName');\n        const swarmId = asset.getMetadata('swarmId');\n\n        const aliasIndex = new AliasIndex(swarmTypeName, pdsHandler, worldStateCache);\n        if (asset.alias && aliasIndex.getUid(asset.alias) !== swarmId) {\n            aliasIndex.create(asset.alias, swarmId);\n        }\n\n\n        const serializedSwarm = beesHealer.asJSON(asset, null, null);\n        pdsHandler.writeKey(swarmTypeName + '/' + swarmId, J(serializedSwarm));\n    };\n\n    this.lookup = createLookup(blockchain, pdsHandler, spr, worldStateCache);\n\n    this.loadAssets = createLoadAssets(blockchain, pdsHandler, worldStateCache);\n\n    this.createAsset = function (swarmTypeName, ctor, ...args) {\n        let asset = $$.assets.startWithContext(blockchain, swarmTypeName, ctor, ...args);\n        this.add(asset);\n        return asset;\n    };\n\n    this.reviveAsset = function (assetValue) {\n        let asset = $$.assets.continue(assetValue);\n        asset.__reinit(self);\n        return asset;\n    };\n\n\n    this.commit = function () {\n        blockchain.commit(self);\n    };\n}\n\nmodule.exports = Blockchain;","const Blockchain = require('./Blockchain');\n\nmodule.exports = {\n    startDB: function (worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution) {\n        if(loadDefaultConstitution){\n            require('../defaultConstitution/assets/index');\n            require('../defaultConstitution/transactions/index');\n        }\n        let pds = require('./pskdb').newPSKDB(worldStateCache, historyStorage);\n        consensusAlgorithm.pskdb = pds;\n        let blockchain = new Blockchain(pds, consensusAlgorithm, worldStateCache, signatureProvider);\n        pds.blockchain = blockchain;\n        return blockchain;\n    },\n    startDefaultDB: function (worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution, forceReboot) {\n        if ($$.blockchain && !forceReboot) {\n            $$.exception('$$.blockchain is already defined. Throwing an exception!');\n        }\n        if(!worldStateCache || !historyStorage || !consensusAlgorithm || !signatureProvider){\n            console.error(\"Initialisation failed with arguments:\", worldStateCache, historyStorage, consensusAlgorithm, signatureProvider);\n            $$.exception('$$.blockchain initialisation failed! Throwing an exception!');\n        }\n        $$.blockchain = this.startDB(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution);\n        return $$.blockchain;\n    }\n};\n","let CNST = require(\"../moduleConstants\");\n//let cutil = require(\"../OBFT/transactionsUtil\");\n//let bm = require(\"../index\");\n\n//var ssutil  = require(\"pskcrypto\");\n\nfunction orderCRTransactions(pset) { //order in place the pset array\n    var arr = [];\n    for (let d in pset) {\n        arr.push(pset[d]);\n    }\n\n    arr.sort(function (t1, t2) {\n        if (t1.transactionPulse < t2.transactionPulse) return -1;\n        if (t1.transactionPulse > t2.transactionPulse) return 1;\n        if (t1.second < t2.second) return -1;\n        if (t1.second > t2.second) return 1;\n        if (t1.nanosecod < t2.nanosecod) return -1;\n        if (t1.nanosecod > t2.nanosecod) return 1;\n        if (t1.digest < t2.digest) return -1;\n        if (t1.digest > t2.digest) return 1;\n        return 0; //only for identical transactions...\n    })\n    return arr;\n}\n\nfunction KeyValueDBWithVersions(worldStateCache) { //main storage\n    let cset = {};  // contains all keys\n    let keyVersions = {};  //will store versions\n    let self = this;\n\n    this.dump = function () {\n        //console.log(\"Main Storage\", {keyVersions,cset})\n        worldStateCache.dump();\n    };\n\n    this.readKey = function (keyName, mandatoryToExist) {\n        if (keyVersions.hasOwnProperty(keyName)) {\n            return cset[keyName];\n        }\n        if (mandatoryToExist) {\n            keyVersions[keyName] = 0;\n        }\n        return undefined;\n    };\n\n    this.writeKey = function (keyName, value, newVersion) {\n\n        if (keyVersions.hasOwnProperty(keyName)) {\n            if (!newVersion) {\n                keyVersions[keyName]++;\n            } else {\n                keyVersions[keyName] = newVersion;\n            }\n        } else {\n            keyVersions[keyName] = 0;\n        }\n        cset[keyName] = value;\n    };\n\n    this.version = function (keyName) {\n        if (keyVersions.hasOwnProperty(keyName)) {\n            return keyVersions[keyName];\n        }\n        return undefined;\n    };\n\n    this.getInternalValues = function (currentPulse) {\n        return {\n            cset,\n            versions: keyVersions,\n            currentPulse\n        }\n    }\n}\n\nfunction DBTransactionHandler(parentStorage) {\n    let readSetVersions = {}; //version of a key when read first time\n    let writeSet = {};  //contains only keys modified in handlers\n\n    this.dump = function () {\n        console.log(\"DBTransactionHandler:\", {readSetVersions, writeSet});\n        parentStorage.dump();\n    };\n\n    this.readKey = function (keyName, mandatoryToExist) {\n        function internalReadKey() {\n            if (readSetVersions.hasOwnProperty(keyName)) {\n                return writeSet[keyName];\n            }\n            let version = parentStorage.version(keyName);\n            if (version != undefined) {\n                readSetVersions[keyName] = version;\n            }\n            return parentStorage.readKey(keyName);\n        }\n\n        let result = internalReadKey();\n        //writeSet[keyName] = result;\n\n        /*\n        if(mandatoryToExist){\n            console.debug(\"Looking for \", keyName, \" Version:\", parentStorage.version(keyName), \"Result:\", result);\n        }\n        if(!result && mandatoryToExist){\n            console.error(\"Found nothing for\", keyName, \"Key Version:\", parentStorage.version(keyName));\n            this.dump();\n            $$.exception(\"Mandatory key not found:\" + keyName);\n        }*/\n        return result;\n    };\n\n    this.writeKey = function (keyName, value) {\n        this.readKey(keyName);         //save read version\n        writeSet[keyName] = value;\n    };\n\n    this.computeSwarmTransactionDiff = function () {\n        return {\n            input: readSetVersions,\n            output: writeSet\n        };\n    };\n}\n\n\nfunction PSKDB(worldStateCache, historyStorage) {\n    this.blockchain = undefined;\n    let mainStorage = new KeyValueDBWithVersions(worldStateCache);\n    let self = this;\n\n    let currentPulse = 0;\n    let hashOfLatestCommittedBlock = \"Genesis Block\";\n\n    this.getHandler = function () { // the single way of working with pskdb\n        let tempStorage = new DBTransactionHandler(mainStorage);\n        return tempStorage;\n    };\n\n    this.getCurrentPulse = function () {\n        return currentPulse;\n    };\n\n    this.setCurrentPulse = function (cp) {\n        currentPulse = cp;\n    };\n\n    this.getPreviousHash = function () {\n        return hashOfLatestCommittedBlock;\n    };\n\n    this.initialise = function (reportResultCallback) {\n        let gotLatestBlock_done = false;\n        let gotState_done = false;\n        let lbn = 0;\n        let state = 0;\n        let cp = 0;\n\n        function loadNextBlock() {\n            if (cp > lbn) {\n                if (lbn != 0) {\n                    currentPulse = cp;\n                }\n                reportResultCallback(null, lbn);\n            } else {\n                historyStorage.loadSpecificBlock(cp, function (err, block) {\n                    if (block) {\n                        self.commitBlock(block, true);\n                        cp = block.pulse;\n                    }\n                    cp++;\n                    loadNextBlock();\n                })\n            }\n        }\n\n        function loadMissingBlocksFromHistory() {\n            if (gotState_done && gotLatestBlock_done) {\n                if (state && state.pulse) {\n                    cp = state.pulse;\n                }\n                console.log(\"Reloading from cache at pulse \", cp, \"and rebuilding state until pulse\", lbn);\n                if (state.pulse) {\n                    mainStorage.initialiseInternalValue(state);\n                }\n                loadNextBlock();\n            }\n        }\n\n        function gotLatestBlock(err, val) {\n            gotLatestBlock_done = true;\n            if (!err) {\n                lbn = val;\n            }\n            loadMissingBlocksFromHistory();\n        }\n\n        function gotState(err, val) {\n            gotState_done = true;\n\n            if (!err) {\n                state = val;\n            }\n            if (state.latestBlockHash) {\n                hashOfLatestCommittedBlock = state.latestBlockHash;\n            }\n            loadMissingBlocksFromHistory();\n        }\n\n        worldStateCache.getState(gotState);\n        historyStorage.getLatestBlockNumber(gotLatestBlock);\n    };\n\n\n    this.commitBlock = function (block, doNotSaveHistory, callback) {\n        let blockSet = block.blockset;\n        currentPulse = block.pulse;\n\n        let verificationKeySpace = new VerificationKeySpaceHandler(mainStorage, worldStateCache, this.blockchain);\n\n        verificationKeySpace.commit(blockSet);\n\n        hashOfLatestCommittedBlock = block.hash;\n        if (!doNotSaveHistory) {\n            historyStorage.appendBlock(block, false, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                __updateState();\n            });\n        } else {\n            __updateState()\n        }\n\n        function __updateState() {\n            let internalValues = mainStorage.getInternalValues(currentPulse);\n            internalValues.latestBlockHash = block.hash;\n            worldStateCache.updateState(internalValues, callback);\n        }\n    };\n\n    this.computePTBlock = function (nextBlockSet) {\n        let tempStorage = new VerificationKeySpaceHandler(mainStorage, worldStateCache, blockchain);\n        return tempStorage.computePTBlock(nextBlockSet);\n    };\n\n    /* Verification Space Digest is now the hash of the latest commited block*/\n    this.getHashLatestBlock = historyStorage.getHashLatestBlock;\n}\n\nlet lec = require(\"./securityParadigms/localExecutionCache\");\n\n/* play the role of DBTransactionHandler (readKey, writeKey) while also doing transaction validation*/\nfunction VerificationKeySpaceHandler(parentStorage, worldStateCache, blockchain) {\n    let readSetVersions = {}; //version of a key when read first time\n    let writeSetVersions = {}; //increment version with each writeKey\n    let writeSet = {};  //contains only keys modified in handlers\n    let self = this;\n\n    let aliases = {};\n\n    this.dump = function () {\n        console.log(\"VerificationKeySpaceHandler:\", {readSetVersions, writeSetVersions, writeSet});\n        parentStorage.dump();\n    };\n\n\n    this.readKey = function (keyName) {\n        if (writeSetVersions.hasOwnProperty(keyName)) {\n            return writeSet[keyName];\n        }\n        readSetVersions[keyName] = parentStorage.version(keyName);\n        return parentStorage.readKey(keyName);\n    };\n\n    this.saveAlias = function (assetType, alias, swarmId) {\n        aliases[swarmId] = {assetType, alias};\n    };\n\n    this.writeKey = function (keyName, value) {\n        this.readKey(keyName);         //save read version\n        if (!writeSetVersions.hasOwnProperty(keyName)) {\n            writeSetVersions[keyName] = readSetVersions[keyName];\n        }\n        writeSetVersions[keyName]++;\n        writeSet[keyName] = value;\n    };\n\n    this.version = function (keyName) {\n        if (writeSetVersions.hasOwnProperty(keyName)) {\n            return writeSetVersions[keyName];\n        }\n        return parentStorage.version(keyName);\n    };\n\n    function applyTransaction(t, willBeCommited) {\n        let ret = true;\n        lec.ensureEventTransaction(t);\n        for (let k in t.input) {\n            let transactionVersion = t.input[k];\n            if (transactionVersion == undefined) {\n                transactionVersion = 0;\n            }\n            let currentVersion = self.version(k);\n            if (currentVersion == undefined || currentVersion == null) {\n                currentVersion = 0;\n            }\n            if (transactionVersion != currentVersion) {\n                //console.log(k, transactionVersion , currentVersion);\n                //ret = \"Failed to apply in transactionVersion != currentVersion (\" + transactionVersion + \"!=\"+ currentVersion + \")\";\n                return false;\n            }\n        }\n\n        //TODO: potential double spending bug if a transaction was replaced\n        if (!lec.verifyTransaction(t, self, willBeCommited, blockchain)) {\n            return false;\n        }\n\n        for (let k in t.output) {\n            self.writeKey(k, t.output[k]);\n        }\n\n        /* who has this responsability?\n        if(willBeCommited){\n            lec.removeFromCacheAtCommit(t);\n        }*/\n        return ret;\n    }\n\n    this.computePTBlock = function (nextBlockSet) {   //make a transactions block from nextBlockSet by removing invalid transactions from the key versions point of view\n        let validBlock = [];\n        let orderedByTime = orderCRTransactions(nextBlockSet);\n        let i = 0;\n\n        while (i < orderedByTime.length) {\n            let t = orderedByTime[i];\n            if (applyTransaction(t)) {\n                validBlock.push(t.digest);\n            }\n            i++;\n        }\n\n\n        return validBlock;\n    };\n\n    this.commit = function (blockSet, reportDropping) {\n        let i = 0;\n        let orderedByTime = orderCRTransactions(blockSet);\n\n        while (i < orderedByTime.length) {\n            let t = orderedByTime[i];\n            if (applyTransaction(t, true) && reportDropping) {\n                $$.log(\"Dropping transaction\", t);\n            }\n\n            i++;\n        }\n\n        for (let v in writeSetVersions) {\n            parentStorage.writeKey(v, writeSet[v], writeSetVersions[v]);\n        }\n\n        worldStateCache.updateAliases(aliases);\n    }\n}\n\n\nexports.newPSKDB = function (worldStateCache, historyStorage) {\n    return new PSKDB(worldStateCache, historyStorage);\n};","let CNST=require(\"../../moduleConstants\");\nlet cache = {};\n\nlet alreadyVerified = {\n\n};\n\nfunction sandBoxedExecution(cet){\n    let transactionType = cet.swarmType;\n    $$.transactions.start(\"\")\n}\n\nmodule.exports = {\n    ensureEventTransaction:function(cetransaction){\n        return cetransaction;\n    },\n    verifyTransaction:function(t, handler, forceDeepVerification, blockchain){\n\n        //todo: to be removed later; modification done in the same time with the mod in pskdb\n        return true;\n\n        let old_assets = {};\n        let new_assets = {};\n        let fastCheck = true;\n\n        if(!forceDeepVerification){\n            let t = cache[t.digest];\n            if(typeof t != undefined) return true;\n        }\n\n        for(let k in t.output){\n            new_assets[k] = {};\n            old_assets[k] = {};\n\n            let  old_value = handler.readKey(k);\n            let  new_value = t.output[k];\n\n            let assetValue = JSON.parse(new_value);\n\n            let asset = $$.assets.continue(assetValue);\n            asset.__reinit(blockchain);\n\n            new_assets[k][asset.getSwarmId()] = asset;\n            handler.saveAlias(asset.getSwarmType(), asset.alias, asset.getSwarmId());\n\n            if(old_value !== undefined){\n                /* undefined for new asset (did not exist before current transaction)*/\n                let assetValue = JSON.parse(old_value);\n                let asset = $$.assets.continue(assetValue);\n                asset.__reinit(blockchain);\n                if(asset.securityParadigm.mainParadigm == CNST.CONSTITUTIONAL){\n                    fastCheck = false;\n                }\n                old_assets[k][asset.getSwarmId()] = asset;;\n            }\n            //else ... force constitutional checks?\n        }\n\n        return true; //TODO: implement proper checks\n\n        if(fastCheck){\n            //check the signatures or other rules specified in security paradigms\n        } else {\n            //execute transaction again and see if the results are identical\n        }\n        cache[t.digest] = t;\n        return true;\n    },\n    removeFromCacheAtCommit:function(t){\n        delete alreadyVerified[t.digest];\n        delete cache[t.digest];\n    }\n};\n","\nvar CNST = require(\"../../moduleConstants\");\n\nfunction ConstitutionalSPFactory(){\n     this.constitutional = function(spm, optionalTransactionName){\n         spm.mainParadigm = CNST.CONSTITUTIONAL;\n         if(optionalTransactionName){\n             spm.data[CNST.CONSTITUTIONAL] = optionalTransactionName;\n             $$.notImplemented(\"optionalTransactionName is not properly implemented yet\")\n         }\n         //spm.addSecurityParadigm(CNST.CONSTITUTIONAL ,optionalTransactionName);\n     }\n\n    /* we do not instantiate SPs... but anyway it behaves as some sort of factory in an virtual way of instantiation*/\n    this.checkInsideTransactionValidation = function(transaction, asset){\n\n    }\n}\n\nfunction PredicativeSPFactory(){\n    let predicates = {};\n    this.addPredicate = function(spm, predicateName, predicateDefinition){\n        predicates[predicateName] = predicateDefinition;\n        spm.mainParadigm = CNST.PREDICATIVE;\n        spm.data[CNST.PREDICATIVE] = predicateName;\n    }\n    /* not allowed for now... maybe in future*/\n    this.registerPredicate = function(predicateName, predicateFunction){\n\n    }\n\n    /* */\n    this.checkInsideTransactionValidation = function(transaction, asset){\n\n    }\n}\n\nfunction RestrictedSPFactory(){\n    this.allow = function(spm, agentId){\n        spm.mainParadigm = CNST.RESTRICTED;\n        if(!spm.data[CNST.RESTRICTED]) {\n            spm.data[CNST.RESTRICTED] = [agentId];\n        } else {\n            spm.data[CNST.RESTRICTED].push(agentId);\n        }\n    }\n\n    this.checkInsideTransactionValidation = function(transaction, asset){\n\n    }\n\n}\n\n\nfunction mkApi(sp, APIName, factory){\n    return function(...args){\n        return factory[APIName](sp, ...args);\n    }\n}\n\nfunction SecurityParadigmMetadata(assetInstance,metaData, apiNames, allFactories){\n    if(metaData != undefined){\n        for(let v in metaData){\n            this[v] =  metaData[v];\n        }\n    } else {\n        this.mainParadigm = CNST.RESTRICTED;\n        this.data = {};\n    }\n\n    //could be refined to add better restrictions\n    for(let v in apiNames){\n        this[apiNames[v]] = mkApi(this, apiNames[v], allFactories[v]);\n    }\n    assetInstance.setMetadata(\"SecurityParadigm\", this);\n}\n\n\nfunction Registry(blockchain){\n    let allFactories = {};\n    let apiNames = {};\n    let self = this;\n    this.register = function (SPName, apiName, factory) {\n        allFactories[SPName]         = factory;\n        apiNames[SPName]    = apiName;\n    }\n\n    this.getSecurityParadigm = function(assetInstance){\n        let  metaData = assetInstance.getMetadata(CNST.SECURITY_PARADIGM);\n        return new SecurityParadigmMetadata(assetInstance, metaData, apiNames, allFactories);\n    }\n\n    self.register(CNST.CONSTITUTIONAL ,\"constitutional\", new ConstitutionalSPFactory());\n    self.register(CNST.RESTRICTED,\"allow\", new RestrictedSPFactory());\n    self.register(CNST.PREDICATIVE ,\"addPredicate\", new PredicativeSPFactory());\n\n    this.validateTransaction = function(currentLayer, transaction){\n\n    }\n}\n\nmodule.exports = {\n    getRegistry: function () {\n        /* normally should be called only once, made it more open for tests only...*/\n        return new Registry();\n    }\n}","let pskcrypto = require(\"pskcrypto\");\nlet fs = require(\"fs\");\n\nlet consUtil = require(\"../OBFT/transactionsUtil\");\n\nlet detailedDebug = false;\n\n\nlet pulseSwarm = $$.flow.describe(\"pulseSwarm\", {\n    start: function (delegatedAgentName, communicationOutlet, pdsAdapter, pulsePeriodicity, votingBox) {\n\n        this.lset = {}; // digest -> transaction - localy generated set of transactions (`createTransactionFromSwarm` stores each transaction; `beat` resets `lset`)\n        this.dset = {}; // digest -> transaction - remotely delivered set of transactions that will be next participate in consensus\n        this.pset = {}; // digest -> transaction - consensus pending set\n\n        this.currentPulse = 0;\n        this.topPulseConsensus = 0;\n        this.lastPulseAchievedConsensus = 0;\n\n        this.pulsesHistory = {};\n\n        this.vsd = pdsAdapter.getHashLatestBlock();\n\n\n        this.commitCounter = 0;                 // total  number of transactions that got commited\n\n        this.nodeName               = delegatedAgentName;\n        this.communicationOutlet    = communicationOutlet;\n        this.pdsAdapter             = pdsAdapter;\n        this.pulsePeriodicity       = pulsePeriodicity;\n        this.votingBox              = votingBox;\n\n        this.beat();\n    },\n\n    beat: function () {\n        let ptBlock = null;\n        let nextConsensusPulse = this.topPulseConsensus + 1;\n        let majoritarianVSD = \"none\";\n\n        while (nextConsensusPulse <= this.currentPulse) {\n            ptBlock = consUtil.detectMajoritarianPTBlock(nextConsensusPulse, this.pulsesHistory, this.votingBox);\n            majoritarianVSD = consUtil.detectMajoritarianVSD(nextConsensusPulse, this.pulsesHistory, this.votingBox);\n\n            if (ptBlock != \"none\" && this.vsd == majoritarianVSD) {\n                if (!this.hasAllTransactions(ptBlock)) {\n                    this.print(\"Unknown transactions detected...\")\n                    break;\n                }\n                //console.log(this.nodeName, ptBlock.length,this.vsd, majoritarianVSD, nextConsensusPulse);\n                if (ptBlock.length /*&& this.hasAllTransactions(ptBlock)*/) {\n                    this.pset = consUtil.setsConcat(this.pset, this.dset);\n                    this.dset = {};\n                    let resultSet = consUtil.makeSetFromBlock(this.pset, ptBlock);\n\n                    this.commitCounter += ptBlock.length;\n                    //this.print(\"\\t\\tBlock [\" + this.dumpPtBlock(ptBlock) + \"] at pulse \" + nextConsensusPulse + \" and VSD \" +  this.vsd.slice(0,8));\n\n                    this.pdsAdapter.commit(resultSet);\n                    let topDigest = ptBlock[ptBlock.length - 1];\n                    this.topPulseConsensus = this.pset[topDigest].transactionPulse;\n                    consUtil.setsRemovePtBlockAndPastTransactions(this.pset, ptBlock, this.topPulseConsensus); //cleanings\n                    let oldVsd = this.vsd;\n                    this.vsd = this.pdsAdapter.getVSD();\n\n                    this.lastPulseAchievedConsensus = nextConsensusPulse;   //safer than `this.currentPulse`!?\n                    //this.topPulseConsensus = nextConsensusPulse;\n\n                    this.print(\"\\t\\t consensus at pulse \" + nextConsensusPulse + \" and VSD \" + oldVsd.slice(0, 8));\n                } else {\n                    this.pset = consUtil.setsConcat(this.pset, this.dset);\n                    this.dset = {};\n                    this.lastPulseAchievedConsensus = nextConsensusPulse;   //safer than `this.currentPulse`!?\n                    this.topPulseConsensus = nextConsensusPulse;\n                    //this.print(\"\\t\\tEmpty \" + \" at: \" + nextConsensusPulse );\n                    //console.log(\"\\t\\tmajoritarian \", majoritarianVSD.slice(0,8) , nextConsensusPulse);\n                }\n                break; //exit WHILE\n\n            } //end if (ptBlock != \"none\" && this.vsd == majoritarianVSD)\n\n            nextConsensusPulse++;\n        } //end while\n\n\n        //daca nu a reusit,ar trebui sa vada daca nu exista un alt last majoritar\n        ptBlock = this.pdsAdapter.computePTBlock(this.pset);\n\n        let newPulse = consUtil.createPulse(\n            this.nodeName,                          //==> Pulse.signer\n            this.currentPulse,\n            ptBlock,\n            this.lset,\n            this.vsd,\n            this.topPulseConsensus,\n            this.lastPulseAchievedConsensus);\n\n        //console.log(\"\\t\\tPulse\", this.nodeName, this.vsd.slice(0,8) );\n        //this.print(\"Pulse\" );\n        this.recordPulse(newPulse);\n\n        let self = this;\n        self.communicationOutlet.broadcastPulse(newPulse);\n        \n        this.lset = {};\n        this.currentPulse++;\n\n        setTimeout(this.beat, this.pulsePeriodicity);   //self invocation of phase `beat`\n    },\n    hasAllTransactions: function (ptBlock) {\n        for (let i = 0; i < ptBlock.length; i++) {\n            let item = ptBlock[i];\n            if (!this.pset.hasOwnProperty(item)) {\n                //TODO: ask for the missing transaction\n                return false;\n            }\n        }\n        return true;\n    },\n    receiveTransaction: function (t) {\n        this.lset[t.digest] = t;\n        return t;\n    },\n    /**\n     *\n     * @param {Pulse} pulse e.g. new Pulse(this.nodeName, this.currentPulse, ......)\n     */\n    recordPulse: function (pulse) {\n        let from = pulse.signer;\n\n        if (!pulse.ptBlock) {\n            pulse.ptBlock = [];\n        }\n        //pulse.blockDigest = pskcrypto.hashValues(pulse.ptBlock);\n        //pulse.blockDigest = pulse.ptBlock.blockDigest;\n\n        if (!this.pulsesHistory[pulse.currentPulse]) {\n            this.pulsesHistory[pulse.currentPulse] = {};\n        }\n        this.pulsesHistory[pulse.currentPulse][from] = pulse;\n\n        if(pulse.currentPulse >= this.topPulseConsensus) {\n            if (pulse.currentPulse <= this.lastPulseAchievedConsensus) {\n                for (let d in pulse.lset) {\n                    this.pset[d] = pulse.lset[d];// could still be important for consensus\n                }\n            } else {\n                for (let d in pulse.lset) {\n                    this.dset[d] = pulse.lset[d];\n                }\n            }\n        }\n        //TODO: ask for pulses that others received but we failed to receive\n    },\n\n    dumpPtBlock: function (ptBlock) {\n        return ptBlock.map(function (item) {\n            return item.slice(0, 8);\n        }).join(\" \");\n    },\n    dump: function () {\n        // this.print(\"Final\");\n    },\n    print: function (str) {\n        if (!detailedDebug) {\n            if (str === \"Pulse\") return;\n        }\n\n        if (!str) {\n            str = \"State \"\n        }\n\n        function countSet(set) {\n            let l = 0;\n            for (let v in set) l++;\n            return l;\n        }\n\n        console.log(this.nodeName, \" | \", str, \" | \",\n            \"currentPulse:\", this.currentPulse, \"top:\", this.topPulseConsensus, \"LPAC:\", this.lastPulseAchievedConsensus, \"VSD:\", this.vsd.slice(0, 8),\n            \" | \", countSet(this.pset), countSet(this.dset), countSet(this.lset),\n            \" | \", this.commitCounter / GLOBAL_MAX_TRANSACTION_TIME, \" tranzactii pe secunda. Total tranzactii comise:\", this.commitCounter);\n\n    },\n    printState: function () {\n        console.log(this.nodeName, \",\", this.currentPulse, \",\", this.vsd);\n    },\n    printPset: function () {\n        function sortedDigests(set) {\n            let res = [];\n            for (let d in set) {\n                res.push(d);\n            }\n            return pskcrypto.hashValues(res.sort());\n        }\n        function appendToCSV(filename, arr) {\n            const reducer = (accumulator, currentValue) => accumulator + \" , \" + currentValue;\n            let str = arr.reduce(reducer, \"\") + \"\\n\";\n            fs.appendFileSync(filename, str);\n        }\n\n        let arr = [\n            this.nodeName,\n            this.currentPulse,\n            this.topPulseConsensus,\n            this.lastPulseAchievedConsensus,\n            sortedDigests(this.pset),\n            sortedDigests(this.dset),\n            sortedDigests(this.lset),\n            this.vsd\n        ];\n        appendToCSV(\"data.csv\", arr);\n        // console.log(this.nodeName,\",\",this.currentPulse,\",\",Object.keys(this.pset).length);\n    }\n});\n\n\n/**\n * @param {String} delegatedAgentName e.g. 'Node 0', or 'agent_007'\n * @param {Object} communicationOutlet e.g. object to be used in phase `beat` of the returned \"pulseSwarm\" flow\n *  - it should have a property: `broadcastPulse`: function(from, pulse) {...}\n *      - {String} `from` e.g. `delegatedAgentName`\n *      - {Pulse} `pulse` (see 'transactionsUtil.js')\n * @param {InMemoryPDS} pdsAdapter e.g. require(\"pskdb/lib/InMemoryPDS\").newPDS(null);\n * @param {Number} pulsePeriodicity e.g. 300\n * \n * @returns {SwarmDescription} A new instance of \"pulseSwarm\" flow, with phase `start` already running\n */\nexports.createConsensusManager = function (delegatedAgentName, communicationOutlet, pdsAdapter, pulsePeriodicity, votingBox) {\n    let instance = pulseSwarm();\n    instance.start(delegatedAgentName, communicationOutlet, pdsAdapter, pulsePeriodicity, votingBox);\n    return instance;\n}\n","function DirectCommitAlgorithm() {\n    var mod = require(\"blockchain\");\n    let pskdb = null;\n    this.setPSKDB = function (_pskdb) {\n        pskdb = _pskdb;\n    };\n    this.commit = function (transaction, callback) {\n        const set = {};\n        let cp = this.pskdb.getCurrentPulse();\n        set[transaction.digest] = transaction;\n        this.pskdb.commitBlock(mod.createBlock(set, cp, this.pskdb.getPreviousHash()), false, (err) => {\n            if (err) {\n                return callback(err);\n            }\n\n            cp++;\n            this.pskdb.setCurrentPulse(cp);\n            callback();\n        });\n    };\n\n    this.getCurrentPulse = function () {\n        return this.pskdb.getCurrentPulse();\n    }\n}\n\n\nfunction SignSensusAlgoritm(nodeName, networkImplementation, pulsePeriodicity, votingBox) {\n    let pskdb = null;\n    let algorithm = null;\n    this.setPSKDB = function (_pskdb) {\n        pskdb = _pskdb;\n        algorithm = require(\"../../signsensus/SignSensusImplementation\").createConsensusManager(nodeName, networkImplementation, pskdb, pulsePeriodicity, votingBox);\n        this.recordPulse = algorithm.recordPulse;\n        console.log(\"Setting pskdb for algorithm\")\n    };\n\n    this.commit = function (transaction) {\n        algorithm.sendLocalTransactionToConsensus(transaction);\n    };\n\n    this.getCurrentPulse = function () {\n        return algorithm.currentPulse;\n    }\n}\n\n\nfunction OBFTAlgoritm(nodeName, networkImplementation, pulsePeriodicity, latency, votingBox) {\n    let pskdb = null;\n    let algorithm = null;\n    this.setPSKDB = function (_pskdb) {\n        pskdb = _pskdb;\n        algorithm = require(\"../../OBFT/OBFTImplementation\").createConsensusManager(nodeName, networkImplementation, pskdb, pulsePeriodicity, latency, votingBox);\n        this.recordPulse = algorithm.recordPulse;\n        console.log(\"Setting pskdb for algorithm\")\n    };\n\n    this.commit = function (transaction) {\n        algorithm.sendLocalTransactionToConsensus(transaction);\n    };\n\n    this.getCurrentPulse = function () {\n        return algorithm.currentPulse;\n    }\n}\n\nmodule.exports = {\n    createAlgorithm: function (name, ...args) {\n        switch (name) {\n            case \"direct\":\n                return new DirectCommitAlgorithm(...args);\n            case \"SignSensus\":\n                return new SignSensusAlgoritm(...args);\n            case \"OBFT\":\n                return new OBFTAlgoritm(...args);\n            default:\n                $$.exception(\"Unknown consensus algortihm  \" + name);\n        }\n    }\n};","const LatestHashTracker = require(\"./LatestHashTracker\");\n\nfunction BarHistoryStorage(archive) {\n    const path = require(\"path\");\n    const blocksPath = \"blocks\";\n    let lht = new LatestHashTracker();\n\n    this.getHashLatestBlock = lht.getHashLatestBlock;\n\n    this.appendBlock = function (block, announceFlag, callback) {\n        archive.writeFile(path.join(blocksPath, block.pulse.toString()), JSON.stringify(block, null, 1), (err) => {\n            if (err) {\n                return callback(err);\n            }\n\n            archive.writeFile(path.join(blocksPath, \"index\"), block.pulse.toString(), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                lht.update(block.pulse, block);\n                callback();\n            });\n        });\n    };\n\n    this.getLatestBlockNumber = function (callback) {\n        archive.readFile(path.join(blocksPath, \"index\"), (err, res) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, parseInt(res.toString()));\n        });\n    };\n\n    this.loadSpecificBlock = function (blockNumber, callback) {\n        archive.readFile(path.join(blocksPath, blockNumber.toString()), (err, res) => {\n            if (err) {\n                return callback(err);\n            }\n\n            res = JSON.parse(res.toString());\n            lht.update(res.pulse, res);\n            callback(undefined, res);\n        });\n    };\n\n    ////////////////////////\n    let observer;\n    //send to callback all blocks newer then fromVSD\n    this.observeNewBlocks = function (fromVSD, callback) {\n        observer = callback;\n    }\n}\n\nmodule.exports = BarHistoryStorage;","const LatestHashTracker = require(\"./LatestHashTracker\");\n\nfunction FsHistoryStorage(folder) {\n    const blocksPath = folder + \"/blocks\";\n    let lht = new LatestHashTracker();\n    this.getHashLatestBlock = lht.getHashLatestBlock;\n\n    let fs = require(\"fs\");\n\n    this.appendBlock = function (block, announceFlag, callback) {\n        ensureBlocksPathExist((err) => {\n            if (err) {\n                return callback(err);\n            }\n\n            fs.writeFile(blocksPath + \"/\" + block.pulse, JSON.stringify(block, null, 1), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n                fs.writeFile(blocksPath + \"/index\", block.pulse.toString(), (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    lht.update(block.pulse, block);\n                    callback();\n                });\n            });\n        });\n    };\n\n    this.getLatestBlockNumber = function (callback) {\n        ensureBlocksPathExist((err) => {\n            if (err) {\n                return callback(err);\n            }\n\n            fs.readFile(blocksPath + \"/index\", function (err, res) {\n                let maxBlockNumber = 0;\n                if (err) {\n                    callback(err);\n                } else {\n                    maxBlockNumber = parseInt(res);\n                    callback(null, maxBlockNumber);\n                }\n            });\n        });\n    };\n\n    this.loadSpecificBlock = function (blockNumber, callback) {\n        ensureBlocksPathExist((err) => {\n            if (err) {\n                return callback(err);\n            }\n\n            fs.readFile(blocksPath + \"/\" + blockNumber, function (err, res) {\n                if (err) {\n                    callback(err, null);\n                } else {\n                    res = JSON.parse(res);\n                    lht.update(res.pulse, res);\n                    callback(null, res);\n                }\n            });\n        });\n    };\n\n    ////////////////////////\n    let observer;\n    //send to callback all blocks newer then fromVSD\n    this.observeNewBlocks = function (fromVSD, callback) {\n        observer = callback;\n    };\n\n    //------------------------------------------- internal methods ----------------------------------------------------\n    function ensureBlocksPathExist(callback) {\n        fs.access(blocksPath, (err) => {\n            if (err) {\n                fs.mkdir(blocksPath, {recursive: true}, callback);\n            }else{\n                callback();\n            }\n        });\n    }\n}\n\nmodule.exports = FsHistoryStorage;\n","function LatestHashTracker() {\n    let hlb = \"none\";\n    let maxBlockNumber = 0;\n\n    this.update = function (blockNumber, block) {\n        if (blockNumber > maxBlockNumber) {\n            hlb = block.blockDigest;\n        }\n    };\n\n    this.getHashLatestBlock = function () {\n        return hlb;\n    }\n}\n\nmodule.exports = LatestHashTracker;","const LatestHashTracker = require(\"./LatestHashTracker\");\n\nfunction MemoryHistoryStorage() {\n    let blocks = [];\n    let lht = new LatestHashTracker();\n    this.getHashLatestBlock = lht.getHashLatestBlock;\n\n    this.appendBlock = function (block, announceFlag, callback) {\n        blocks.push(block);\n        lht.update(blocks.length, block);\n        callback(null, block);\n\n    };\n\n    this.getLatestBlockNumber = function (callback) {\n        callback(null, blocks.length);\n    };\n\n    this.loadSpecificBlock = function (blockNumber, callback) {\n        let block = blocks[blockNumber];\n        lht.update(blockNumber, block);\n        callback(null, blocks[blockNumber]);\n    }\n}\n\nmodule.exports = MemoryHistoryStorage;","const FsHistoryStorage = require(\"./FsHistoryStorage\");\nconst MemoryHistoryStorage = require(\"./MemoryHistoryStorage\");\nconst BarHistoryStorage = require(\"./BarHistoryStorage\");\n\nmodule.exports = {\n    createStorage: function (storageType, ...args) {\n        switch (storageType) {\n            case \"fs\":\n                return new FsHistoryStorage(...args);\n            case \"bar\":\n                return new BarHistoryStorage(...args);\n            case \"memory\":\n                return new MemoryHistoryStorage(...args);\n            default:\n                $$.exception(\"Unknown blockchain storage \" + storageType);\n        }\n    }\n};","const mc = require(\"../../moduleConstants\");\nlet pulseUtil = require(\"../../OBFT/PulseUtil\");\n\n\nfunction IPCNetworkSimulator(){\n    this.broadcastPulse = function(pulse){\n        process.send(pulse);\n    }\n\n    this.newPulse = function(){\n        let p = pulseUtil.createPulse()\n        process.send(pulse);\n    }\n\n    this.listen = function(callback){\n        process.on('message', function(msg){\n            callback(null, msg);\n        })\n    }\n}\n\n/*\nvar com = {\n    broadcastPulse: function(from, pulse){\n        nodes.forEach( function(n){\n            if(n.nodeName != from) {\n                setTimeout(function(){\n                    n.recordPulse(from, pulse);\n                }, cutil.getRandomInt(cfg.NETWORK_DELAY));\n            } else {\n                if(pulse.currentPulse > 2 * maxPulse){\n                    afterFinish[from] = true;\n                }\n            }\n        });\n\n\n        if(Object.keys(afterFinish).length >= cfg.MAX_NODES){\n            console.log(Object.keys(afterFinish).length , cfg.MAX_NODES);\n            setTimeout(terminate, 1);\n        }\n    }\n} */\n\n\n\nfunction VirtualMQAdapter(){\n\n}\n\nmodule.exports = {\n    createNetworkAdapter: function (strategyType, ...args) {\n        switch (strategyType) {\n            case \"ipc\":\n                return new IPCNetworkSimulator(...args);\n            case \"virtualmq\":\n                return new VirtualMQAdapter(...args);\n            default:\n                $$.error(\"Unknown communication strategy  \" + strategyType);\n        }\n    }\n}","function PermissiveSignatureProvider(){\n    /*\n    return a signature of message ms for agent agentId\n     */\n    this.signAs = function(agentId, msg){\n        return \"Signature from agent \"+agentId + \" should be here!\";\n    }\n\n    this.verify = function(msg, signatures){\n        return true;\n    };\n}\n\n\nmodule.exports = {\n    createSignatureProvider: function (signProvType,...args) {\n        switch (signProvType) {\n            case \"permissive\":\n                return new PermissiveSignatureProvider(...args);\n            case \"blockchain\":\n            default:\n                $$.exception(\"Signature Provider\" + signProvType + \" not implemented\");\n        }\n    }\n}\n","\nfunction SimpleMajoritarianStrategy(shareHoldersCounter){\n    this.refreshShares = function(){\n\n    }\n    this.vote = function (previousValue, agent) {\n        if (!previousValue) {\n            previousValue = 0;\n        }\n        return previousValue + 1;\n    }\n\n    this.isMajoritarian = function (value) {\n        //console.log(value , Math.floor(shareHoldersCounter/2) + 1);\n        return value >= Math.floor(shareHoldersCounter / 2) + 1;\n    }\n}\n\n\nfunction BlockchainShareHoldersMajority(){\n    let shares = {}\n    this.refreshShares = function(){\n\n    }\n\n    this.vote = function (previousValue, agent) {\n        if (!previousValue) {\n            previousValue = 0;\n        }\n        return previousValue + shares[agent];\n    }\n\n    this.isMajoritarian = function (value) {\n        return value > 0.50;\n    }\n}\n\nmodule.exports = {\n    createVotingStrategy: function (strategyType, ...args) {\n        switch (strategyType) {\n            case \"democratic\":\n                return new SimpleMajoritarianStrategy(...args);\n            case \"shareholders\":\n                return new BlockchainShareHoldersMajority(...args);\n            default:\n                $$.error(\"Unknown voting strategy  \" + strategyType);\n        }\n    }\n}","const mc = require(\"../../moduleConstants\");\n\nfunction StorageContainer(){\n    this.pskdb = {};\n    this.keys = {};\n    this.pulse = 0;\n    let self = this;\n    let latestState = {\n\n    };\n\n    this.readKey = function(key){\n        return self.keys[key];\n    };\n\n    this.writeKey = function(key, value){\n        self.keys[key] = value;\n    };\n\n    function updateAlias(assetType, alias,swarmId){\n        let keyName = assetType + mc.ALIASES;\n        let value = self.readKey(keyName);\n        if(value === undefined){\n            value = {};\n            value[alias] = swarmId;\n        } else {\n            value = JSON.parse(value);\n            value[alias] = swarmId;\n        }\n        self.writeKey(keyName,JSON.stringify(value));\n    }\n\n    this.updateAliases = function(aliases){\n        for(let swarmId in aliases){\n            updateAlias(aliases[swarmId].assetType, aliases[swarmId].alias, swarmId);\n        }\n    }\n}\n\nfunction LocalWSCache(folder) {\n    let storage = new StorageContainer();\n    this.readKey = storage.readKey;\n    this.writeKey = storage.writeKey;\n    this.updateAliases = storage.updateAliases;\n\n    //just in case the folder got to use as storage does not exist\n    require(\"fs\").mkdirSync(folder, {recursive: true});\n\n    const worldStateCachePath = folder + \"/worldStateCache\";\n    let fs = require(\"fs\");\n\n    this.getState = function (callback) {\n        fs.readFile(worldStateCachePath, 'utf8', function (err, res) {\n            let objRes = {};\n            if (err) {\n                callback(err, objRes);\n                console.log(\"Initialisating empty blockchain state\");\n            } else {\n                objRes = JSON.parse(res);\n                storage.pskdb = objRes.pskdb;\n                storage.keys  = objRes.keys;\n                storage.pulse  = objRes.pulse;\n                callback(null, storage.pskdb);\n            }\n        });\n    };\n\n    this.updateState = function (internalValues, callback) {\n        storage.pskdb = internalValues;\n        fs.writeFile(worldStateCachePath, JSON.stringify(storage, null, 1), callback ? callback : function(err){\n            if(err){\n                console.log(err);\n            }\n        });\n    };\n\n    this.dump = function(){\n        console.log(\"LocalWSCache:\", storage);\n    }\n\n}\n\nfunction MemoryCache() {\n    let storage = new StorageContainer();\n    this.readKey = storage.readKey;\n    this.writeKey = storage.writeKey;\n    this.updateAliases = storage.updateAliases;\n\n    this.getState = function (callback) { //err, valuesFromCache\n        callback(null, storage.pskdb);\n    };\n\n    this.updateState = function (internalValues, callback) {\n        //console.info(\"Commiting state in memory cache \"/*, internalValues*/)\n        storage.pskdb = internalValues;\n        storage.pulse = internalValues.pulse;\n        callback(null, storage.pskdb);\n    };\n\n    this.dump = function(){\n        console.log(\"MemoryCache:\", storage);\n    }\n}\n\nmodule.exports = {\n    createCache: function (cacheType, ...args) {\n        switch (cacheType) {\n            case \"fs\":\n                return new LocalWSCache(...args);\n            case \"none\":\n            case \"memory\":\n                return new MemoryCache(...args);\n            default:\n                $$.exception(\"Unknown blockchain cache \" + cacheType);\n        }\n    }\n};","const bm = require(\"blockchain\");\nconst createEDFSBrickStorage = require(\"edfs-brick-storage\").createEDFSBrickStorage;\nconst createFsAdapter = require(\"bar-fs-adapter\").createFsAdapter;\nconst barModule = require(\"bar\");\nconst ArchiveConfigurator = barModule.ArchiveConfigurator;\nArchiveConfigurator.prototype.registerStorageProvider(\"EDFSBrickStorage\", createEDFSBrickStorage);\nArchiveConfigurator.prototype.registerFsAdapter(\"FsAdapter\", createFsAdapter);\n\nfunction RawCSB() {\n\n    const mountPoints = {};//;\n\n    let bar = createBar();\n    let blockchain;\n    let seed;\n\n    this.getSeed = () => {\n        return seed;\n    };\n\n    this.mountBarWithSeed = (mountPoint, barMapDigest, callback) => {\n\n    };\n\n    this.mountBarWithDigest = () => {\n    };\n\n    this.readFile = (barPath, callback) => {\n        bar.readFile(barPath, callback);\n    };\n\n    this.writeFile = (srcFilePath, mountPoint, callback) => {\n\n        bar.addFile(srcFilePath, mountPoint, (err, barMapDigest) => {\n            if (err) {\n                return callback(err);\n            }\n\n            getBlockchain((err, bc)=>{\n                if (err) {\n                    return callback(err);\n                }\n\n                if (!seed) {\n                    seed = bar.getSeed();\n                }\n\n                const transaction = blockchain.startTransactionAs($$.securityContext.getCurrentAgentIdentity(), \"StandardCSBTransactions\", \"addFileAnchor\", barMapDigest);\n                transaction.onCommit((err => callback(err, barMapDigest)));\n            })\n        });\n    };\n\n    this.readDir = () => {\n\n    };\n\n    /* internal functions */\n    function createBlockchain(bar, callback) {\n        const worldStateCache = bm.createWorldStateCache(\"memory\");\n        const historyStorage = bm.createHistoryStorage(\"bar\", bar);\n        const consensusAlgorithm = bm.createConsensusAlgorithm(\"direct\");\n        const signatureProvider = bm.createSignatureProvider(\"permissive\");\n        bm.createABlockchain(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, true).start(callback);\n    }\n\n    function getBlockchain(callback){\n        if (!blockchain) {\n            createBlockchain(bar, (err, res) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                blockchain = res;\n                callback(undefined, blockchain);\n            });\n        }else{\n            callback(undefined, blockchain);\n        }\n    }\n\n    function createBar() {\n        const archiveConfigurator = new barModule.ArchiveConfigurator();\n        archiveConfigurator.setFsAdapter(\"FsAdapter\");\n        archiveConfigurator.setEncryptionAlgorithm(\"aes-256-gcm\");\n        archiveConfigurator.setBufferSize(256);\n        archiveConfigurator.setSeedEndpoint(\"http://localhost:9097\");\n        return new barModule.Archive(archiveConfigurator);\n    }\n}\n\nmodule.exports = RawCSB;","const MAX_QUE_SUPPORTED = 100;\nconst NETWORK_TIMEOUT = 1000;\n\nfunction EDFSBrickQueue(action, queueLimit) {\n\n    if (!Number.isInteger(queueLimit) || queueLimit > MAX_QUE_SUPPORTED) {\n        throw new Error(\"Que limit should be a number greater than 0 and lower than \" + MAX_QUE_SUPPORTED);\n    }\n\n    let bricksQueue = [];\n    let rateLimit = queueLimit;\n    let inExecution = 0;\n\n    function executeQueue() {\n\n        if (bricksQueue.length === 0) {\n            return;\n        }\n\n        if (rateLimit === 0) {\n            rateLimit++;\n            return setTimeout(executeQueue, NETWORK_TIMEOUT);\n        }\n\n        rateLimit--;\n        let item = bricksQueue.pop();\n        let {callback, ...requestData} = item;\n        let args = Object.values(requestData);\n        inExecution++;\n        action(...args, (err, data, headers) => {\n            inExecution--;\n                if (err) {\n                    if (err.statusCode === 429) {\n                        console.log(\"Too many requests!\");\n                        bricksQueue.push(item);\n                        setTimeout(executeQueue, NETWORK_TIMEOUT);\n                    } else {\n                        return callback(err);\n                    }\n                } else {\n                    if (typeof headers !== \"undefined\" && headers.hasOwnProperty(\"x-ratelimit-remaining\")) {\n                        let remainingQuota = Number.parseInt(headers['x-ratelimit-remaining']);\n\n                        if (!isNaN(remainingQuota)) {\n\n                            rateLimit = remainingQuota;\n                            if(rateLimit > 0){\n                                let freeSlots = rateLimit-inExecution;\n                                while(freeSlots>0){\n                                    executeQueue();\n                                    freeSlots--;\n                                }\n                            }\n                            else{\n                                executeQueue();\n                            }\n\n                        }\n\n                    }\n\n                    if (callback) {\n                        callback(null, data, headers);\n                    }\n                }\n            }\n        );\n    }\n\n    this.addBrickRequest = function (url, ...args) {\n\n        let queueData = {\n            url: url\n        };\n        switch (args.length) {\n            case 1:\n                if (typeof args[0] === \"object\") {\n                    queueData['brickData'] = args[0];\n                } else {\n                    if (typeof args[0] === \"function\") {\n                        queueData['callback'] = args[0];\n                    } else {\n                        throw new Error(\"Invalid arguments\")\n                    }\n                }\n                break;\n            case 2:\n                if (typeof args[0] !== \"object\") {\n                    throw new Error(\"Invalid brick data.\")\n                }\n                if (typeof args[1] !== \"function\") {\n                    throw new Error(\"Invalid callback function.\")\n                }\n                queueData['brickData'] = args[0];\n                queueData['callback'] = args[1];\n                break;\n            default:\n                throw new Error(\"Too many arguments.\");\n        }\n\n        bricksQueue.push(queueData);\n        if (rateLimit > 0) {\n            executeQueue();\n        }\n    };\n\n    this.getQueueSize = function () {\n        return bricksQueue.length;\n    };\n\n    this.getQueueFreeSlots = function () {\n        return rateLimit;\n    };\n}\n\nmodule.exports = {\n    EDFSPutBrickQueue: function (limit) {\n        return new EDFSBrickQueue($$.remote.doHttpPost, limit);\n    },\n\n    EDFSGetBrickQueue: function (limit) {\n        return new EDFSBrickQueue($$.remote.doHttpGet, limit);\n    }\n};\n","require(\"psk-http-client\");\nconst bar = require(\"bar\");\nconst Brick = bar.Brick;\nlet PutBrickQueue = require(\"./EDFSBrickQueue\").EDFSPutBrickQueue;\nlet GetBrickQueue = require(\"./EDFSBrickQueue\").EDFSGetBrickQueue;\nlet bricksQueue = [];\n\nfunction EDFSBrickStorage(urls) {\n\n    let putBrickQueue = new PutBrickQueue(30);\n    let getBrickQueue = new GetBrickQueue(30);\n\n    if (typeof urls === \"string\") {\n        urls = [urls]\n    }\n\n    let urlIndex = -1;\n\n    let map;\n\n    this.setBarMap = function (barMap) {\n        map = barMap;\n    };\n\n    this.putBrick = function (brick, callback) {\n        const url = getStorageUrlAddress();\n        $$.remote.doHttpPost(url + \"/EDFS/\" + brick.getHash(), brick.getTransformedData(), callback);\n        // putBrick(brick.getHash(), brick, true, callback);\n    };\n\n    function putBrick(brickId, brick, isSerial, callback) {\n        if (typeof isSerial === \"function\") {\n            callback = isSerial;\n            isSerial = undefined;\n        }\n        let callbackSent = false;\n\n        let handler = function (err, data, headers) {\n            if (!isConnectionError(err)) {\n                if (callbackSent) {\n                    if (err) {\n                        callback(err);\n                    }\n                } else {\n                    callback(err, data, headers)\n                }\n            }\n        };\n        let url = getStorageUrlAddress();\n\n        putBrickQueue.addBrickRequest(url + \"/EDFS/\" + brickId,\n            brick.getTransformedData(),\n            handler);\n\n        if (isSerial && putBrickQueue.getQueueFreeSlots() > 0) {\n            callbackSent = true;\n            callback();\n        }\n    }\n\n\n    this.getBrick = function (brickHash, callback) {\n        let url = getStorageUrlAddress();\n\n        $$.remote.doHttpGet(url + \"/EDFS/\" + brickHash, (err, brickData) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const brick = new Brick();\n            brick.setTransformedData(brickData);\n            callback(undefined, brick);\n        });\n        // let brickRequest = {brickHash: brickHash, callback: callback, data: null};\n        // bricksQueue.push(brickRequest);\n        //\n        // getBrickQueue.addBrickRequest(url + \"/EDFS/\" + brickHash, (err, brickData) => {\n        //     brickRequest.data = {err: err, brickData: brickData};\n        //     handleBricksOrder();\n        // });\n    };\n\n    this.deleteBrick = function (brickHash, callback) {\n        throw new Error(\"Not implemented\");\n    };\n\n    this.putBarMap = function (barMap, callback) {\n        map = barMap;\n        const barMapBrick = barMap.toBrick();\n        barMapBrick.setTransformParameters(barMap.getTransformParameters());\n\n        let brickId = barMapBrick.getId();\n        if (!brickId) {\n            brickId = barMapBrick.getHash();\n        }\n\n        barMapBrick.setId(brickId);\n        const url = getStorageUrlAddress();\n        $$.remote.doHttpPost(url + \"/EDFS/\" + brickId, barMapBrick.getTransformedData(), (err => callback(err, barMapBrick.getSeed())));\n        // putBrick(brickId, mapBrick, true, (err, res) => {\n        //\n        // });\n    };\n\n    this.getBarMap = function (mapDigest, callback) {\n        if (typeof mapDigest === \"function\") {\n            callback = mapDigest;\n            mapDigest = undefined;\n        }\n\n        if (map) {\n            return callback(undefined, map);\n        }\n\n        if (typeof mapDigest === \"undefined\") {\n            return callback(undefined, new bar.FolderBarMap());\n        }\n\n        this.getBrick(mapDigest, (err, mapBrick) => {\n            if (err) {\n                return callback(err);\n            }\n\n            map = new bar.FolderBarMap(mapBrick);\n            callback(undefined, map);\n        });\n    };\n\n    //------------------------------------------ internal methods ---------------------------------------------------\n    function getStorageUrlAddress() {\n        urlIndex++;\n        if (urlIndex >= urls.length) {\n            urlIndex = 0;\n        }\n        return urls[urlIndex];\n    }\n\n    function isConnectionError(err) {\n        if (err && err.code === \"ECONNREFUSED\") {\n            console.error(\"EDFS Server is unavailable! Try again later!\");\n            return true;\n        }\n        return false;\n    }\n\n    function handleBricksOrder() {\n        let brickRequest = bricksQueue[0];\n        if (brickRequest && brickRequest.data) {\n            let data = brickRequest.data;\n            if (!isConnectionError(data.err)) {\n                const brick = new Brick();\n                brick.setTransformedData(data.brickData);\n                brickRequest.callback(data.err, brick);\n                bricksQueue.shift();\n                handleBricksOrder();\n            }\n\n        }\n    }\n}\n\nmodule.exports = {\n    createEDFSBrickStorage(url) {\n        return new EDFSBrickStorage(url);\n    }\n};\n\n","const path = require(\"path\");\nconst fs = require(\"fs\");\nconst crypto = require(\"crypto\");\nconst PskHash = require('pskcrypto').PskHash;\n\nconst folderNameSize = process.env.FOLDER_NAME_SIZE || 5;\nconst FILE_SEPARATOR = '-';\nlet rootfolder;\nlet aliasesPath;\n\n$$.flow.describe(\"BricksManager\", {\n    init: function (rootFolder, callback) {\n        if (!rootFolder) {\n            callback(new Error(\"No root folder specified!\"));\n            return;\n        }\n        rootFolder = path.resolve(rootFolder);\n        this.__ensureFolderStructure(rootFolder, function (err, pth) {\n            rootfolder = rootFolder;\n            aliasesPath = path.join(rootfolder, \"aliases\");\n            callback(err, rootFolder);\n        });\n    },\n    write: function (fileName, readFileStream, callback) {\n        if (!this.__verifyFileName(fileName, callback)) {\n            return;\n        }\n\n        if (!readFileStream || !readFileStream.pipe || typeof readFileStream.pipe !== \"function\") {\n            callback(new Error(\"Something wrong happened\"));\n            return;\n        }\n\n        const folderName = path.join(rootfolder, fileName.substr(0, folderNameSize));\n\n        this.__ensureFolderStructure(folderName, (err) => {\n            if (err) {\n                return callback(err);\n            }\n\n            this.__writeFile(readFileStream, folderName, fileName, callback);\n        });\n\n    },\n    read: function (fileName, writeFileStream, callback) {\n        if (!this.__verifyFileName(fileName, callback)) {\n            return;\n        }\n\n        const folderPath = path.join(rootfolder, fileName.substr(0, folderNameSize));\n        const filePath = path.join(folderPath, fileName);\n\n        this.__verifyFileExistence(filePath, (err, result) => {\n            if (!err) {\n                this.__readFile(writeFileStream, filePath, callback);\n            } else {\n                callback(new Error(`File ${filePath} was not found.`));\n            }\n        });\n    },\n    addAlias: function (fileName, readStream, callback) {\n        if (!this.__verifyFileName(fileName, callback)) {\n            return;\n        }\n\n        this.__streamToString(readStream, (err, alias) => {\n            if (err) {\n                return callback(err);\n            }\n            if (!alias) {\n                return callback(new Error(\"No alias was provided\"));\n            }\n\n            this.__readAliases((err, aliases) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (!aliases[alias]) {\n                    aliases[alias] = [];\n                }\n\n                if(!aliases[alias].includes(fileName)) {\n                    aliases[alias].push(fileName);\n                    this.__writeAliases(aliases, callback);\n                }\n\n                callback();\n            });\n\n        });\n    },\n    writeWithHash: function (fileHash, readStream, callback) {\n        this.write(fileHash, readStream, (err, computedDigest) => {\n            if (err) {\n                return callback(err);\n            }\n\n            if (fileHash !== computedDigest) {\n                fs.unlink(fileHash, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    callback(new Error(\"The specified file hash is incorrect\"));\n                });\n            }\n\n            callback();\n        });\n    },\n    writeWithAlias: function (alias, readStream, callback) {\n        const fileName = encodeURIComponent(crypto.randomBytes(20).toString(\"base64\"));\n        this.write(fileName, readStream, (err, fileHash) => {\n            if (err) {\n                return callback(err);\n            }\n\n            this.__renameFile(fileName, fileHash, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                this.__readAliases((err, aliases) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    if (typeof aliases[alias] === \"undefined\") {\n                        aliases[alias] = [];\n                    }\n\n                    if (!aliases[alias].includes(fileHash)) {\n                        aliases[alias].push(fileHash);\n                        this.__writeAliases(aliases, callback);\n                    }else{\n                        callback();\n                    }\n                });\n            });\n        });\n    },\n    readWithAlias: function (alias, writeStream, callback) {\n        this.__readAliases((err, aliases) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const fileName = this.__getFileName(aliases, alias);\n            this.read(fileName, writeStream, callback);\n        });\n\n    },\n    readVersion: function (fileName, fileVersion, writeFileStream, callback) {\n        if (!this.__verifyFileName(fileName, callback)) {\n            return;\n        }\n\n        const folderPath = path.join(rootfolder, fileName.substr(0, folderNameSize));\n        const filePath = path.join(folderPath, fileName, fileVersion);\n        this.__verifyFileExistence(filePath, (err, result) => {\n            if (!err) {\n                this.__readFile(writeFileStream, path.join(filePath), callback);\n            } else {\n                callback(new Error(\"No file found.\"));\n            }\n        });\n    },\n    getVersionsForFile: function (fileName, callback) {\n        if (!this.__verifyFileName(fileName, callback)) {\n            return;\n        }\n\n        const folderPath = path.join(rootfolder, fileName.substr(0, folderNameSize), fileName);\n        fs.readdir(folderPath, (err, files) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const totalNumberOfFiles = files.length;\n            const filesData = [];\n\n            let resolvedFiles = 0;\n\n            for (let i = 0; i < totalNumberOfFiles; ++i) {\n                fs.stat(path.join(folderPath, files[i]), (err, stats) => {\n                    if (err) {\n                        filesData.push({version: files[i], creationTime: null, creationTimeMs: null});\n                        return;\n                    }\n\n                    filesData.push({\n                        version: files[i],\n                        creationTime: stats.birthtime,\n                        creationTimeMs: stats.birthtimeMs\n                    });\n\n                    resolvedFiles += 1;\n\n                    if (resolvedFiles >= totalNumberOfFiles) {\n                        filesData.sort((first, second) => {\n                            const firstCompareData = first.creationTimeMs || first.version;\n                            const secondCompareData = second.creationTimeMs || second.version;\n\n                            return firstCompareData - secondCompareData;\n                        });\n                        callback(undefined, filesData);\n                    }\n                });\n            }\n        });\n    },\n    compareVersions: function (bodyStream, callback) {\n        let body = '';\n\n        bodyStream.on('data', (data) => {\n            body += data;\n        });\n\n        bodyStream.on('end', () => {\n            try {\n                body = JSON.parse(body);\n                this.__compareVersions(body, callback);\n            } catch (e) {\n                callback(e);\n            }\n        });\n    },\n    __verifyFileName: function (fileName, callback) {\n        if (!fileName || typeof fileName !== \"string\") {\n            return callback(new Error(\"No fileId specified.\"));\n        }\n\n        if (fileName.length < folderNameSize) {\n            return callback(new Error(\"FileId too small. \" + fileName));\n        }\n\n        return true;\n    },\n    __ensureFolderStructure: function (folder, callback) {\n        fs.mkdir(folder, {recursive: true}, callback);\n    },\n    __writeFile: function (readStream, folderPath, fileName, callback) {\n        const hash = require(\"crypto\").createHash(\"sha256\");\n        const filePath = path.join(folderPath, fileName);\n        fs.access(filePath, (err) => {\n            if (err) {\n                readStream.on('data', (data) => {\n                    hash.update(data);\n                });\n\n                const writeStream = fs.createWriteStream(filePath, {mode: 0o444});\n\n                writeStream.on(\"finish\", () => {\n                    callback(undefined, hash.digest(\"hex\"));\n                });\n\n                writeStream.on(\"error\", (err) => {\n                    writeStream.close();\n                    callback(err);\n                });\n\n                readStream.pipe(writeStream);\n            } else {\n                callback();\n\n            }\n        });\n    },\n    __getNextVersionFileName: function (folderPath, fileName, callback) {\n        this.__getLatestVersionNameOfFile(folderPath, (err, fileVersion) => {\n            if (err) {\n                console.error(err);\n                return callback(err);\n            }\n\n            callback(undefined, fileVersion.numericVersion + 1);\n        });\n    },\n    __getLatestVersionNameOfFile: function (folderPath, callback) {\n        fs.readdir(folderPath, (err, files) => {\n            if (err) {\n                console.error(err);\n                callback(err);\n                return;\n            }\n\n            let fileVersion = {numericVersion: 0, fullVersion: '0' + FILE_SEPARATOR};\n\n            if (files.length > 0) {\n                try {\n                    const allVersions = files.map(file => file.split(FILE_SEPARATOR)[0]);\n                    const latestFile = this.__maxElement(allVersions);\n                    fileVersion = {\n                        numericVersion: parseInt(latestFile),\n                        fullVersion: files.filter(file => file.split(FILE_SEPARATOR)[0] === latestFile.toString())[0]\n                    };\n\n                } catch (e) {\n                    e.code = 'invalid_file_name_found';\n                    callback(e);\n                }\n            }\n\n            callback(undefined, fileVersion);\n        });\n    },\n    __maxElement: function (numbers) {\n        let max = numbers[0];\n\n        for (let i = 1; i < numbers.length; ++i) {\n            max = Math.max(max, numbers[i]);\n        }\n\n        if (isNaN(max)) {\n            throw new Error('Invalid element found');\n        }\n\n        return max;\n    },\n    __compareVersions: function (files, callback) {\n        const filesWithChanges = [];\n        const entries = Object.entries(files);\n        let remaining = entries.length;\n\n        if (entries.length === 0) {\n            callback(undefined, filesWithChanges);\n            return;\n        }\n\n        entries.forEach(([fileName, fileHash]) => {\n            this.getVersionsForFile(fileName, (err, versions) => {\n                if (err) {\n                    if (err.code === 'ENOENT') {\n                        versions = [];\n                    } else {\n                        callback(err);\n                    }\n\n                }\n\n                const match = versions.some(version => {\n                    const hash = version.version.split(FILE_SEPARATOR)[1];\n                    return hash === fileHash;\n                });\n\n                if (!match) {\n                    filesWithChanges.push(fileName);\n                }\n\n                if (--remaining === 0) {\n                    callback(undefined, filesWithChanges);\n                }\n            })\n        });\n    },\n    __readFile: function (writeFileStream, filePath, callback) {\n        const readStream = fs.createReadStream(filePath);\n\n        writeFileStream.on(\"finish\", callback);\n        writeFileStream.on(\"error\", callback);\n\n        readStream.pipe(writeFileStream);\n    },\n    __verifyFileExistence: function (filePath, callback) {\n        fs.access(filePath, callback);\n    },\n    __getFileName: function (aliases, alias) {\n        const lastIndex = aliases[alias].length - 1;\n        return aliases[alias][lastIndex];\n    },\n    __writeAliases: function (aliases, callback) {\n        fs.writeFile(aliasesPath, JSON.stringify(aliases), callback);\n    },\n    __readAliases: function (callback) {\n        fs.readFile(aliasesPath, (err, aliases) => {\n            if (err) {\n                if (err.code === \"ENOENT\") {\n                    return callback(undefined, {});\n                }else{\n                    return callback(err);\n                }\n            }\n            callback(undefined, JSON.parse(aliases.toString()));\n        });\n    },\n    __checkIfFileHasAlias: function (aliases, alias, fileName) {\n        return !!aliases[alias].find(el => el === fileName);\n    },\n    __streamToString: function (readStream, callback) {\n        let str = '';\n        readStream.on(\"data\", (chunk) => {\n            str += chunk;\n        });\n\n        readStream.on(\"end\", () => {\n            callback(undefined, str);\n        });\n\n        readStream.on(\"error\", callback);\n    },\n    __renameFile: function (oldFileName, newFileName, callback) {\n        const oldFolderPath = path.join(rootfolder, path.basename(oldFileName).substring(0, folderNameSize));\n        const newFolderPath = path.join(rootfolder, path.basename(newFileName).substring(0, folderNameSize));\n        const oldFilePath = path.join(oldFolderPath, oldFileName);\n        const newFilePath = path.join(newFolderPath, newFileName);\n\n        fs.stat(newFolderPath, (err, stats) => {\n            if (err) {\n                if (err.code === \"ENOENT\") {\n                    fs.mkdir(newFolderPath, {recursive: true}, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n                        __moveFile(callback);\n                    });\n                } else {\n                    return callback(err);\n                }\n            } else {\n                __moveFile(callback);\n            }\n        });\n\n        function __moveFile(callback) {\n            fs.access(newFilePath, (err) => {\n                if (!err) {\n                    __removeFile(callback);\n                    return;\n                }\n\n                fs.copyFile(oldFilePath, newFilePath, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    __removeFile(callback);\n                });\n            });\n\n        }\n\n        function __removeFile(callback) {\n            fs.unlink(oldFilePath, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                fs.readdir(oldFolderPath, (err, files) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    if (files.length === 0) {\n                        fs.rmdir(oldFolderPath, callback);\n                    }\n                });\n            });\n        }\n    }\n});\n","require(\"psk-http-client\");\n\nfunction EDFSClient(url) {\n    this.attachAlias = (fileName, alias, callback) => {\n        $$.remote.doHttpPost(url + \"/EDFS/addAlias/\" + fileName, alias, callback);\n    };\n\n    this.writeToAlias = (alias, data, callback) => {\n        $$.remote.doHttpPost(url + \"/EDFS/alias/\" + alias, data, callback);\n    };\n\n    this.readFromAlias = (alias, callback) => {\n        $$.remote.doHttpGet(url + \"/EDFS/alias/\" + alias, callback);\n    };\n\n    this.writeFile = (fileName, data, callback) => {\n        $$.remote.doHttpPost(url + \"/EDFS/\" + fileName, data, callback);\n    };\n\n    this.readFile = (fileName, callback) => {\n        $$.remote.doHttpGet(url + \"/EDFS/\" + fileName, callback);\n    };\n}\n\nmodule.exports = EDFSClient;","require(\"../flows/BricksManager\");\n\nfunction EDFSMiddleware(server) {\n\n    server.post('/:fileId', (req, res) => {\n        $$.flow.start(\"BricksManager\").writeWithHash(req.params.fileId, req, (err, result) => {\n            res.statusCode = 201;\n            if (err) {\n                res.statusCode = 500;\n\n                if (err.code === 'EACCES') {\n                    res.statusCode = 409;\n                }\n            }\n            res.end();\n        });\n    });\n\n    server.get('/:fileId', (req, res) => {\n        res.setHeader(\"content-type\", \"application/octet-stream\");\n        $$.flow.start(\"BricksManager\").read(req.params.fileId, res, (err, result) => {\n            res.statusCode = 200;\n            if (err) {\n                console.log(err);\n                res.statusCode = 404;\n            }\n            res.end();\n        });\n    });\n\n    server.post('/addAlias/:fileId', (req, res) => {\n        $$.flow.start(\"BricksManager\").addAlias(req.params.fileId, req, (err, result) => {\n            res.statusCode = 201;\n            if (err) {\n                res.statusCode = 500;\n\n                if (err.code === 'EACCES') {\n                    res.statusCode = 409;\n                }\n            }\n            res.end();\n        });\n    });\n\n    server.post('/alias/:alias', (req, res) => {\n        $$.flow.start(\"BricksManager\").writeWithAlias(req.params.alias, req,  (err, result) => {\n            res.statusCode = 201;\n            if (err) {\n                res.statusCode = 500;\n\n                if (err.code === 'EACCES') {\n                    res.statusCode = 409;\n                }\n            }\n            res.end();\n        });\n    });\n\n    server.get('/alias/:alias', (req, res) => {\n        res.setHeader(\"content-type\", \"application/octet-stream\");\n        $$.flow.start(\"BricksManager\").readWithAlias(req.params.alias, res, (err, result) => {\n            res.statusCode = 200;\n            if (err) {\n                console.log(err);\n                res.statusCode = 404;\n            }\n            res.end();\n        });\n    });\n}\n\nmodule.exports = EDFSMiddleware;","const utils = require(\"swarmutils\");\nconst OwM = utils.OwM;\nvar beesHealer = utils.beesHealer;\nvar fs = require(\"fs\");\nvar path = require(\"path\");\n\n\n//TODO: prevent a class of race condition type of errors by signaling with files metadata to the watcher when it is safe to consume\n\nfunction FolderMQ(folder, callback = () => {}){\n\n\tif(typeof callback !== \"function\"){\n\t\tthrow new Error(\"Second parameter should be a callback function\");\n\t}\n\n\tfolder = path.normalize(folder);\n\n\tfs.mkdir(folder, {recursive: true}, function(err, res){\n\t\tfs.exists(folder, function(exists) {\n\t\t\tif (exists) {\n\t\t\t\treturn callback(null, folder);\n\t\t\t} else {\n\t\t\t\treturn callback(err);\n\t\t\t}\n\t\t});\n\t});\n\n\tfunction mkFileName(swarmRaw){\n\t\tlet meta = OwM.prototype.getMetaFrom(swarmRaw);\n\t\tlet name = `${folder}${path.sep}${meta.swarmId}.${meta.swarmTypeName}`;\n\t\tconst unique = meta.phaseId || $$.uidGenerator.safe_uuid();\n\n\t\tname = name+`.${unique}`;\n\t\treturn path.normalize(name);\n\t}\n\n\tthis.getHandler = function(){\n\t\tif(producer){\n\t\t\tthrow new Error(\"Only one consumer is allowed!\");\n\t\t}\n\t\tproducer = true;\n\t\treturn {\n\t\t\tsendSwarmSerialization: function(serialization, callback){\n\t\t\t\tif(typeof callback !== \"function\"){\n\t\t\t\t\tthrow new Error(\"Second parameter should be a callback function\");\n\t\t\t\t}\n\t\t\t\twriteFile(mkFileName(JSON.parse(serialization)), serialization, callback);\n\t\t\t},\n\t\t\taddStream : function(stream, callback){\n\t\t\t\tif(typeof callback !== \"function\"){\n\t\t\t\t\tthrow new Error(\"Second parameter should be a callback function\");\n\t\t\t\t}\n\n\t\t\t\tif(!stream || !stream.pipe || typeof stream.pipe !== \"function\"){\n\t\t\t\t\treturn callback(new Error(\"Something wrong happened\"));\n\t\t\t\t}\n\n\t\t\t\tlet swarm = \"\";\n\t\t\t\tstream.on('data', (chunk) =>{\n\t\t\t\t\tswarm += chunk;\n\t\t\t\t});\n\n\t\t\t\tstream.on(\"end\", () => {\n\t\t\t\t\twriteFile(mkFileName(JSON.parse(swarm)), swarm, callback);\n\t\t\t\t});\n\n\t\t\t\tstream.on(\"error\", (err) =>{\n\t\t\t\t\tcallback(err);\n\t\t\t\t});\n\t\t\t},\n\t\t\taddSwarm : function(swarm, callback){\n\t\t\t\tif(!callback){\n\t\t\t\t\tcallback = $$.defaultErrorHandlingImplementation;\n\t\t\t\t}else if(typeof callback !== \"function\"){\n\t\t\t\t\tthrow new Error(\"Second parameter should be a callback function\");\n\t\t\t\t}\n\n\t\t\t\tbeesHealer.asJSON(swarm,null, null, function(err, res){\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\tconsole.log(err);\n\t\t\t\t\t}\n\t\t\t\t\twriteFile(mkFileName(res), J(res), callback);\n\t\t\t\t});\n\t\t\t},\n\t\t\tsendSwarmForExecution: function(swarm, callback){\n\t\t\t\tif(!callback){\n\t\t\t\t\tcallback = $$.defaultErrorHandlingImplementation;\n\t\t\t\t}else if(typeof callback !== \"function\"){\n\t\t\t\t\tthrow new Error(\"Second parameter should be a callback function\");\n\t\t\t\t}\n\n\t\t\t\tbeesHealer.asJSON(swarm, OwM.prototype.getMetaFrom(swarm, \"phaseName\"), OwM.prototype.getMetaFrom(swarm, \"args\"), function(err, res){\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\tconsole.log(err);\n\t\t\t\t\t}\n\t\t\t\t\tvar file = mkFileName(res);\n\t\t\t\t\tvar content = JSON.stringify(res);\n\n\t\t\t\t\t//if there are no more FD's for files to be written we retry.\n\t\t\t\t\tfunction wrapper(error, result){\n\t\t\t\t\t\tif(error){\n\t\t\t\t\t\t\tconsole.log(`Caught an write error. Retry to write file [${file}]`);\n\t\t\t\t\t\t\tsetTimeout(()=>{\n\t\t\t\t\t\t\t\twriteFile(file, content, wrapper);\n\t\t\t\t\t\t\t}, 10);\n\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\treturn callback(error, result);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\twriteFile(file, content, wrapper);\n\t\t\t\t});\n\t\t\t}\n\t\t};\n\t};\n\n\tvar recipient;\n\tthis.setIPCChannel = function(processChannel){\n\t\tif(processChannel && !processChannel.send || (typeof processChannel.send) != \"function\"){\n\t\t\tthrow new Error(\"Recipient is not instance of process/child_process or it was not spawned with IPC channel!\");\n\t\t}\n\t\trecipient = processChannel;\n\t\tif(consumer){\n\t\t\tconsole.log(`Channel updated`);\n\t\t\t(recipient || process).on(\"message\", receiveEnvelope);\n\t\t}\n\t};\n\n\n\tvar consumedMessages = {};\n\n\tfunction checkIfConsummed(name, message){\n\t\tconst shortName = path.basename(name);\n\t\tconst previousSaved = consumedMessages[shortName];\n\t\tlet result = false;\n\t\tif(previousSaved && !previousSaved.localeCompare(message)){\n\t\t\tresult = true;\n\t\t}\n\t\treturn result;\n\t}\n\n\tfunction save2History(envelope){\n\t\tconsumedMessages[path.basename(envelope.name)] = envelope.message;\n\t}\n\n\tfunction buildEnvelopeConfirmation(envelope, saveHistory){\n\t\tif(saveHistory){\n\t\t\tsave2History(envelope);\n\t\t}\n\t\treturn `Confirm envelope ${envelope.timestamp} sent to ${envelope.dest}`;\n\t}\n\n\tfunction buildEnvelope(name, message){\n\t\treturn {\n\t\t\tdest: folder,\n\t\t\tsrc: process.pid,\n\t\t\ttimestamp: new Date().getTime(),\n\t\t\tmessage: message,\n\t\t\tname: name\n\t\t};\n\t}\n\n\tfunction receiveEnvelope(envelope){\n\t\tif(!envelope || typeof envelope !== \"object\"){\n\t\t\treturn;\n\t\t}\n\t\t//console.log(\"received envelope\", envelope, folder);\n\n\t\tif(envelope.dest !== folder && folder.indexOf(envelope.dest)!== -1 && folder.length === envelope.dest+1){\n\t\t\tconsole.log(\"This envelope is not for me!\");\n\t\t\treturn;\n\t\t}\n\n\t\tlet message = envelope.message;\n\n\t\tif(callback){\n\t\t\t//console.log(\"Sending confirmation\", process.pid);\n\t\t\trecipient.send(buildEnvelopeConfirmation(envelope, true));\n\t\t\tconsumer(null, JSON.parse(message));\n\t\t}\n\t}\n\n\tthis.registerAsIPCConsumer = function(callback){\n\t\tif(typeof callback !== \"function\"){\n\t\t\tthrow new Error(\"The argument should be a callback function\");\n\t\t}\n\t\tregisteredAsIPCConsumer = true;\n\t\t//will register as normal consumer in order to consume all existing messages but without setting the watcher\n\t\tthis.registerConsumer(callback, true, (watcher) => !watcher);\n\n\t\t//console.log(\"Registered as IPC Consummer\", );\n\t\t(recipient || process).on(\"message\", receiveEnvelope);\n\t};\n\n\tthis.registerConsumer = function (callback, shouldDeleteAfterRead = true, shouldWaitForMore = (watcher) => true) {\n\t\tif(typeof callback !== \"function\"){\n\t\t\tthrow new Error(\"First parameter should be a callback function\");\n\t\t}\n\t\tif (consumer) {\n\t\t\tthrow new Error(\"Only one consumer is allowed! \" + folder);\n\t\t}\n\n\t\tconsumer = callback;\n\n\t\tfs.mkdir(folder, {recursive: true}, function (err, res) {\n\t\t\tif (err && (err.code !== 'EEXIST')) {\n\t\t\t\tconsole.log(err);\n\t\t\t}\n\t\t\tconsumeAllExisting(shouldDeleteAfterRead, shouldWaitForMore);\n\t\t});\n\t};\n\n\tthis.writeMessage = writeFile;\n\n\tthis.unlinkContent = function (messageId, callback) {\n\t\tconst messagePath = path.join(folder, messageId);\n\n\t\tfs.unlink(messagePath, (err) => {\n\t\t\tcallback(err);\n\t\t});\n\t};\n\n\tthis.dispose = function(force){\n\t\tif(typeof folder != \"undefined\"){\n\t\t\tvar files;\n\t\t\ttry{\n\t\t\t\tfiles = fs.readdirSync(folder);\n\t\t\t}catch(error){\n\t\t\t\t//..\n\t\t\t}\n\n\t\t\tif(files && files.length > 0 && !force){\n\t\t\t\tconsole.log(\"Disposing a channel that still has messages! Dir will not be removed!\");\n\t\t\t\treturn false;\n\t\t\t}else{\n\t\t\t\ttry{\n\t\t\t\t\tfs.rmdirSync(folder);\n\t\t\t\t}catch(err){\n\t\t\t\t\t//..\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfolder = null;\n\t\t}\n\n\t\tif(producer){\n\t\t\t//no need to do anything else\n\t\t}\n\n\t\tif(typeof consumer != \"undefined\"){\n\t\t\tconsumer = () => {};\n\t\t}\n\n\t\tif(watcher){\n\t\t\twatcher.close();\n\t\t\twatcher = null;\n\t\t}\n\n\t\treturn true;\n\t};\n\n\n\t/* ---------------- protected  functions */\n\tvar consumer = null;\n\tvar registeredAsIPCConsumer = false;\n\tvar producer = null;\n\n\tfunction buildPathForFile(filename){\n\t\treturn path.normalize(path.join(folder, filename));\n\t}\n\n\tfunction consumeMessage(filename, shouldDeleteAfterRead, callback) {\n\t\tvar fullPath = buildPathForFile(filename);\n\n\t\tfs.readFile(fullPath, \"utf8\", function (err, data) {\n\t\t\tif (!err) {\n\t\t\t\tif (data !== \"\") {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tvar message = JSON.parse(data);\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\tconsole.log(\"Parsing error\", error);\n\t\t\t\t\t\terr = error;\n\t\t\t\t\t}\n\n\t\t\t\t\tif(checkIfConsummed(fullPath, data)){\n\t\t\t\t\t\t//console.log(`message already consumed [${filename}]`);\n\t\t\t\t\t\treturn ;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (shouldDeleteAfterRead) {\n\n\t\t\t\t\t\tfs.unlink(fullPath, function (err, res) {\n\t\t\t\t\t\t\tif (err) {throw err;};\n\t\t\t\t\t\t});\n\n\t\t\t\t\t}\n\t\t\t\t\treturn callback(err, message);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconsole.log(\"Consume error\", err);\n\t\t\t\treturn callback(err);\n\t\t\t}\n\t\t});\n\t}\n\n\tfunction consumeAllExisting(shouldDeleteAfterRead, shouldWaitForMore) {\n\n\t\tlet currentFiles = [];\n\n\t\tfs.readdir(folder, 'utf8', function (err, files) {\n\t\t\tif (err) {\n\t\t\t\t$$.errorHandler.error(err);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tcurrentFiles = files;\n\t\t\titerateAndConsume(files);\n\n\t\t});\n\n\t\tfunction startWatching(){\n\t\t\tif (shouldWaitForMore(true)) {\n\t\t\t\twatchFolder(shouldDeleteAfterRead, shouldWaitForMore);\n\t\t\t}\n\t\t}\n\n\t\tfunction iterateAndConsume(files, currentIndex = 0) {\n\t\t\tif (currentIndex === files.length) {\n\t\t\t\t//console.log(\"start watching\", new Date().getTime());\n\t\t\t\tstartWatching();\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (path.extname(files[currentIndex]) !== in_progress) {\n\t\t\t\tconsumeMessage(files[currentIndex], shouldDeleteAfterRead, (err, data) => {\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\titerateAndConsume(files, ++currentIndex);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tconsumer(null, data, path.basename(files[currentIndex]));\n\t\t\t\t\tif (shouldWaitForMore()) {\n\t\t\t\t\t\titerateAndConsume(files, ++currentIndex);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\titerateAndConsume(files, ++currentIndex);\n\t\t\t}\n\t\t}\n\t}\n\n\tfunction writeFile(filename, content, callback){\n\t\tif(recipient){\n\t\t\tvar envelope = buildEnvelope(filename, content);\n\t\t\t//console.log(\"Sending to\", recipient.pid, recipient.ppid, \"envelope\", envelope);\n\t\t\trecipient.send(envelope);\n\t\t\tvar confirmationReceived = false;\n\n\t\t\tfunction receiveConfirmation(message){\n\t\t\t\tif(message === buildEnvelopeConfirmation(envelope)){\n\t\t\t\t\t//console.log(\"Received confirmation\", recipient.pid);\n\t\t\t\t\tconfirmationReceived = true;\n\t\t\t\t\ttry{\n\t\t\t\t\t\trecipient.off(\"message\", receiveConfirmation);\n\t\t\t\t\t}catch(err){\n\t\t\t\t\t\t//...\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trecipient.on(\"message\", receiveConfirmation);\n\n\t\t\tsetTimeout(()=>{\n\t\t\t\tif(!confirmationReceived){\n\t\t\t\t\t//console.log(\"No confirmation...\", process.pid);\n\t\t\t\t\thidden_writeFile(filename, content, callback);\n\t\t\t\t}else{\n\t\t\t\t\tif(callback){\n\t\t\t\t\t\treturn callback(null, content);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}, 200);\n\t\t}else{\n\t\t\thidden_writeFile(filename, content, callback);\n\t\t}\n\t}\n\n\tconst in_progress = \".in_progress\";\n\tfunction hidden_writeFile(filename, content, callback){\n\t\tvar tmpFilename = filename+in_progress;\n\t\ttry{\n\t\t\tif(fs.existsSync(tmpFilename) || fs.existsSync(filename)){\n\t\t\t\tconsole.log(new Error(`Overwriting file ${filename}`));\n\t\t\t}\n\t\t\tfs.writeFileSync(tmpFilename, content);\n\t\t\tfs.renameSync(tmpFilename, filename);\n\t\t}catch(err){\n\t\t\treturn callback(err);\n\t\t}\n\t\tcallback(null, content);\n\t}\n\n\tvar alreadyKnownChanges = {};\n\n\tfunction alreadyFiredChanges(filename, change){\n\t\tvar res = false;\n\t\tif(alreadyKnownChanges[filename]){\n\t\t\tres = true;\n\t\t}else{\n\t\t\talreadyKnownChanges[filename] = change;\n\t\t}\n\n\t\treturn res;\n\t}\n\n\tfunction watchFolder(shouldDeleteAfterRead, shouldWaitForMore){\n\n\t\tsetTimeout(function(){\n\t\t\tfs.readdir(folder, 'utf8', function (err, files) {\n\t\t\t\tif (err) {\n\t\t\t\t\t$$.errorHandler.error(err);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tfor(var i=0; i<files.length; i++){\n\t\t\t\t\twatchFilesHandler(\"change\", files[i]);\n\t\t\t\t}\n\t\t\t});\n\t\t}, 1000);\n\n\t\tfunction watchFilesHandler(eventType, filename){\n\t\t\t//console.log(`Got ${eventType} on ${filename}`);\n\n\t\t\tif(!filename || path.extname(filename) === in_progress){\n\t\t\t\t//caught a delete event of a file\n\t\t\t\t//or\n\t\t\t\t//file not ready to be consumed (in progress)\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tvar f = buildPathForFile(filename);\n\t\t\tif(!fs.existsSync(f)){\n\t\t\t\t//console.log(\"File not found\", f);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t//console.log(`Preparing to consume ${filename}`);\n\t\t\tif(!alreadyFiredChanges(filename, eventType)){\n\t\t\t\tconsumeMessage(filename, shouldDeleteAfterRead, (err, data) => {\n\t\t\t\t\t//allow a read a the file\n\t\t\t\t\talreadyKnownChanges[filename] = undefined;\n\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\t// ??\n\t\t\t\t\t\tconsole.log(\"\\nCaught an error\", err);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tconsumer(null, data, filename);\n\n\n\t\t\t\t\tif (!shouldWaitForMore()) {\n\t\t\t\t\t\twatcher.close();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}else{\n\t\t\t\tconsole.log(\"Something happens...\", filename);\n\t\t\t}\n\t\t}\n\n\n\t\tconst watcher = fs.watch(folder, watchFilesHandler);\n\n\t\tconst intervalTimer = setInterval(()=>{\n\t\t\tfs.readdir(folder, 'utf8', function (err, files) {\n\t\t\t\tif (err) {\n\t\t\t\t\t$$.errorHandler.error(err);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif(files.length > 0){\n\t\t\t\t\tconsole.log(`\\n\\nFound ${files.length} files not consumed yet in ${folder}`, new Date().getTime(),\"\\n\\n\");\n\t\t\t\t\t//faking a rename event trigger\n\t\t\t\t\twatchFilesHandler(\"rename\", files[0]);\n\t\t\t\t}\n\t\t\t});\n\t\t}, 5000);\n\t}\n}\n\nexports.getFolderQueue = function(folder, callback){\n\treturn new FolderMQ(folder, callback);\n};\n","function MemoryMQInteractionSpace() {\n    var swarmInteract = require(\"./../swarmInteraction\");\n    var swarmHandlersSubscribers = {};\n\n    function dispatchingSwarms(swarm){\n\t\tsetTimeout(function(){\n            var subsList = swarmHandlersSubscribers[swarm.meta.swarmId];\n            if(subsList){\n                for(var i=0; i<subsList.length; i++){\n                    var handler = subsList[i];\n                    handler(null, swarm);\n                }\n            }\n        }, 1);\n    }\n\n    var initialized = false;\n    function init(){\n\t\tif(!initialized){\n\t\t\tinitialized = true;\n\t\t\t$$.PSK_PubSub.subscribe($$.CONSTANTS.SWARM_FOR_EXECUTION, dispatchingSwarms);\n\t\t}\n    }\n\n    var comm = {\n        startSwarm: function (swarmName, ctor, args) {\n\t\t\tinit();\n            return $$.swarm.start(swarmName, ctor, ...args);\n        },\n        continueSwarm: function (swarmHandler, swarmSerialisation, ctor, args) {\n\t\t\tinit();\n            swarmHandler[ctor].apply(swarmHandler, args);\n        },\n        on: function (swarmHandler, callback) {\n\t\t\tinit();\n            if(!swarmHandlersSubscribers[swarmHandler.getInnerValue().meta.swarmId]){\n\t\t\t\tswarmHandlersSubscribers[swarmHandler.getInnerValue().meta.swarmId] = [ callback ];\n            }else{\n\t\t\t\tswarmHandlersSubscribers[swarmHandler.getInnerValue().meta.swarmId].push(callback);\n            }\n        },\n        off: function (swarmHandler) {\n\t\t\tif(swarmHandlersSubscribers[swarmHandler.getInnerValue().meta.swarmId]){\n\t\t\t\tswarmHandlersSubscribers[swarmHandler.getInnerValue().meta.swarmId] = [];\n            }\n        }\n    };\n\n    return swarmInteract.newInteractionSpace(comm);\n\n}\n\nvar space;\nmodule.exports.createInteractionSpace = function () {\n    if(!space){\n        space = new MemoryMQInteractionSpace();\n    }else{\n        console.log(\"MemoryMQInteractionSpace already created! Using same instance.\");\n    }\n    return space;\n};","function WindowMQInteractionSpace(channelName, communicationWindow, secondCommunicationChannel){\n    var swarmInteract = require(\"./../swarmInteraction\");\n    var childMessageMQ = require(\"./specificMQImpl/ChildWebViewMQ\").createMQ(channelName, communicationWindow, secondCommunicationChannel);\n    var swarmInstances = {};\n\n    var comm = {\n        startSwarm: function (swarmName, ctor, args) {\n            var swarm = {meta:{\n                    swarmTypeName:swarmName,\n                    ctor:ctor,\n                    args:args\n                }};\n            childMessageMQ.produce(swarm);\n            return swarm;\n        },\n        continueSwarm: function (swarmHandler, swarmSerialisation, phaseName, args) {\n\n            var newSerialization = JSON.parse(JSON.stringify(swarmSerialisation));\n            newSerialization.meta.ctor = undefined;\n            newSerialization.meta.phaseName = phaseName;\n            newSerialization.meta.target = \"iframe\";\n            newSerialization.meta.args = args;\n            childMessageMQ.produce(newSerialization);\n        },\n        on: function (swarmHandler, callback) {\n            childMessageMQ.registerConsumer(callback);\n        },\n        off: function (swarmHandler) {\n\n        }\n    };\n\n\n    var space = swarmInteract.newInteractionSpace(comm);\n    this.startSwarm = function (name, ctor, ...args) {\n        return space.startSwarm(name, ctor, ...args);\n    };\n\n    this.init = function () {\n\n        childMessageMQ.registerConsumer(function (err, data) {\n            if (err) {\n                console.log(err);\n            }\n            else {\n                var swarm;\n                if(data && data.meta && data.meta.swarmId && swarmInstances[data.meta.swarmId]){\n                    swarm = swarmInstances[data.meta.swarmId];\n                    swarm.update(data);\n                    swarm[data.meta.phaseName].apply(swarm, data.meta.args);\n                }else{\n\n                    swarm = $$.swarm.start(data.meta.swarmTypeName, data.meta.ctor, ...data.meta.args);\n\n                    swarmInstances[swarm.getInnerValue().meta.swarmId] = swarm;\n\n                    swarm.onReturn(function(data){\n                        console.log(\"Swarm is finished\");\n                        console.log(data);\n                    });\n                }\n            }\n        });\n        const readyEvt = {webViewIsReady: true};\n        parent.postMessage(JSON.stringify(readyEvt), \"*\");\n\n    };\n\n    function handler(message){\n        log(\"sending swarm \", message);\n        childMessageMQ.produce(message);\n    }\n\n    function filterInteractions(message){\n        log(\"checking if message is 'interaction' \", message);\n        return message && message.meta && message.meta.target && message.meta.target === \"interaction\";\n    }\n    //TODO fix this for nativeWebView\n\n    $$.PSK_PubSub.subscribe($$.CONSTANTS.SWARM_FOR_EXECUTION, handler, function(){return true;}, filterInteractions);\n\n    log(\"registering listener for handling interactions\");\n\n    function log(...args){\n        args.unshift(\"[WindowMQInteractionSpace\"+(window.frameElement ? \"*\": \"\")+\"]\" );\n        //console.log.apply(this, args);\n    }\n}\n\nmodule.exports.createInteractionSpace = function(channelName, communicationWindow, secondCommunicationChannel){\n    return new WindowMQInteractionSpace(channelName, communicationWindow, secondCommunicationChannel);\n};","/*TODO\nFor the moment I don't see any problems if it's not cryptographic safe.\nThis version keeps  compatibility with mobile browsers/webviews.\n */\nfunction uuidv4() {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n        var r = Math.random() * 16 | 0, v = c === 'x' ? r : (r & 0x3 | 0x8);\n        return v.toString(16);\n    });\n}\n\nfunction WindowMQInteractionSpace(channelName, communicationWindow) {\n    var swarmInteract = require(\"./../swarmInteraction\");\n    var childMessageMQ = require(\"./specificMQImpl/ChildWndMQ\").createMQ(channelName, communicationWindow);\n    var swarmInstances = {};\n\n    var comm = {\n        startSwarm: function (swarmName, ctor, args) {\n\n            var uniqueId = uuidv4();\n            var swarm = {\n                meta: {\n                    swarmTypeName: swarmName,\n                    ctor: ctor,\n                    args: args,\n                    requestId: uniqueId,\n                }\n            };\n            childMessageMQ.produce(swarm);\n            return swarm;\n        },\n        continueSwarm: function (swarmHandler, swarmSerialisation, phaseName, args) {\n\n            var newSerialization = JSON.parse(JSON.stringify(swarmSerialisation));\n            newSerialization.meta.ctor = undefined;\n            newSerialization.meta.phaseName = phaseName;\n            newSerialization.meta.target = \"iframe\";\n            newSerialization.meta.args = args;\n            childMessageMQ.produce(newSerialization);\n        },\n        on: function (swarmHandler, callback) {\n            childMessageMQ.registerCallback(swarmHandler.meta.requestId, callback);\n        },\n        off: function (swarmHandler) {\n            console.log(\"Function not implemented!\");\n        }\n    };\n\n\n    var space = swarmInteract.newInteractionSpace(comm);\n    this.startSwarm = function (name, ctor, ...args) {\n        return space.startSwarm(name, ctor, ...args);\n    };\n\n    this.init = function () {\n\n        childMessageMQ.registerConsumer(function (err, data) {\n            if (err) {\n                console.log(err);\n            }\n            else {\n                var swarm;\n                if (data && data.meta && data.meta.swarmId && swarmInstances[data.meta.swarmId]) {\n                    swarm = swarmInstances[data.meta.swarmId];\n                    swarm.update(data);\n                    swarm[data.meta.phaseName].apply(swarm, data.meta.args);\n                } else {\n\n                    swarm = $$.swarm.start(data.meta.swarmTypeName, data.meta.ctor, ...data.meta.args);\n                    swarm.setMetadata(\"requestId\", data.meta.requestId);\n                    swarmInstances[swarm.getInnerValue().meta.swarmId] = swarm;\n\n                    swarm.onReturn(function (data) {\n                        console.log(\"Swarm is finished\");\n                        console.log(data);\n                    });\n                }\n            }\n        });\n        parent.postMessage({webViewIsReady: true}, \"*\");\n    };\n\n    function handler(message) {\n        log(\"sending swarm \", message);\n        childMessageMQ.produce(message);\n    }\n\n    function filterInteractions(message) {\n        log(\"checking if message is 'interaction' \", message);\n        return message && message.meta && message.meta.target && message.meta.target === \"interaction\";\n    }\n\n    $$.PSK_PubSub.subscribe($$.CONSTANTS.SWARM_FOR_EXECUTION, handler, function () {\n        return true;\n    }, filterInteractions);\n    log(\"registering listener for handling interactions\");\n\n    function log(...args) {\n        args.unshift(\"[WindowMQInteractionSpace\" + (window.frameElement ? \"*\" : \"\") + \"]\");\n        //console.log.apply(this, args);\n    }\n}\n\nmodule.exports.createInteractionSpace = function (channelName, communicationWindow) {\n    return new WindowMQInteractionSpace(channelName, communicationWindow);\n};\n","var OwM = require(\"swarmutils\").OwM;\nvar swarmInteract = require(\"./../swarmInteraction\");\nvar folderMQ = require(\"foldermq\");\n\nfunction FolderMQInteractionSpace(agent, targetFolder, returnFolder) {\n    var swarmHandlersSubscribers = {};\n    var queueHandler = null;\n    var responseQueue = null;\n\n    var queue = folderMQ.createQue(targetFolder, (err , result) => {\n        if(err){\n           throw err;\n        }\n    });\n\n    function createSwarmPack(swarmName, phaseName, ...args){\n        var swarm = new OwM();\n\n        swarm.setMeta(\"swarmId\", $$.uidGenerator.safe_uuid());\n\n        swarm.setMeta(\"requestId\", swarm.getMeta(\"swarmId\"));\n        swarm.setMeta(\"swarmTypeName\", swarmName);\n        swarm.setMeta(\"phaseName\", phaseName);\n        swarm.setMeta(\"args\", args);\n        swarm.setMeta(\"command\", \"executeSwarmPhase\");\n        swarm.setMeta(\"target\", agent);\n        swarm.setMeta(\"homeSecurityContext\", returnFolder);\n\n        return swarm;\n    }\n\n    function dispatchingSwarms(err, swarm){\n        if (err) {\n            console.log(err);\n        }\n\t\tsetTimeout(function(){\n            var subsList = swarmHandlersSubscribers[swarm.meta.swarmId];\n            if(subsList){\n                for(var i=0; i<subsList.length; i++){\n                    let handler = subsList[i];\n                    handler(null, swarm);\n                }\n            }\n        }, 1);\n    }\n\n    function init(){\n        if(!queueHandler){\n            queueHandler = queue.getHandler();\n        }\n    }\n\t\n\tinit();\n\n    function prepareToConsume(){\n        if(!responseQueue){\n            responseQueue = folderMQ.createQue(returnFolder);\n            responseQueue.registerConsumer(dispatchingSwarms);\n        }\n    }\n\n    var communication = {\n        startSwarm: function (swarmName, ctor, args) {\n            prepareToConsume();\n            var swarm = createSwarmPack(swarmName, ctor, ...args);\n            queueHandler.sendSwarmForExecution(swarm);\n            return swarm;\n        },\n        continueSwarm: function (swarmHandler, swarmSerialisation, ctor, ...args) {\n            try{\n                swarmHandler.update(swarmSerialisation);\n                swarmHandler[ctor].apply(swarmHandler, args);\n            }catch(err){\n                console.log(err);\n            }\n        },\n        on: function (swarmHandler, callback) {\n            prepareToConsume();\n\n            if(!swarmHandlersSubscribers[swarmHandler.meta.swarmId]){\n                swarmHandlersSubscribers[swarmHandler.meta.swarmId] = [];\n            }\n            swarmHandlersSubscribers[swarmHandler.meta.swarmId].push(callback);\n\n        },\n        off: function (swarmHandler) {\n            swarmHandlersSubscribers[swarmHandler.meta.swarmId] = [];\n        }\n    };\n\n    return swarmInteract.newInteractionSpace(communication);\n}\n\nvar spaces = {};\n\nmodule.exports.createInteractionSpace = function (agent, targetFolder, returnFolder) {\n    var index = targetFolder+returnFolder;\n    if(!spaces[index]){\n        spaces[index] = new FolderMQInteractionSpace(agent, targetFolder, returnFolder);\n    }else{\n        console.log(`FolderMQ interaction space based on [${targetFolder}, ${returnFolder}] already exists!`);\n    }\n    return spaces[index];\n};","require('psk-http-client');\n\nfunction HTTPInteractionSpace(alias, remoteEndPoint, agentUid, cryptoInfo) {\n    const swarmInteract = require(\"./../swarmInteraction\");\n\n    let initialized = false;\n    function init(){\n        if(!initialized){\n            initialized = true;\n            $$.remote.createRequestManager();\n            $$.remote.newEndPoint(alias, remoteEndPoint, agentUid, cryptoInfo);\n        }\n    }\n\n    const comm = {\n        startSwarm: function (swarmName, ctor, args) {\n            init();\n            return $$.remote[alias].startSwarm(swarmName, ctor, ...args);\n        },\n        continueSwarm: function (swarmHandler, swarmSerialisation, ctor, args) {\n            return $$.remote[alias].continueSwarm(swarmSerialisation, ctor, args);\n        },\n        on: function (swarmHandler, callback) {\n            swarmHandler.on('*', callback);\n        },\n        off: function (swarmHandler) {\n            swarmHandler.off('*');\n        }\n    };\n\n    return swarmInteract.newInteractionSpace(comm);\n}\n\nmodule.exports.createInteractionSpace = function (alias, remoteEndPoint, agentUid, cryptoInfo) {\n    //singleton\n    return new HTTPInteractionSpace(alias, remoteEndPoint, agentUid, cryptoInfo);\n};","var channelsRegistry = {}; //keeps callbacks for consumers and windows references for producers\nvar callbacksRegistry = {};\n\nfunction dispatchEvent(event) {\n    var swarm = JSON.parse(event.data);\n    if(swarm.meta){\n        var callback = callbacksRegistry[swarm.meta.channelName];\n        if (callback) {\n            return callback(null, swarm);\n        } else {\n            throw new Error(\"\");\n        }\n    }\n\n}\n\n\nfunction ChildWndMQ(channelName, mainWindow, secondCommunicationChannel) {\n    //channel name is\n\n    channelsRegistry[channelName] = mainWindow;\n\n    this.produce = function (swarmMsg) {\n        swarmMsg.meta.channelName = channelName;\n        var message = {\n            meta:swarmMsg.meta,\n            publicVars:swarmMsg.publicVars,\n            privateVars:swarmMsg.privateVars\n        };\n\n        message.meta.args = message.meta.args.map(function (argument) {\n            if (argument instanceof Error) {\n                var error = {};\n                if (argument.message) {\n                    error[\"message\"] = argument.message;\n                }\n                if (argument.code) {\n                    error[\"code\"] = argument.code;\n                }\n                return error;\n            }\n            return argument;\n        });\n        mainWindow.postMessage(JSON.stringify(message), \"*\");\n    };\n\n    var consumer;\n\n    this.registerConsumer = function (callback, shouldDeleteAfterRead = true) {\n        if (typeof callback !== \"function\") {\n            throw new Error(\"First parameter should be a callback function\");\n        }\n        if (consumer) {\n           // throw new Error(\"Only one consumer is allowed!\");\n        }\n\n        consumer = callback;\n        callbacksRegistry[channelName] = consumer;\n\n        if (secondCommunicationChannel && typeof secondCommunicationChannel.addEventListener !== \"undefined\") {\n            secondCommunicationChannel.addEventListener(\"message\", dispatchEvent);\n        }\n      };\n}\n\n\nmodule.exports.createMQ = function createMQ(channelName, wnd, secondCommunicationChannel){\n    return new ChildWndMQ(channelName, wnd, secondCommunicationChannel);\n};\n\n\nmodule.exports.initForSwarmingInChild = function(domainName){\n\n    var pubSub = $$.require(\"soundpubsub\").soundPubSub;\n\n    var inbound = createMQ(domainName+\"/inbound\");\n    var outbound = createMQ(domainName+\"/outbound\");\n\n\n    inbound.registerConsumer(function(err, swarm){\n        if (err) {\n            console.log(err);\n        }\n        //restore and execute this tasty swarm\n        global.$$.swarmsInstancesManager.revive_swarm(swarm);\n    });\n\n    pubSub.subscribe($$.CONSTANTS.SWARM_FOR_EXECUTION, function(swarm){\n        outbound.sendSwarmForExecution(swarm);\n    });\n};\n\n","var channelsRegistry = {}; //keeps callbacks for consumers and windows references for producers\nvar callbacksRegistry = {};\nvar swarmCallbacks = {};\n\nfunction dispatchEvent(event) {\n\n    if (event.source !== window) {\n\n        var swarm = event.data;\n\n        if (swarm.meta) {\n            let callback;\n            if (!swarm.meta.requestId || !swarmCallbacks[swarm.meta.requestId]) {\n                callback = callbacksRegistry[swarm.meta.channelName];\n            }\n            else {\n                callback = swarmCallbacks[swarm.meta.requestId];\n            }\n\n            if (callback) {\n                return callback(null, swarm);\n            } else {\n                throw new Error(\"\");\n            }\n\n        }\n    }\n}\n\n\nfunction ChildWndMQ(channelName, mainWindow) {\n    //channel name is\n\n    channelsRegistry[channelName] = mainWindow;\n\n    this.produce = function (swarmMsg) {\n        swarmMsg.meta.channelName = channelName;\n        var message = {\n            meta: swarmMsg.meta,\n            publicVars: swarmMsg.publicVars,\n            privateVars: swarmMsg.privateVars\n        };\n        //console.log(swarmMsg.getJSON());\n        //console.log(swarmMsg.valueOf());\n        message.meta.args = message.meta.args.map(function (argument) {\n            if (argument instanceof Error) {\n                var error = {};\n                if (argument.message) {\n                    error[\"message\"] = argument.message;\n                }\n                if (argument.code) {\n                    error[\"code\"] = argument.code;\n                }\n                return error;\n            }\n            return argument;\n        });\n        mainWindow.postMessage(message, \"*\");\n    };\n\n    var consumer;\n\n    this.registerConsumer = function (callback, shouldDeleteAfterRead = true) {\n        if (typeof callback !== \"function\") {\n            throw new Error(\"First parameter should be a callback function\");\n        }\n        if (consumer) {\n            // throw new Error(\"Only one consumer is allowed!\");\n        }\n\n        consumer = callback;\n        callbacksRegistry[channelName] = consumer;\n        mainWindow.addEventListener(\"message\", dispatchEvent);\n    };\n\n    this.registerCallback = function (requestId, callback) {\n        swarmCallbacks[requestId] = callback;\n        callbacksRegistry[channelName] = callback;\n        mainWindow.addEventListener(\"message\", dispatchEvent);\n    };\n\n}\n\n\nmodule.exports.createMQ = function createMQ(channelName, wnd) {\n    return new ChildWndMQ(channelName, wnd);\n};\n\n\nmodule.exports.initForSwarmingInChild = function (domainName) {\n\n    var pubSub = $$.require(\"soundpubsub\").soundPubSub;\n\n    var inbound = createMQ(domainName + \"/inbound\");\n    var outbound = createMQ(domainName + \"/outbound\");\n\n\n    inbound.registerConsumer(function (err, swarm) {\n        if (err) {\n            console.log(err);\n        }\n        //restore and execute this tasty swarm\n        global.$$.swarmsInstancesManager.revive_swarm(swarm);\n    });\n\n    pubSub.subscribe($$.CONSTANTS.SWARM_FOR_EXECUTION, function (swarm) {\n        outbound.sendSwarmForExecution(swarm);\n    });\n};\n\n","if (typeof $$ == \"undefined\") {\n    $$ = {};\n}\n\nfunction VirtualSwarm(innerObj, globalHandler){\n    let knownExtraProps = [ \"swarm\" ];\n\n    function buildHandler() {\n        var utility = {};\n        return {\n            set: function (target, property, value, receiver) {\n                switch (true) {\n                    case target.privateVars && target.privateVars.hasOwnProperty(property):\n                        target.privateVars[property] = value;\n                        break;\n                    case target.publicVars && target.publicVars.hasOwnProperty(property):\n                        target.publicVars[property] = value;\n                        break;\n                    case target.hasOwnProperty(property):\n                        target[property] = value;\n                        break;\n                    case knownExtraProps.indexOf(property) === -1:\n                        if (!globalHandler.protected) {\n                            globalHandler.protected = {};\n                        }\n                        globalHandler.protected[property] = value;\n                        break;\n                    default:\n                        utility[property] = value;\n                }\n                return true;\n            },\n            get: function (target, property, receiver) {\n\n                switch (true) {\n                    case target.publicVars && target.publicVars.hasOwnProperty(property):\n                        return target.publicVars[property];\n                    case target.privateVars && target.privateVars.hasOwnProperty(property):\n                        return target.privateVars[property];\n                    case target.hasOwnProperty(property):\n                        return target[property];\n                    case utility.hasOwnProperty(property):\n                        return utility[property];\n                    case globalHandler.protected && globalHandler.protected.hasOwnProperty(property):\n                        return globalHandler.protected[property];\n                    default:\n                        return undefined;\n                }\n            }\n        };\n    }\n\n    return new Proxy(innerObj, buildHandler());\n}\n\nfunction SwarmInteraction(communicationInterface, swarmName, ctor, args) {\n\n    var swarmHandler = communicationInterface.startSwarm(swarmName, ctor, args);\n\n    this.on = function(description){\n        communicationInterface.on(swarmHandler, function(err, swarmSerialisation){\n            if (err) {\n                console.log(err);\n            }\n            let phase = description[swarmSerialisation.meta.phaseName];\n            let virtualSwarm = new VirtualSwarm(swarmSerialisation, swarmHandler);\n\n            if(!phase){\n                //TODO review and fix. Fix case when an interaction is started from another interaction\n                if(swarmHandler && (!swarmHandler.Target || swarmHandler.Target.swarmId !== swarmSerialisation.meta.swarmId)){\n                    console.log(\"Not my swarm!\");\n                    return;\n                }\n                var interactPhaseErr =  new Error(\"Interact method \"+swarmSerialisation.meta.phaseName+\" was not found.\");\n                if(description[\"onError\"]){\n                    description[\"onError\"].call(virtualSwarm, interactPhaseErr);\n                    return;\n                }\n                else{\n                    throw interactPhaseErr;\n                }\n            }\n\n            virtualSwarm.swarm = function(phaseName, ...args){\n                communicationInterface.continueSwarm(swarmHandler, swarmSerialisation, phaseName, args);\n            };\n\n            phase.apply(virtualSwarm, swarmSerialisation.meta.args);\n            if(virtualSwarm.meta.command === \"asyncReturn\"){\n                communicationInterface.off(swarmHandler);\n            }\n        });\n    };\n\n    this.onReturn = function(callback){\n        this.on({\n            __return__: callback\n        });\n    };\n}\n\nvar abstractInteractionSpace = {\n    startSwarm: function (swarmName, ctor, args) {\n        throw new Error(\"Overwrite  SwarmInteraction.prototype.startSwarm\");\n    },\n    resendSwarm: function (swarmInstance, swarmSerialisation, ctor, args) {\n        throw new Error(\"Overwrite  SwarmInteraction.prototype.continueSwarm \");\n    },\n    on: function (swarmInstance, phaseName, callback) {\n        throw new Error(\"Overwrite  SwarmInteraction.prototype.onSwarm\");\n    },\noff: function (swarmInstance) {\n        throw new Error(\"Overwrite  SwarmInteraction.prototype.onSwarm\");\n    }\n};\n\nmodule.exports.newInteractionSpace = function (communicationInterface) {\n\n    if(!communicationInterface) {\n        communicationInterface = abstractInteractionSpace ;\n    }\n    return {\n        startSwarm: function (swarmName, ctor, ...args) {\n            return new SwarmInteraction(communicationInterface, swarmName, ctor, args);\n        }\n    };\n};\n\n","module.exports = Pend;\n\nfunction Pend() {\n  this.pending = 0;\n  this.max = Infinity;\n  this.listeners = [];\n  this.waiting = [];\n  this.error = null;\n}\n\nPend.prototype.go = function(fn) {\n  if (this.pending < this.max) {\n    pendGo(this, fn);\n  } else {\n    this.waiting.push(fn);\n  }\n};\n\nPend.prototype.wait = function(cb) {\n  if (this.pending === 0) {\n    cb(this.error);\n  } else {\n    this.listeners.push(cb);\n  }\n};\n\nPend.prototype.hold = function() {\n  return pendHold(this);\n};\n\nfunction pendHold(self) {\n  self.pending += 1;\n  var called = false;\n  return onCb;\n  function onCb(err) {\n    if (called) throw new Error(\"callback called twice\");\n    called = true;\n    self.error = self.error || err;\n    self.pending -= 1;\n    if (self.waiting.length > 0 && self.pending < self.max) {\n      pendGo(self, self.waiting.shift());\n    } else if (self.pending === 0) {\n      var listeners = self.listeners;\n      self.listeners = [];\n      listeners.forEach(cbListener);\n    }\n  }\n  function cbListener(listener) {\n    listener(self.error);\n  }\n}\n\nfunction pendGo(self, fn) {\n  fn(pendHold(self));\n}\n","let SwarmPacker = require(\"swarmutils\").SwarmPacker;\n\nconst receiveEndpoint = process.env.RECEIVE_ENDPOINT || \"receive-message/\";\nconst sendEndpoint = process.env.SEND_ENDPOINT || \"send-message/\";\nconst createChannelEndpoint = process.env.CREATE_CHANNEL_ENDPOINT || 'create-channel/';\n\n/**********************  utility class **********************************/\nfunction RequestManager(pollingTimeOut){\n    if(!pollingTimeOut){\n        pollingTimeOut = 1000; //1 second by default\n    }\n\n    const self = this;\n\n    function Request(endPoint, initialSwarm, delayedStart){\n        let onReturnCallbacks = [];\n        let onErrorCallbacks = [];\n        let onCallbacks = [];\n        const requestId = initialSwarm.meta.requestId;\n        initialSwarm = null;\n\n        this.getRequestId = function(){\n            return requestId;\n        };\n\n        this.on = function(phaseName, callback){\n            if(typeof phaseName != \"string\"  && typeof callback != \"function\"){\n                throw new Error(\"The first parameter should be a string and the second parameter should be a function\");\n            }\n\n            onCallbacks.push({\n                callback:callback,\n                phase:phaseName\n            });\n\n            if(typeof delayedStart === \"undefined\"){\n                self.poll(endPoint, this);\n            }\n\n            return this;\n        };\n\n        this.onReturn = function(callback){\n            onReturnCallbacks.push(callback);\n            if(typeof delayedStart === \"undefined\"){\n                self.poll(endPoint, this);\n            }\n            return this;\n        };\n\n        this.onError = function(callback){\n            if(onErrorCallbacks.indexOf(callback)!==-1){\n                onErrorCallbacks.push(callback);\n            }else{\n                console.log(\"Error callback already registered!\");\n            }\n        };\n\n        this.start = function(){\n            if(typeof delayedStart !== \"undefined\"){\n                self.poll(endPoint, this);\n            }\n        };\n\n        this.dispatch = function(err, result){\n            if(result instanceof ArrayBuffer) {\n                result = SwarmPacker.unpack(result);\n            }\n\n            result = typeof result === \"string\" ? JSON.parse(result) : result;\n\n            result = OwM.prototype.convert(result);\n            const resultReqId = result.getMeta(\"requestId\");\n            const phaseName = result.getMeta(\"phaseName\");\n            let onReturn = false;\n\n            if(resultReqId === requestId){\n                onReturnCallbacks.forEach(function(c){\n                    c(null, result);\n                    onReturn = true;\n                });\n                if(onReturn){\n                    onReturnCallbacks = [];\n                    onErrorCallbacks = [];\n                }\n\n                onCallbacks.forEach(function(i){\n                    //console.log(\"XXXXXXXX:\", phaseName , i);\n                    if(phaseName === i.phase || i.phase === '*') {\n                        i.callback(err, result);\n                    }\n                });\n            }\n\n            if(onReturnCallbacks.length === 0 && onCallbacks.length === 0){\n                self.unpoll(endPoint, this);\n            }\n        };\n\n        this.dispatchError = function (err) {\n            for (let i = 0; i < onErrorCallbacks.length; i++) {\n                const errCb = onErrorCallbacks[i];\n                errCb(err);\n            }\n        };\n\n        this.off = function(){\n            self.unpoll(endPoint, this);\n        };\n    }\n\n    this.createRequest = function(remoteEndPoint, swarm, delayedStart){\n        return new Request(remoteEndPoint, swarm, delayedStart);\n    };\n\n    /* *************************** polling zone ****************************/\n\n    const pollSet = {};\n\n    const activeConnections = {};\n\n    this.poll = function(remoteEndPoint, request){\n        let requests = pollSet[remoteEndPoint];\n        if(!requests){\n            requests = {};\n            pollSet[remoteEndPoint] = requests;\n        }\n        requests[request.getRequestId()] = request;\n        pollingHandler();\n    };\n\n    this.unpoll = function(remoteEndPoint, request){\n        const requests = pollSet[remoteEndPoint];\n        if(requests){\n            delete requests[request.getRequestId()];\n            if(Object.keys(requests).length === 0){\n                delete pollSet[remoteEndPoint];\n            }\n        }\n        else {\n            console.log(\"Unpolling wrong request:\",remoteEndPoint, request);\n        }\n    };\n\n    function createPollThread(remoteEndPoint){\n        function reArm(){\n            $$.remote.doHttpGet(remoteEndPoint, function(err, res){\n                let requests = pollSet[remoteEndPoint];\n\n                if(err){\n                    for(const req_id in requests){\n                        if(!requests.hasOwnProperty(req_id)) {return;}\n\n                        let err_handler = requests[req_id].dispatchError;\n                        if(err_handler){\n                            err_handler(err);\n                        }\n                    }\n                    activeConnections[remoteEndPoint] = false;\n                } else {\n\n                    for(const k in requests){\n                        if(!requests.hasOwnProperty(k)) {return;}\n\n                        requests[k].dispatch(null, res);\n                    }\n\n                    if(Object.keys(requests).length !== 0) {\n                        reArm();\n                    } else {\n                        delete activeConnections[remoteEndPoint];\n                        console.log(\"Ending polling for \", remoteEndPoint);\n                    }\n                }\n            });\n        }\n        reArm();\n    }\n\n    function pollingHandler(){\n        let setTimer = false;\n        for(const remoteEndPoint in pollSet){\n            if(!pollSet.hasOwnProperty(remoteEndPoint)) {return;}\n\n            if(!activeConnections[remoteEndPoint]){\n                createPollThread(remoteEndPoint);\n                activeConnections[remoteEndPoint] = true;\n            }\n            setTimer = true;\n        }\n        if(setTimer) {\n            setTimeout(pollingHandler, pollingTimeOut);\n        }\n    }\n\n    setTimeout( pollingHandler, pollingTimeOut);\n}\n\n\nfunction extractDomainAgentDetails(url){\n    const vRegex = /([a-zA-Z0-9]*|.)*\\/agent\\/([a-zA-Z0-9]+(\\/)*)+/g;\n\n    if(!url.match(vRegex)){\n        throw new Error(\"Invalid format. (Eg. domain[.subdomain]*/agent/[organisation/]*agentId)\");\n    }\n\n    const devider = \"/agent/\";\n    let domain;\n    let agentUrl;\n\n    const splitPoint = url.indexOf(devider);\n    if(splitPoint !== -1){\n        domain = url.slice(0, splitPoint);\n        agentUrl = url.slice(splitPoint+devider.length);\n    }\n\n    return {domain, agentUrl};\n}\n\nfunction urlEndWithSlash(url){\n\n    if(url[url.length - 1] !== \"/\"){\n        url += \"/\";\n    }\n\n    return url;\n}\n\nconst OwM = require(\"swarmutils\").OwM;\n\n/********************** main APIs on working with remote end points **********************************/\nfunction PskHttpClient(remoteEndPoint, agentUid, options){\n    const baseOfRemoteEndPoint = remoteEndPoint; //remove last id\n    let channelInitialized = false;\n    let channelInitStarted = false;\n\n    remoteEndPoint = urlEndWithSlash(remoteEndPoint);\n\n    //domainInfo contains 2 members: domain (privateSky domain) and agentUrl\n    const domainInfo = extractDomainAgentDetails(agentUid);\n    let homeSecurityContext = domainInfo.agentUrl;\n    let returnRemoteEndPoint = remoteEndPoint;\n\n    if(options && typeof options.returnRemote != \"undefined\"){\n        returnRemoteEndPoint = options.returnRemote;\n    }\n\n    if(!options || options && (typeof options.uniqueId == \"undefined\" || options.uniqueId)){\n        homeSecurityContext += \"_\"+Math.random().toString(36).substr(2, 9);\n    }\n\n    returnRemoteEndPoint = urlEndWithSlash(returnRemoteEndPoint);\n\n    this.startSwarm = function(swarmName, phaseName, ...args){\n        const swarm = new OwM();\n        swarm.setMeta(\"swarmId\", $$.uidGenerator.safe_uuid());\n        swarm.setMeta(\"requestId\", swarm.getMeta(\"swarmId\"));\n        swarm.setMeta(\"swarmTypeName\", swarmName);\n        swarm.setMeta(\"phaseName\", phaseName);\n        swarm.setMeta(\"args\", args);\n        swarm.setMeta(\"command\", \"executeSwarmPhase\");\n        swarm.setMeta(\"target\", domainInfo.agentUrl);\n        swarm.setMeta(\"homeSecurityContext\", getRemoteToSendMessage(returnRemoteEndPoint, homeSecurityContext));\n\n        const requestToBeReturned = $$.remote.requestManager.createRequest(getRemoteToReceiveMessage(returnRemoteEndPoint, homeSecurityContext), swarm, true);\n\n        if(!channelInitialized && channelInitStarted === false) {\n            channelInitStarted = true;\n            $$.remote.doHttpPut(getRemoteToCreateChannel(returnRemoteEndPoint, homeSecurityContext), 'someSignature', (err) => {\n                if(err && err.statusCode !== 409) {\n                    console.error(err, err.statusCode);\n                    requestToBeReturned.dispatchError(err);\n                    channelInitialized = false;\n                    return;\n                }\n\n                channelInitialized = true;\n                requestToBeReturned.start();\n                $$.remote.doHttpPost(getRemoteToSendMessage(remoteEndPoint, domainInfo.domain), SwarmPacker.pack(swarm), function (err, res) {\n                    if (err) {\n                        requestToBeReturned.dispatchError(err);\n                    }\n                });\n            });\n        } else {\n            requestToBeReturned.start();\n            $$.remote.doHttpPost(getRemoteToSendMessage(remoteEndPoint, domainInfo.domain), SwarmPacker.pack(swarm), function (err, res) {\n                if (err) {\n                    requestToBeReturned.dispatchError(err);\n                }\n            });\n        }\n\n        return requestToBeReturned;\n    };\n\n    this.continueSwarm = function(existingSwarm, phaseName, ...args){\n        const swarm = new OwM(existingSwarm);\n        swarm.setMeta(\"phaseName\", phaseName);\n        swarm.setMeta(\"args\", args);\n        swarm.setMeta(\"command\", \"executeSwarmPhase\");\n        swarm.setMeta(\"target\", domainInfo.agentUrl);\n        swarm.setMeta(\"homeSecurityContext\", returnRemoteEndPoint+$$.remote.base64Encode(homeSecurityContext));\n\n        $$.remote.doHttpPost(getRemoteToSendMessage(remoteEndPoint, domainInfo.domain), SwarmPacker.pack(swarm), function(err, res){\n            if(err){\n                console.log(err);\n            }\n        });\n        //return $$.remote.requestManager.createRequest(swarm.getMeta(\"homeSecurityContext\"), swarm);\n    };\n\n    const allCatchAlls = [];\n    let requestsCounter = 0;\n\n    function CatchAll(swarmName, phaseName, callback){ //same interface as Request\n        const requestId = requestsCounter++;\n        this.getRequestId = function(){\n            return \"swarmName\" + \"phaseName\" + requestId;\n        };\n\n        this.dispatch = function(err, result){\n            result = OwM.prototype.convert(result);\n            const currentPhaseName = result.getMeta(\"phaseName\");\n            const currentSwarmName = result.getMeta(\"swarmTypeName\");\n            if((currentSwarmName === swarmName || swarmName === '*') && (currentPhaseName === phaseName || phaseName === '*')) {\n                return callback(err, result);\n            }\n        };\n    }\n\n    this.on = function(swarmName, phaseName, callback){\n        const c = new CatchAll(swarmName, phaseName, callback);\n        allCatchAlls.push({\n            s:swarmName,\n            p:phaseName,\n            c:c\n        });\n\n        if(!channelInitialized) {\n            $$.remote.doHttpPut(getRemoteToCreateChannel(returnRemoteEndPoint, homeSecurityContext), 'someSignature', (err) => {\n                if(err) {\n                    if(err.statusCode !== 409) {\n                        channelInitialized = false;\n                        c.dispatch(err); // should this be here?\n                        return;\n                    }\n                }\n\n                channelInitialized = true;\n                $$.remote.requestManager.poll(getRemoteToReceiveMessage(remoteEndPoint, domainInfo.domain) , c);\n            });\n        } else {\n            $$.remote.requestManager.poll(getRemoteToReceiveMessage(remoteEndPoint, domainInfo.domain) , c);\n        }\n\n    };\n\n    this.off = function(swarmName, phaseName){\n        allCatchAlls.forEach(function(ca){\n            if((ca.s === swarmName || swarmName === '*') && (phaseName === ca.p || phaseName === '*')){\n                $$.remote.requestManager.unpoll(getRemoteToReceiveMessage(remoteEndPoint, domainInfo.domain), ca.c);\n            }\n        });\n    };\n\n    this.uploadCSB = function(cryptoUid, binaryData, callback){\n        $$.remote.doHttpPost(baseOfRemoteEndPoint + \"/CSB/\" + cryptoUid, binaryData, callback);\n    };\n\n    this.downloadCSB = function(cryptoUid, callback){\n        $$.remote.doHttpGet(baseOfRemoteEndPoint + \"/CSB/\" + cryptoUid, callback);\n    };\n\n    function getRemoteToReceiveMessage(baseUrl, domain){\n        return [urlEndWithSlash(baseUrl), receiveEndpoint, $$.remote.base64Encode(domain)].join(\"\");\n    }\n\n    function getRemoteToSendMessage(baseUrl, domain){\n        return [urlEndWithSlash(baseUrl), sendEndpoint, $$.remote.base64Encode(domain)].join(\"\");\n    }\n\n    function getRemoteToCreateChannel(baseUrl, domain) {\n        return [urlEndWithSlash(baseUrl), createChannelEndpoint, $$.remote.base64Encode(domain)].join(\"\");\n\n    }\n}\n\n/********************** initialisation stuff **********************************/\nif (typeof $$ === \"undefined\") {\n    $$ = {};\n}\n\nif (typeof  $$.remote === \"undefined\") {\n    $$.remote = {};\n    $$.remote.createRequestManager = function(timeOut){\n        $$.remote.requestManager = new RequestManager(timeOut);\n    };\n\n\n    $$.remote.cryptoProvider = null;\n    $$.remote.newEndPoint = function(alias, remoteEndPoint, agentUid, options){\n        if(alias === \"newRemoteEndPoint\" || alias === \"requestManager\" || alias === \"cryptoProvider\"){\n            console.log(\"PskHttpClient Unsafe alias name:\", alias);\n            return null;\n        }\n\n        $$.remote[alias] = new PskHttpClient(remoteEndPoint, agentUid, options);\n    };\n\n\n    $$.remote.doHttpPost = function (url, data, callback){\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.doHttpPut = function (url, data, callback){\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.doHttpGet = function doHttpGet(url, callback){\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.base64Encode = function base64Encode(stringToEncode){\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.base64Decode = function base64Decode(encodedString){\n        throw new Error(\"Overwrite this!\");\n    };\n}\n\n/*  interface\nfunction CryptoProvider(){\n\n    this.generateSafeUid = function(){\n\n    }\n\n    this.signSwarm = function(swarm, agent){\n\n    }\n} */\n","function generateMethodForRequestWithData(httpMethod) {\n    return function (url, data, callback) {\n        const xhr = new XMLHttpRequest();\n\n        xhr.onload = function () {\n            if (xhr.readyState === 4 && (xhr.status >= 200 && xhr.status < 300)) {\n                const data = xhr.response;\n                callback(null, data);\n            } else {\n                if(xhr.status>=400){\n                    const error = new Error(\"An error occured. StatusCode: \" + xhr.status);\n                    callback({error: error, statusCode: xhr.status});\n                } else {\n                    console.log(`Status code ${xhr.status} received, response is ignored.`);\n                }\n            }\n        };\n\n        xhr.open(httpMethod, url, true);\n        //xhr.setRequestHeader(\"Content-Type\", \"application/json;charset=UTF-8\");\n\n        if(data && data.pipe && typeof data.pipe === \"function\"){\n            const buffers = [];\n            data.on(\"data\", function(data) {\n                buffers.push(data);\n            });\n            data.on(\"end\", function() {\n                const actualContents = Buffer.concat(buffers);\n                xhr.send(actualContents);\n            });\n        }\n        else {\n            if(ArrayBuffer.isView(data) || data instanceof ArrayBuffer) {\n                xhr.setRequestHeader('Content-Type', 'application/octet-stream');\n            }\n\n            xhr.send(data);\n        }\n    };\n}\n\n\n$$.remote.doHttpPost = generateMethodForRequestWithData('POST');\n\n$$.remote.doHttpPut = generateMethodForRequestWithData('PUT');\n\n\n$$.remote.doHttpGet = function doHttpGet(url, callback) {\n\n    var xhr = new XMLHttpRequest();\n\n    xhr.onreadystatechange = function () {\n        //check if headers were received and if any action should be performed before receiving data\n        if (xhr.readyState === 2) {\n            var contentType = xhr.getResponseHeader(\"Content-Type\");\n            if (contentType === \"application/octet-stream\") {\n                xhr.responseType = 'arraybuffer';\n            }\n        }\n    };\n\n    xhr.onload = function () {\n\n        if (xhr.readyState === 4 && xhr.status == \"200\") {\n            var contentType = xhr.getResponseHeader(\"Content-Type\");\n\n            if(contentType===\"application/octet-stream\"){\n                let responseBuffer = this.response;\n                callback(null, responseBuffer);\n            }\n            else{\n                callback(null, xhr.response);\n            }\n\n        } else {\n            callback(new Error(\"An error occured. StatusCode: \" + xhr.status));\n        }\n    };\n\n    xhr.open(\"GET\", url);\n    xhr.send();\n};\n\n\nfunction CryptoProvider(){\n\n    this.generateSafeUid = function(){\n        let uid = \"\";\n        var array = new Uint32Array(10);\n        window.crypto.getRandomValues(array);\n\n\n        for (var i = 0; i < array.length; i++) {\n            uid += array[i].toString(16);\n        }\n\n        return uid;\n    }\n\n    this.signSwarm = function(swarm, agent){\n        swarm.meta.signature = agent;\n    }\n}\n\n\n\n$$.remote.cryptoProvider = new CryptoProvider();\n\n$$.remote.base64Encode = function base64Encode(stringToEncode){\n    return window.btoa(stringToEncode);\n};\n\n$$.remote.base64Decode = function base64Decode(encodedString){\n    return window.atob(encodedString);\n};\n","require(\"./psk-abstract-client\");\n\nconst http = require(\"http\");\nconst https = require(\"https\");\nconst URL = require(\"url\");\nconst userAgent = 'PSK NodeAgent/0.0.1';\nconst signatureHeaderName = process.env.vmq_signature_header_name || \"x-signature\";\n\n\nconsole.log(\"PSK node client loading\");\n\nfunction getNetworkForOptions(options) {\n\tif(options.protocol === 'http:') {\n\t\treturn http;\n\t} else if(options.protocol === 'https:') {\n\t\treturn https;\n\t} else {\n\t\tthrow new Error(`Can't handle protocol ${options.protocol}`);\n\t}\n\n}\n\nfunction generateMethodForRequestWithData(httpMethod) {\n\treturn function (url, data, callback) {\n\t\tconst innerUrl = URL.parse(url);\n\n\t\tconst options = {\n\t\t\thostname: innerUrl.hostname,\n\t\t\tpath: innerUrl.pathname,\n\t\t\tport: parseInt(innerUrl.port),\n\t\t\theaders: {\n\t\t\t\t'User-Agent': userAgent,\n\t\t\t\t[signatureHeaderName]: 'replaceThisPlaceholderSignature'\n\t\t\t},\n\t\t\tmethod: httpMethod\n\t\t};\n\n\t\tconst network = getNetworkForOptions(innerUrl);\n\n\t\tif (ArrayBuffer.isView(data) || Buffer.isBuffer(data) || data instanceof ArrayBuffer) {\n\t\t\tif (!Buffer.isBuffer(data)) {\n\t\t\t\tdata = Buffer.from(data);\n\t\t\t}\n\n\t\t\toptions.headers['Content-Type'] = 'application/octet-stream';\n\t\t\toptions.headers['Content-Length'] = data.length;\n\t\t}\n\n\t\tconst req = network.request(options, (res) => {\n\t\t\tconst {statusCode} = res;\n\n\t\t\tlet error;\n\t\t\tif (statusCode >= 400) {\n\t\t\t\terror = new Error('Request Failed.\\n' +\n\t\t\t\t\t`Status Code: ${statusCode}\\n` +\n\t\t\t\t\t`URL: ${options.hostname}:${options.port}${options.path}`);\n\t\t\t}\n\n\t\t\tif (error) {\n\t\t\t\tcallback({error: error, statusCode: statusCode});\n\t\t\t\t// free up memory\n\t\t\t\tres.resume();\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tlet rawData = '';\n\t\t\tres.on('data', (chunk) => {\n\t\t\t\trawData += chunk;\n\t\t\t});\n\t\t\tres.on('end', () => {\n\t\t\t\ttry {\n\t\t\t\t\treturn callback(null, rawData, res.headers);\n\t\t\t\t} catch (err) {\n\t\t\t\t\treturn callback(err);\n\t\t\t\t}\n\t\t\t});\n\t\t}).on(\"error\", (error) => {\n\t\t\tconsole.log(\"POST Error\", error);\n\t\t\tcallback(error);\n\t\t});\n\n\t\tif (data && data.pipe && typeof data.pipe === \"function\") {\n\t\t\tdata.pipe(req);\n\t\t\treturn;\n\t\t}\n\n\t\tif (typeof data !== 'string' && !Buffer.isBuffer(data) && !ArrayBuffer.isView(data)) {\n\t\t\tdata = JSON.stringify(data);\n\t\t}\n\n\t\treq.write(data);\n\t\treq.end();\n\t};\n}\n\n$$.remote.doHttpPost = generateMethodForRequestWithData('POST');\n\n$$.remote.doHttpPut = generateMethodForRequestWithData('PUT');\n\n$$.remote.doHttpGet = function doHttpGet(url, callback){\n    const innerUrl = URL.parse(url);\n\n\tconst options = {\n\t\thostname: innerUrl.hostname,\n\t\tpath: innerUrl.pathname + (innerUrl.search || ''),\n\t\tport: parseInt(innerUrl.port),\n\t\theaders: {\n\t\t\t'User-Agent': userAgent,\n            [signatureHeaderName]: 'someSignature'\n\t\t},\n\t\tmethod: 'GET'\n\t};\n\n\tconst network = getNetworkForOptions(innerUrl);\n\n\tconst req = network.request(options, (res) => {\n\t\tconst { statusCode } = res;\n\n\t\tlet error;\n\t\tif (statusCode !== 200) {\n\t\t\terror = new Error('Request Failed.\\n' +\n\t\t\t\t`Status Code: ${statusCode}`);\n\t\t\terror.code = statusCode;\n\t\t}\n\n\t\tif (error) {\n\t\t\tcallback({error:error, statusCode:statusCode});\n\t\t\t// free up memory\n\t\t\tres.resume();\n\t\t\treturn\n\t\t}\n\n\t\tlet rawData;\n\t\tconst contentType = res.headers['content-type'];\n\n\t\tif(contentType === \"application/octet-stream\"){\n\t\t\trawData = [];\n\t\t}else{\n\t\t\trawData = '';\n\t\t}\n\n\t\tres.on('data', (chunk) => {\n\t\t\tif(Array.isArray(rawData)){\n\t\t\t\trawData.push(...chunk);\n\t\t\t}else{\n\t\t\t\trawData += chunk;\n\t\t\t}\n\t\t});\n\t\tres.on('end', () => {\n\t\t\ttry {\n\t\t\t\tif(Array.isArray(rawData)){\n\t\t\t\t\trawData = Buffer.from(rawData);\n\t\t\t\t}\n\t\t\t\treturn callback(null, rawData, res.headers);\n\t\t\t} catch (err) {\n\t\t\t\tconsole.log(\"Client error:\", err);\n\t\t\t}\n\t\t});\n\t});\n\n\treq.on(\"error\", (error) => {\n\t\tif(error && error.code !== 'ECONNRESET'){\n        \tconsole.log(\"GET Error\", error);\n\t\t}\n\n\t\tcallback(error);\n\t});\n\n\treq.end();\n};\n\n$$.remote.base64Encode = function base64Encode(stringToEncode){\n    return Buffer.from(stringToEncode).toString('base64');\n};\n\n$$.remote.base64Decode = function base64Decode(encodedString){\n    return Buffer.from(encodedString, 'base64').toString('ascii');\n};\n","const AsyncDispatcher = require(\"../utils/AsyncDispatcher\");\nconst EVFSResolver = require(\"./backupResolvers/EVFSResolver\");\n// const crypto = require(\"pskcrypto\");\n\nfunction BackupEngineBuilder() {\n    const resolvers = {};\n    this.addResolver = function (name, resolver) {\n        resolvers[name] = resolver;\n    };\n\n    this.getBackupEngine = function(urls) {\n        if (!urls || urls.length === 0) {\n            throw new Error(\"No url was provided\");\n        }\n\n        return new BackupEngine(urls, resolvers);\n    };\n}\n\nfunction BackupEngine(urls, resolvers) {\n\n    this.save = function (csbIdentifier, dataStream, callback) {\n        const asyncDispatcher = new AsyncDispatcher(callback);\n        asyncDispatcher.dispatchEmpty(urls.length);\n        for (const url of urls) {\n            resolverForUrl(url, (err, resolver) => {\n                if(err){\n                    return callback(err);\n                }\n                resolver.auth(url, undefined, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    resolver.save(url, csbIdentifier, dataStream, (err) => {\n                        if (err) {\n                            asyncDispatcher.markOneAsFinished(err);\n                            return;\n                        }\n                        asyncDispatcher.markOneAsFinished(undefined, url);\n                    });\n                });\n            });\n        }\n    };\n\n    this.load = function (csbIdentifier, version, callback) {\n        if (typeof version === \"function\") {\n            callback = version;\n            version = \"\";\n        }\n\n        tryDownload(csbIdentifier, version, 0, (err, resource) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, resource);\n        });\n    };\n\n    this.getVersions = function (csbIdentifier, callback) {\n        console.log(\"Empty function\");\n    };\n\n    this.compareVersions = function (fileList, callback) {\n        const url = urls[0];\n        resolverForUrl(url, (err, resolver) => {\n            if (err) {\n                return callback(err);\n            }\n\n            resolver.auth(url, undefined, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                resolver.compareVersions(url, fileList, callback);\n            });\n        });\n    };\n\n    //------------------------------------------------ INTERNAL METHODS ------------------------------------------------\n\n    function resolverForUrl(url, callback) {\n        const keys = Object.keys(resolvers);\n        let resolver;\n        let i;\n\n        for (i = 0; i < keys.length; ++i) {\n            if (match(keys[i], url)) {\n                resolver = resolvers[keys[i]];\n                break;\n            }\n        }\n\n        if (i === keys.length) {\n            resolver = resolvers['evfs'];\n            if (!resolver) {\n                return callback(new Error(`No resolver matches the url ${url}`));\n            }\n        }\n\n        callback(undefined, resolver);\n    }\n\n    function match(str1, str2) {\n        return str1.includes(str2) || str2.includes(str1);\n    }\n\n\n    function tryDownload(csbIdentifier, version, index, callback) {\n        if (index === urls.length) {\n            return callback(new Error(\"Failed to download resource\"));\n        }\n\n        const url = urls[index];\n        resolverForUrl(url, (err, resolver) => {\n            if (err) {\n                return callback(err);\n            }\n\n            resolver.auth(url, undefined, (err) => {\n                if (err) {\n                    return tryDownload(csbIdentifier, version, ++index, callback);\n                }\n\n                resolver.load(url, csbIdentifier, version, (err, resource) =>{\n                    if (err) {\n                        return tryDownload(csbIdentifier, version, ++index, callback);\n                    }\n\n                    callback(undefined, resource);\n                });\n            });\n\n        });\n    }\n}\n\nconst engineBuilder = new BackupEngineBuilder();\n\n// engineBuilder.addResolver('dropbox', new DropboxResolver());\n// engineBuilder.addResolver('drive', new DriveResolver());\nengineBuilder.addResolver('evfs', new EVFSResolver());\n\nmodule.exports = {\n    getBackupEngine: function (urls) {\n        return engineBuilder.getBackupEngine(urls);\n    }\n};\n"," function CSBCache(maxSize) {\n\n     let cache = {};\n    let size = 0;\n    const clearingRatio = 0.5;\n\n\n    this.load = function (uid) {\n        // if (cache[uid]) {\n        //     cache[uid].count += 1;\n        //     return cache[uid].instance;\n        // }\n\n        return undefined;\n    };\n\n    this.put = function (uid, obj) {\n        if (size > maxSize) {\n            clear();\n        } else {\n            size++;\n            cache[uid] = {\n                instance: obj,\n                count: 0\n            };\n        }\n\n    };\n\n    //-------------------------internal methods---------------------------------------\n\n    function clear() {\n        size = maxSize - Math.round(clearingRatio * maxSize);\n\n        const entries = Object.entries(cache);\n        cache = entries\n            .sort((arr1, arr2) => arr2[1].count - arr1[1].count)\n            .slice(0, size)\n            .reduce((obj, [ k, v ]) => {\n                obj[k] = v;\n                return obj;\n            }, {});\n    }\n}\n\nmodule.exports = CSBCache;\n","const crypto = require(\"pskcrypto\");\n\n\nfunction CSBIdentifier(id, backupUrls, keyLen = 32) {\n    let seed;\n    let dseed;\n    let uid;\n    let encSeed;\n    // let encDseed;\n\n    init();\n\n    this.getSeed = function () {\n        if(!seed){\n            throw new Error(\"Cannot return seed. Access is denied.\");\n        }\n\n        return generateCompactForm(seed);\n    };\n\n    this.getDseed = function () {\n        if(dseed){\n            return generateCompactForm(dseed);\n        }\n\n        if(seed){\n            dseed = deriveSeed(seed);\n            return generateCompactForm(dseed);\n        }\n\n        throw new Error(\"Cannot return derived seed. Access is denied.\");\n    };\n\n    this.getUid = function () {\n        if(uid){\n            return generateCompactForm(uid).toString();\n        }\n\n        if(dseed){\n            uid = computeUid(dseed);\n            return generateCompactForm(uid).toString();\n        }\n\n        if(seed){\n            dseed = deriveSeed(seed);\n            uid = computeUid(dseed);\n            return generateCompactForm(uid).toString();\n        }\n\n        throw new Error(\"Cannot return uid\");\n    };\n\n    this.getEncSeed = function (encryptionKey) {\n        if(encSeed){\n            return generateCompactForm(encSeed);\n        }\n\n        if(!seed){\n            throw new Error(\"Cannot return encSeed. Access is denied\");\n        }\n\n        if (!encryptionKey) {\n            throw new Error(\"Cannot return encSeed. No encryption key was provided\");\n        }\n\n        //TODO: encrypt seed using encryptionKey. Encryption algorithm remains to be chosen\n    };\n\n\n\n    this.getBackupUrls = function () {\n        if(seed){\n            return seed.backup;\n        }\n\n        if(dseed){\n            return dseed.backup;\n        }\n\n        throw new Error(\"Backup URLs could not be retrieved. Access is denied\");\n    };\n\n    //------------------------------ internal methods ------------------------------\n    function init() {\n        if (!id) {\n            if (!backupUrls) {\n                throw new Error(\"No backups provided.\");\n            }\n\n            seed = create();\n        }else{\n            classifyId();\n        }\n    }\n\n    function classifyId() {\n        if (typeof id !== \"string\" && !Buffer.isBuffer(id) && !(typeof id === \"object\" && !Buffer.isBuffer(id))) {\n            throw new Error(`Id must be a string or a buffer. The type provided was ${typeof id}`);\n        }\n\n        const expandedId = load(id);\n        switch(expandedId.tag){\n            case 's':\n                seed = expandedId;\n                break;\n            case 'd':\n                dseed = expandedId;\n                break;\n            case 'u':\n                uid = expandedId;\n                break;\n            case 'es':\n                encSeed = expandedId;\n                break;\n            case 'ed':\n                encDseed = expandedId;\n                break;\n            default:\n                throw new Error('Invalid tag');\n        }\n    }\n\n\n\n    function create() {\n        const localSeed = {};\n        if (!Array.isArray(backupUrls)) {\n            backupUrls = [ backupUrls ];\n        }\n\n        localSeed.tag    = 's';\n        localSeed.random = crypto.randomBytes(keyLen);\n        localSeed.backup = backupUrls;\n\n        return localSeed;\n    }\n\n    function deriveSeed(seed) {\n        let compactSeed = seed;\n\n        if (typeof seed === 'object' && !Buffer.isBuffer(seed)) {\n            compactSeed = generateCompactForm(seed);\n        }\n\n        if (Buffer.isBuffer(seed)) {\n            compactSeed = seed.toString();\n        }\n\n        if (compactSeed[0] === 'd') {\n            throw new Error('Tried to derive an already derived seed.');\n        }\n\n        const decodedCompactSeed = decodeURIComponent(compactSeed);\n        const splitCompactSeed = decodedCompactSeed.substring(1).split('|');\n\n        const strSeed = Buffer.from(splitCompactSeed[0], 'base64').toString('hex');\n        const backupUrls = Buffer.from(splitCompactSeed[1], 'base64').toString();\n        const dseed = {};\n\n        dseed.tag = 'd';\n        dseed.random = crypto.deriveKey(strSeed, null, keyLen);\n        dseed.backup = JSON.parse(backupUrls);\n\n        return dseed;\n    }\n\n    function computeUid(dseed){\n        if(!dseed){\n            throw new Error(\"Dseed was not provided\");\n        }\n\n        if (typeof dseed === \"object\" && !Buffer.isBuffer(dseed)) {\n            dseed = generateCompactForm(dseed);\n        }\n\n        const uid = {};\n        uid.tag = 'u';\n        uid.random = Buffer.from(crypto.generateSafeUid(dseed));\n\n        return uid;\n    }\n\n    function generateCompactForm({tag, random, backup}) {\n        let compactId = tag + random.toString('base64');\n        if (backup) {\n            compactId += '|' + Buffer.from(JSON.stringify(backup)).toString('base64');\n        }\n        return Buffer.from(encodeURIComponent(compactId));\n    }\n\n    function encrypt(id, encryptionKey) {\n        if(arguments.length !== 2){\n            throw new Error(`Wrong number of arguments. Expected: 2; provided ${arguments.length}`);\n        }\n\n        let tag;\n        if (typeof id === \"object\" && !Buffer.isBuffer(id)) {\n            tag = id.tag;\n            id = generateCompactForm(id);\n        }\n\n        if (tag === 's') {\n            //TODO encrypt seed\n        }else if (tag === 'd') {\n            //TODO encrypt dseed\n        }else{\n            throw new Error(\"The provided id cannot be encrypted\");\n        }\n\n    }\n\n    function load(compactId) {\n        if(typeof compactId === \"undefined\") {\n            throw new Error(`Expected type string or Buffer. Received undefined`);\n        }\n\n        if(typeof compactId !== \"string\"){\n            if (typeof compactId === \"object\" && !Buffer.isBuffer(compactId)) {\n                compactId = Buffer.from(compactId);\n            }\n\n            compactId = compactId.toString();\n        }\n\n        const decodedCompactId = decodeURIComponent(compactId);\n        const id = {};\n        const splitCompactId = decodedCompactId.substring(1).split('|');\n\n        id.tag = decodedCompactId[0];\n        id.random = Buffer.from(splitCompactId[0], 'base64');\n\n        if(splitCompactId[1] && splitCompactId[1].length > 0){\n            id.backup = JSON.parse(Buffer.from(splitCompactId[1], 'base64').toString());\n        }\n\n        return id;\n    }\n}\n\nmodule.exports = CSBIdentifier;\n","const OwM = require('swarmutils').OwM;\nconst pskdb = require('pskdb');\n\nfunction RawCSB(initData) {\n\tconst data = new OwM({blockchain: initData});\n\tconst blockchain = pskdb.startDb({getInitValues, persist});\n\n\tif(!data.blockchain) {\n\t\tdata.blockchain = {\n\t\t\ttransactionLog : '',\n\t\t\tembeddedFiles: {}\n\t\t};\n\t}\n\n\tdata.embedFile = function (fileAlias, fileData) {\n\t\tconst embeddedAsset = data.getAsset(\"global.EmbeddedFile\", fileAlias);\n\t\tif(embeddedAsset.isPersisted()){\n\t\t\tconsole.log(`File with alias ${fileAlias} already exists`);\n\t\t\treturn;\n\t\t}\n\n\t\tdata.blockchain.embeddedFiles[fileAlias] = fileData;\n\t\tdata.saveAsset(embeddedAsset);\n\t};\n\n\tdata.attachFile = function (fileAlias, path, seed) {\n\t\tdata.modifyAsset(\"global.FileReference\", fileAlias, (file) => {\n\t\t\tif (!file.isEmpty()) {\n\t\t\t\tconsole.log(`File with alias ${fileAlias} already exists`);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfile.init(fileAlias, path, seed);\n\t\t});\n\t};\n\n\tdata.saveAsset = function(asset) {\n\t\tconst transaction = blockchain.beginTransaction({});\n\t\ttransaction.add(asset);\n\t\tblockchain.commit(transaction);\n\t};\n\n\tdata.modifyAsset = function(assetType, aid, assetModifier) {\n\t\tconst transaction = blockchain.beginTransaction({});\n\t\tconst asset = transaction.lookup(assetType, aid);\n\t\tassetModifier(asset);\n\n\t\ttransaction.add(asset);\n\t\tblockchain.commit(transaction);\n\t};\n\n\tdata.getAsset = function (assetType, aid) {\n\t\tconst transaction = blockchain.beginTransaction({});\n\t\treturn transaction.lookup(assetType, aid);\n\t};\n\n\tdata.getAllAssets = function(assetType) {\n\t\tconst transaction = blockchain.beginTransaction({});\n\t\treturn transaction.loadAssets(assetType);\n\t};\n\n\t/* internal functions */\n\n\tfunction persist(transactionLog, currentValues, currentPulse) {\n\t\ttransactionLog.currentPulse = currentPulse;\n\n\t\tdata.blockchain.currentValues = currentValues;\n\t\tdata.blockchain.transactionLog += mkSingleLine(JSON.stringify(transactionLog)) + \"\\n\";\n\t}\n\n\tfunction getInitValues () {\n\t\tif(!data.blockchain || !data.blockchain.currentValues) {\n\t\t\treturn null;\n\t\t}\n\t\treturn data.blockchain.currentValues;\n\t}\n\n\tfunction mkSingleLine(str) {\n\t\treturn str.replace(/\\n|\\r/g, \"\");\n\t}\n\n\treturn data;\n}\n\nmodule.exports = RawCSB;","const RawCSB = require('./RawCSB');\nconst fs = require('fs');\nconst crypto = require('pskcrypto');\nconst utils = require('../utils/utils');\nconst DseedCage = require('../utils/DseedCage');\nconst HashCage = require('../utils/HashCage');\nconst CSBCache = require(\"./CSBCache\");\nconst CSBIdentifier = require(\"./CSBIdentifier\");\nconst EventEmitter = require('events');\n\nconst rawCSBCache = new CSBCache(10);\nconst instances = {};\n\n/**\n *\n * @param localFolder   - required\n * @param currentRawCSB - optional\n * @param csbIdentifier - required\n * @constructor\n */\nfunction RootCSB(localFolder, currentRawCSB, csbIdentifier) {\n    if (!localFolder || !csbIdentifier) {\n        throw new Error('Missing required parameters');\n    }\n\n\n    const hashCage = new HashCage(localFolder);\n    const event = new EventEmitter();\n    this.on = event.on;\n    this.off = event.removeListener;\n    this.removeAllListeners = event.removeAllListeners;\n    this.emit = event.emit;\n\n    this.getMidRoot = function (CSBPath, callback) {\n        throw new Error('Not implemented');\n    };\n\n    this.loadRawCSB = function (CSBPath, callback) {\n        if (!currentRawCSB) {\n            __loadRawCSB(csbIdentifier, (err, rawCSB) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                currentRawCSB = rawCSB;\n\n                if (CSBPath || CSBPath !== '') {\n                    this.loadRawCSB(CSBPath, callback);\n                    return;\n                }\n\n                callback(undefined, currentRawCSB);\n            });\n            return;\n        }\n        if (!CSBPath || CSBPath === '') {\n            return callback(null, currentRawCSB);\n        }\n\n        this.loadAssetFromPath(CSBPath, (err, asset, rawCSB) => {\n\n            if (err) {\n                return callback(err);\n            }\n\n            if (!asset || !asset.dseed) {\n                return callback(new Error(`The CSBPath ${CSBPath} is invalid.`));\n            }\n\n            __loadRawCSB(new CSBIdentifier(asset.dseed), callback);\n        });\n    };\n\n    this.saveRawCSB = function (rawCSB, CSBPath, callback) {\n        // save master\n        if (!CSBPath || CSBPath === '') {\n            if (rawCSB) {\n                currentRawCSB = rawCSB;\n            }\n\n            __initializeAssets(currentRawCSB);\n            return __writeRawCSB(currentRawCSB, csbIdentifier, callback);\n        }\n\n        // save csb in hierarchy\n        const splitPath = __splitPath(CSBPath);\n        this.loadAssetFromPath(CSBPath, (err, csbReference) => {\n            if (err) {\n                return callback(err);\n            }\n            if (!csbReference.dseed) {\n                const backups = csbIdentifier.getBackupUrls();\n                const newCSBIdentifier = new CSBIdentifier(undefined, backups);\n                const localSeed = newCSBIdentifier.getSeed();\n                const localDseed = newCSBIdentifier.getDseed();\n                csbReference.init(splitPath.assetAid, localSeed, localDseed);\n\n                this.saveAssetToPath(CSBPath, csbReference, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    this.loadAssetFromPath(CSBPath, (err, csbRef) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        __initializeAssets(rawCSB, csbRef, backups);\n                        __writeRawCSB(rawCSB, new CSBIdentifier(csbReference.dseed), (err) => {\n                            if (err) {\n                                return callback(err);\n                            }\n\n                            this.emit('end');\n                            callback();\n                        });\n                    });\n                });\n            } else {\n                __writeRawCSB(rawCSB, new CSBIdentifier(csbReference.dseed), callback);\n            }\n        });\n    };\n\n    this.saveAssetToPath = function (CSBPath, asset, callback) {\n        const splitPath = __splitPath(CSBPath, {keepAliasesAsString: true});\n        this.loadRawCSB(splitPath.CSBAliases, (err, rawCSB) => {\n            if (err) {\n                return callback(err);\n            }\n            try {\n                rawCSB.saveAsset(asset);\n                this.saveRawCSB(rawCSB, splitPath.CSBAliases, callback);\n            } catch (e) {\n                return callback(e);\n            }\n        });\n    };\n\n    this.loadAssetFromPath = function (CSBPath, callback) {\n        const processedPath = __splitPath(CSBPath);\n        if (!currentRawCSB) {\n            return callback(new Error('currentRawCSB does not exist'));\n        }\n\n        let CSBReference = null;\n        if (processedPath.CSBAliases.length > 0) {\n            const nextAlias = processedPath.CSBAliases[0];\n            CSBReference = currentRawCSB.getAsset('global.CSBReference', nextAlias);\n        } else {\n            if (!processedPath.assetType || !processedPath.assetAid) {\n                return callback(new Error('Not asset type or id specified in CSBPath'));\n            }\n\n            CSBReference = currentRawCSB.getAsset(processedPath.assetType, processedPath.assetAid);\n        }\n\n        if (processedPath.CSBAliases.length === 0) {\n            return callback(null, CSBReference, currentRawCSB);\n        }\n\n        processedPath.CSBAliases.shift();\n\n        if(!CSBReference || !CSBReference.dseed){\n            return callback(new Error(`The CSBPath ${CSBPath} is invalid`));\n        }\n        __loadAssetFromPath(processedPath, new CSBIdentifier(CSBReference.dseed), 0, callback);\n    };\n\n\n    /* ------------------- INTERNAL METHODS ------------------- */\n\n    function __loadRawCSB(localCSBIdentifier, callback) {\n        const uid = localCSBIdentifier.getUid();\n        const cachedRawCSB = rawCSBCache.load(uid);\n\n        if (cachedRawCSB) {\n            return callback(null, cachedRawCSB);\n        }\n\n        const rootPath = utils.generatePath(localFolder, localCSBIdentifier);\n        fs.readFile(rootPath, (err, encryptedCsb) => {\n            if (err) {\n                return callback(err);\n            }\n\n            crypto.decryptObject(encryptedCsb, localCSBIdentifier.getDseed(), (err, csbData) => {\n                if (err) {\n                    return callback(err);\n                }\n                const csb = new RawCSB(csbData);\n                rawCSBCache.put(uid, csb);\n                callback(null, csb);\n            });\n        });\n    }\n\n    /**\n     *\n     * @param CSBPath: string - internal path that looks like /{CSBName1}/{CSBName2}:{assetType}:{assetAliasOrId}\n     * @param options:object\n     * @returns {{CSBAliases: [string], assetAid: (*|undefined), assetType: (*|undefined)}}\n     * @private\n     */\n    function __splitPath(CSBPath, options = {}) {\n        const pathSeparator = '/';\n\n        if (CSBPath.startsWith(pathSeparator)) {\n            CSBPath = CSBPath.substring(1);\n        }\n\n        let CSBAliases = CSBPath.split(pathSeparator);\n        if (CSBAliases.length < 1) {\n            throw new Error('CSBPath too short');\n        }\n\n        const lastIndex = CSBAliases.length - 1;\n        const optionalAssetSelector = CSBAliases[lastIndex].split(':');\n\n        if (optionalAssetSelector[0] === '') {\n            CSBAliases = [];\n        } else {\n            CSBAliases[lastIndex] = optionalAssetSelector[0];\n        }\n\n        if (!optionalAssetSelector[1] && !optionalAssetSelector[2]) {\n            optionalAssetSelector[1] = 'global.CSBReference';\n            optionalAssetSelector[2] = CSBAliases[lastIndex];\n            CSBAliases.pop();\n        }\n\n        if (options.keepAliasesAsString === true) {\n            CSBAliases = CSBAliases.join('/');\n        }\n        return {\n            CSBAliases: CSBAliases,\n            assetType: optionalAssetSelector[1],\n            assetAid: optionalAssetSelector[2]\n        };\n    }\n\n    function __loadAssetFromPath(processedPath, localCSBIdentifier, currentIndex, callback) {\n        __loadRawCSB(localCSBIdentifier, (err, rawCSB) => {\n            if (err) {\n                return callback(err);\n            }\n\n            if (currentIndex < processedPath.CSBAliases.length) {\n                const nextAlias = processedPath.CSBAliases[currentIndex];\n                const asset = rawCSB.getAsset(\"global.CSBReference\", nextAlias);\n                const newCSBIdentifier = new CSBIdentifier(asset.dseed);\n\n                __loadAssetFromPath(processedPath, newCSBIdentifier, ++currentIndex, callback);\n                return;\n            }\n\n            const asset = rawCSB.getAsset(processedPath.assetType, processedPath.assetAid);\n            callback(null, asset, rawCSB);\n\n        });\n\n    }\n\n    function __writeRawCSB(rawCSB, localCSBIdentifier, callback) {\n        crypto.encryptObject(rawCSB.blockchain, localCSBIdentifier.getDseed(), null, (err, encryptedBlockchain) => {\n            if (err) {\n                return callback(err);\n            }\n\n            hashCage.loadHash((err, hashObj) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                const key = localCSBIdentifier.getUid();\n                hashObj[key] = crypto.pskHash(encryptedBlockchain).toString('hex');\n\n                hashCage.saveHash(hashObj, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    fs.writeFile(utils.generatePath(localFolder, localCSBIdentifier), encryptedBlockchain, callback);\n                });\n            });\n        });\n    }\n\n    function __initializeAssets(rawCSB, csbRef, backupUrls) {\n\n        let isMaster;\n\n        const csbMeta = rawCSB.getAsset('global.CSBMeta', 'meta');\n        if (currentRawCSB === rawCSB) {\n            isMaster = typeof csbMeta.isMaster === 'undefined' ? true : csbMeta.isMaster;\n            if (!csbMeta.id) {\n                csbMeta.init($$.uidGenerator.safe_uuid());\n                csbMeta.setIsMaster(isMaster);\n                rawCSB.saveAsset(csbMeta);\n            }\n        } else {\n            backupUrls.forEach((url) => {\n                const uid = $$.uidGenerator.safe_uuid();\n                const backup = rawCSB.getAsset('global.Backup', uid);\n                backup.init(uid, url);\n                rawCSB.saveAsset(backup);\n            });\n\n            isMaster = typeof csbMeta.isMaster === 'undefined' ? false : csbMeta.isMaster;\n            csbMeta.init(csbRef.getMetadata('swarmId'));\n            csbMeta.setIsMaster(isMaster);\n            rawCSB.saveAsset(csbMeta);\n        }\n    }\n}\n\n\nfunction createRootCSB(localFolder, masterRawCSB, csbIdentifier, pin, callback) {\n    let masterDseed;\n\n    if (csbIdentifier) {\n        masterDseed = csbIdentifier.getDseed();\n        if (masterRawCSB) {\n            const rootCSB = new RootCSB(localFolder, masterRawCSB, masterDseed);\n            return callback(null, rootCSB);\n        }\n\n        return loadWithIdentifier(localFolder, masterDseed, callback);\n    } else if (pin) {\n\n        return loadWithPin(localFolder, pin, callback);\n    } else {\n        return callback(new Error('Missing seed, dseed and pin, at least one is required'));\n    }\n}\n\nfunction loadWithPin(localFolder, pin, callback) {\n    new DseedCage(localFolder).loadDseedBackups(pin, (err, csbIdentifier, backups) => {\n        if (err) {\n            return callback(err);\n        }\n\n        if (!csbIdentifier && (!backups || backups.length === 0)) {\n            return callback();\n        }\n\n        if (!csbIdentifier) {\n            return callback(undefined, undefined, undefined, backups);\n        }\n\n        const dseed = csbIdentifier.getDseed();\n        const key = crypto.generateSafeUid(dseed, localFolder);\n        if (!instances[key]) {\n            instances[key] = new RootCSB(localFolder, null, csbIdentifier);\n        }\n\n        const rootCSB = instances[key];\n\n        rootCSB.loadRawCSB('', (err) => {\n            if (err) {\n                return callback(err);\n            }\n            callback(undefined, rootCSB, csbIdentifier, backups);\n        });\n    });\n}\n\nfunction loadWithIdentifier(localFolder, csbIdentifier, callback) {\n    const masterDseed = csbIdentifier.getDseed();\n    const key = crypto.generateSafeUid(masterDseed, localFolder);\n    if (!instances[key]) {\n        instances[key] = new RootCSB(localFolder, null, csbIdentifier);\n    }\n\n    const rootCSB = instances[key];\n    rootCSB.loadRawCSB('', (err) => {\n        if (err) {\n            return callback(err);\n        }\n        callback(null, rootCSB);\n    });\n}\n\nfunction createNew(localFolder, csbIdentifier, rawCSB) {\n    if (!localFolder || !csbIdentifier) {\n        throw new Error(\"Missing required arguments\");\n    }\n\n    rawCSB = rawCSB || new RawCSB();\n    const masterDseed = csbIdentifier.getDseed();\n    const key = crypto.generateSafeUid(masterDseed, localFolder);\n    if (!instances[key]) {\n        instances[key] = new RootCSB(localFolder, rawCSB, csbIdentifier);\n    }\n\n    return instances[key];\n}\n\nfunction writeNewMasterCSB(localFolder, csbIdentifier, callback) {\n    if (!localFolder || !csbIdentifier) {\n        return callback(new Error('Missing required arguments'));\n    }\n\n    const masterDseed = csbIdentifier.getDseed();\n    const key = crypto.generateSafeUid(masterDseed, localFolder);\n    if (!instances[key]) {\n        instances[key] = new RootCSB(localFolder, null, csbIdentifier);\n    }\n\n    const rootCSB = instances[key];\n    rootCSB.saveRawCSB(new RawCSB(), '', callback);\n}\n\nmodule.exports = {\n    createNew,\n    createRootCSB,\n    loadWithIdentifier,\n    loadWithPin,\n    writeNewMasterCSB\n};","\nfunction EVFSResolver() {\n    let isAuthenticated = false;\n\n    this.auth = function (url, authObj, callback) {\n        isAuthenticated = true;\n        callback();\n    };\n\n    this.save = function (url, csbIdentifier, dataStream, callback) {\n        if (!isAuthenticated) {\n            return callback(new Error('Unauthenticated'));\n        }\n\n        $$.remote.doHttpPost(url + \"/CSB/\" + csbIdentifier.getUid(), dataStream, (err, res) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, res);\n        });\n    };\n\n    this.load = function (url, csbIdentifier, version, callback) {\n        if (!isAuthenticated) {\n            return callback(new Error('Unauthenticated'));\n        }\n\n        if (typeof version === \"function\") {\n            callback = version;\n            version = \"\";\n        }\n\n        $$.remote.doHttpGet(url + \"/CSB/\" + csbIdentifier.getUid() + \"/\" + version, (err, resource) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, resource);\n        });\n\n    };\n\n    this.getVersions = function (url, csbIdentifier, callback) {\n        if (!isAuthenticated) {\n            return callback(new Error('Unauthenticated'));\n        }\n\n        $$.remote.doHttpGet(url + \"/CSB/\" + csbIdentifier.getUid() + \"/versions\", (err, versions) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, JSON.parse(versions));\n        });\n    };\n\n    this.compareVersions = function (url, filesList, callback) {\n        if (!isAuthenticated) {\n            return callback(new Error('Unauthenticated'));\n        }\n\n        $$.remote.doHttpPost(url + \"/CSB/compareVersions\", JSON.stringify(filesList), (err, modifiedFiles) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, modifiedFiles);\n        });\n    };\n}\n\nmodule.exports = EVFSResolver;","const flowsUtils = require(\"../../utils/flowsUtils\");\nconst validator = require(\"../../utils/validator\");\nconst DseedCage = require(\"../../utils/DseedCage\");\nconst fs = require('fs');\nconst path = require('path');\n\n$$.swarm.describe(\"addBackup\", {\n    start: function (backupUrl, localFolder = process.cwd()) {\n        if(!backupUrl){\n            return this.swarm(\"interaction\", \"handleError\", new Error(\"No backup url provided\"));\n        }\n\n        this.localFolder = localFolder;\n        this.backupUrl = backupUrl;\n        fs.stat(path.join(this.localFolder, \".privateSky\", 'dseed'), (err, stats)=>{\n            if(err){\n                this.swarm(\"interaction\", \"createPin\", flowsUtils.defaultPin, flowsUtils.noTries);\n            }else{\n                this.swarm(\"interaction\", \"readPin\", flowsUtils.noTries);\n            }\n        });\n    },\n\n    validatePin: function (pin) {\n        validator.validatePin(this.localFolder, this, \"addBackup\", pin, flowsUtils.noTries);\n    },\n    \n    addBackup: function (pin = flowsUtils.defaultPin, backups) {\n        backups = backups || [];\n        backups.push(this.backupUrl);\n        const dseedCage = new DseedCage(this.localFolder);\n        dseedCage.saveDseedBackups(pin, this.csbIdentifier, backups, validator.reportOrContinue(this, 'finish', \"Failed to save backups\"));\n    },\n\n    finish: function () {\n        this.swarm(\"interaction\", 'printInfo', this.backupUrl + ' has been successfully added to backups list.');\n    }\n});","// var path = require(\"path\");\n\nconst utils = require(\"./../../utils/flowsUtils\");\n// const crypto = require(\"pskcrypto\");\n// var fs = require(\"fs\");\n\n$$.swarm.describe(\"addCsb\", {\n\tstart: function (aliasCsb, aliasDestCsb) {\n\t\tthis.aliasCsb = aliasCsb;\n\t\tthis.aliasDestCsb = aliasDestCsb;\n\t\tthis.swarm(\"interaction\", \"readPin\", 3);\n\t},\n\tvalidatePin: function (pin, noTries) {\n\t\tvar self = this;\n\t\tutils.checkPinIsValid(pin, function (err) {\n\t\t\tif(err){\n\t\t\t\tself.swarm(\"interaction\", \"readPin\", noTries-1);\n\t\t\t}else {\n\t\t\t\tself.addCsb(pin, self.aliasCsb);\n\t\t\t}\n\t\t});\n\t},\n\taddCsb: function (pin, aliasCSb, aliasDestCsb, callback) {\n\t\tvar self = this;\n\t\tutils.getCsb(pin, aliasCSb, function (err, parentCsb) {\n\t\t\tif(err){\n\t\t\t\tself.swarm(\"interaction\", \"handleError\", err, \"Failed to get csb\");\n\t\t\t}\n\t\t});\n\t}\n});","const flowsUtils = require(\"./../../utils/flowsUtils\");\nconst utils = require(\"./../../utils/utils\");\nconst crypto = require(\"pskcrypto\");\nconst fs = require(\"fs\");\nconst path = require('path');\nconst validator = require(\"../../utils/validator\");\nconst CSBIdentifier = require(\"../CSBIdentifier\");\nconst HashCage = require('../../utils/HashCage');\nconst RootCSB = require(\"../RootCSB\");\n\n$$.swarm.describe(\"attachFile\", { //url: CSB1/CSB2/aliasFile\n    start: function (url, filePath, localFolder = process.cwd()) { //csb1:assetType:alias\n        const {CSBPath, alias} = utils.processUrl(url, 'FileReference');\n        this.CSBPath = CSBPath;\n        this.alias = alias;\n        this.filePath = filePath;\n        this.localFolder = localFolder;\n        this.swarm(\"interaction\", \"readPin\", flowsUtils.noTries);\n    },\n\n    validatePin: function (pin, noTries) {\n        validator.validatePin(this.localFolder, this, 'loadFileReference', pin, noTries);\n    },\n\n    withCSBIdentifier: function (id, url, filePath, localFolder = process.cwd()) {\n        const {CSBPath, alias} = utils.processUrl(url, 'FileReference');\n        this.CSBPath = CSBPath;\n        this.alias = alias;\n        this.filePath = filePath;\n        this.localFolder = localFolder;\n        this.csbIdentifier = new CSBIdentifier(id);\n        RootCSB.loadWithIdentifier(this.localFolder, this.csbIdentifier, (err, rootCSB) => {\n            if (err) {\n                this.swarm(\"interaction\", \"handleError\", err, \"Failed to load rootCSB\");\n                return;\n            }\n\n            this.rootCSB = rootCSB;\n            this.loadFileReference();\n\n        });\n    },\n\n    loadFileReference: function () {\n        this.rootCSB.loadRawCSB('', validator.reportOrContinue(this, 'loadAsset', 'Failed to load masterCSB.'));\n    },\n\n    loadAsset: function () {\n        this.rootCSB.loadAssetFromPath(this.CSBPath, validator.reportOrContinue(this, 'saveFileToDisk', 'Failed to load asset'));\n    },\n\n    saveFileToDisk: function (fileReference) {\n        if (fileReference.isPersisted()) {\n            this.swarm(\"interaction\", \"handleError\", new Error(\"File is persisted\"), \"A file with the same alias already exists \");\n            return;\n        }\n\n        const csbIdentifier = new CSBIdentifier(undefined, this.csbIdentifier.getBackupUrls());\n        this.fileID = utils.generatePath(this.localFolder, csbIdentifier);\n        crypto.on('progress', (progress) => {\n            this.swarm('interaction', 'reportProgress', progress);\n        });\n        crypto.encryptStream(this.filePath, this.fileID, csbIdentifier.getDseed(), validator.reportOrContinue(this, 'saveFileReference', \"Failed at file encryption.\", fileReference, csbIdentifier));\n\n    },\n\n\n    saveFileReference: function (fileReference, csbIdentifier) {\n        crypto.removeAllListeners('progress');\n        fileReference.init(this.alias, csbIdentifier.getSeed(), csbIdentifier.getDseed());\n        this.rootCSB.saveAssetToPath(this.CSBPath, fileReference, validator.reportOrContinue(this, 'computeHash', \"Failed to save file\", this.fileID));\n    },\n\n\n    computeHash: function () {\n        const fileStream = fs.createReadStream(this.fileID);\n        crypto.pskHashStream(fileStream, validator.reportOrContinue(this, \"loadHashObj\", \"Failed to compute hash\"));\n    },\n\n    loadHashObj: function (digest) {\n        this.hashCage = new HashCage(this.localFolder);\n        this.hashCage.loadHash(validator.reportOrContinue(this, \"addToHashObj\", \"Failed to load hashObj\", digest));\n    },\n\n    addToHashObj: function (hashObj, digest) {\n        hashObj[path.basename(this.fileID)] = digest.toString(\"hex\");\n        this.hashCage.saveHash(hashObj, validator.reportOrContinue(this, \"printSuccess\", \"Failed to save hashObj\"));\n    },\n\n    printSuccess: function () {\n        this.swarm(\"interaction\", \"printInfo\", this.filePath + \" has been successfully added to \" + this.CSBPath);\n        this.swarm(\"interaction\", \"__return__\");\n    }\n});\n","const flowsUtils = require('../../utils/flowsUtils');\nconst RootCSB = require(\"../RootCSB\");\nconst RawCSB = require(\"../RawCSB\");\nconst validator = require(\"../../utils/validator\");\nconst DseedCage = require(\"../../utils/DseedCage\");\nconst CSBIdentifier = require(\"../CSBIdentifier\");\n\n$$.swarm.describe(\"createCsb\", {\n    start: function (CSBPath, localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        this.CSBPath = CSBPath || '';\n        validator.checkMasterCSBExists(localFolder, (err, status) => {\n            if (err) {\n                this.swarm(\"interaction\", \"createPin\", flowsUtils.defaultPin);\n            } else {\n                this.swarm(\"interaction\", \"readPin\", flowsUtils.noTries);\n            }\n        });\n    },\n\n    withoutPin: function (CSBPath, backups, localFolder = process.cwd(), seed, isMaster = false) {\n        this.localFolder = localFolder;\n        this.CSBPath = CSBPath;\n        this.isMaster = isMaster;\n        if (typeof backups === 'undefined' || backups.length === 0) {\n            backups = [ flowsUtils.defaultBackup ];\n        }\n\n        validator.checkMasterCSBExists(localFolder, (err, status) => {\n            if (err) {\n                this.createMasterCSB(backups);\n            } else {\n                const csbIdentifier = new CSBIdentifier(seed);\n                this.withCSBIdentifier(CSBPath, csbIdentifier);\n            }\n        });\n\n    },\n\n    withCSBIdentifier: function (CSBPath, csbIdentifier) {\n        this.CSBPath = CSBPath;\n        RootCSB.loadWithIdentifier(this.localFolder, csbIdentifier, validator.reportOrContinue(this, 'createCSB', 'Failed to load master with provided dseed'));\n    },\n\n    validatePin: function (pin, noTries) {\n        validator.validatePin(this.localFolder, this, \"createCSB\", pin, noTries);\n    },\n\n    loadBackups: function (pin) {\n        this.pin = pin;\n        this.dseedCage = new DseedCage(this.localFolder);\n        this.dseedCage.loadDseedBackups(this.pin, (err, csbIdentifier, backups) => {\n            if (err) {\n                this.createMasterCSB();\n            } else {\n                this.createMasterCSB(backups);\n            }\n        });\n    },\n\n    createMasterCSB: function (backups) {\n        this.csbIdentifier = new CSBIdentifier(undefined, backups || flowsUtils.defaultBackup);\n\n        this.swarm(\"interaction\", \"printSensitiveInfo\", this.csbIdentifier.getSeed(), flowsUtils.defaultPin);\n\n        const rawCSB = new RawCSB();\n        const meta = rawCSB.getAsset('global.CSBMeta', 'meta');\n        meta.init();\n        meta.setIsMaster(true);\n        if (typeof this.isMaster !== 'undefined') {\n            meta.setIsMaster(this.isMaster);\n        }\n        rawCSB.saveAsset(meta);\n        this.rootCSB = RootCSB.createNew(this.localFolder, this.csbIdentifier, rawCSB);\n        const nextPhase = (this.CSBPath === '' || typeof this.CSBPath === 'undefined') ? 'saveRawCSB' : 'createCSB';\n        if (this.pin) {\n            this.dseedCage.saveDseedBackups(this.pin, this.csbIdentifier, backups, validator.reportOrContinue(this, nextPhase, \"Failed to save dseed \"));\n        } else {\n            this[nextPhase]();\n        }\n    },\n\n    createCSB: function (rootCSB) {\n        this.rootCSB = this.rootCSB || rootCSB;\n        const rawCSB = new RawCSB();\n        const meta = rawCSB.getAsset(\"global.CSBMeta\", \"meta\");\n        meta.init();\n        meta.setIsMaster(false);\n        rawCSB.saveAsset(meta);\n        this.saveRawCSB(rawCSB);\n    },\n\n    saveRawCSB: function (rawCSB) {\n        this.rootCSB.saveRawCSB(rawCSB, this.CSBPath, validator.reportOrContinue(this, \"printSuccess\", \"Failed to save raw CSB\"));\n\n    },\n\n\n    printSuccess: function () {\n        let message = \"Successfully saved CSB at path \" + this.CSBPath;\n        if (!this.CSBPath || this.CSBPath === '') {\n            message = 'Successfully saved CSB root';\n        }\n        this.swarm(\"interaction\", \"printInfo\", message);\n        this.swarm('interaction', '__return__');\n    }\n});\n","const flowsUtils = require(\"./../../utils/flowsUtils\");\nconst utils = require(\"./../../utils/utils\");\nconst crypto = require(\"pskcrypto\");\nconst validator = require(\"../../utils/validator\");\nconst CSBIdentifier = require(\"../CSBIdentifier\");\n\n$$.swarm.describe(\"extractFile\", {\n\tstart: function (url, localFolder = process.cwd()) {\n\t\tthis.localFolder = localFolder;\n\t\tconst {CSBPath, alias} = utils.processUrl(url, 'global.FileReference');\n\t\tthis.CSBPath = CSBPath;\n\t\tthis.alias = alias;\n\t\tthis.swarm(\"interaction\", \"readPin\", flowsUtils.noTries);\n\t},\n\n\tvalidatePin: function (pin, noTries) {\n\t\tvalidator.validatePin(this.localFolder, this, \"loadFileAsset\", pin, noTries);\n\t},\n\n\tloadFileAsset: function () {\n\t\tthis.rootCSB.loadAssetFromPath(this.CSBPath, validator.reportOrContinue(this, \"decryptFile\", \"Failed to load file asset \" + this.alias));\n\t},\n\t\n\tdecryptFile: function (fileReference) {\n\t\tconst csbIdentifier = new CSBIdentifier(fileReference.dseed);\n\t\tconst filePath = utils.generatePath(this.localFolder, csbIdentifier);\n\n\t\tcrypto.on('progress', (progress) => {\n            this.swarm('interaction', 'reportProgress', progress);\n        });\n\n\t\tcrypto.decryptStream(filePath, this.localFolder, csbIdentifier.getDseed(), (err, fileNames) => {\n\t\t\tif(err){\n\t\t\t\treturn this.swarm(\"interaction\", \"handleError\", err, \"Failed to decrypt file\" + filePath);\n\t\t\t}\n\n\t\t\tthis.swarm(\"interaction\", \"printInfo\", this.alias + \" was successfully extracted. \");\n\t\t\tthis.swarm(\"interaction\", \"__return__\", fileNames);\n\t\t});\n\t}\n});","require(\"callflow\");\n\nmodule.exports = $$.library(function () {\n    require('./addCsb');\n    require('./addBackup');\n    require('./attachFile');\n    require('./createCsb');\n    require('./extractFile');\n    require('./listCSBs');\n    require('./resetPin');\n    require('./restore');\n    require('./receive');\n\trequire('./saveBackup');\n    require('./setPin');\n});\n\n\n","const flowsUtils = require(\"./../../utils/flowsUtils\");\nconst validator = require(\"../../utils/validator\");\n// const fs = require(\"fs\");\nconst RootCSB = require(\"../RootCSB\");\nconst CSBIdentifier = require(\"../CSBIdentifier\");\n\n$$.swarm.describe(\"listCSBs\", {\n    start: function (CSBPath, localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        this.CSBPath = CSBPath || '';\n        validator.checkMasterCSBExists(localFolder, (err, status) => {\n            if (err) {\n                this.swarm(\"interaction\", \"noMasterCSBExists\");\n            } else {\n                this.swarm(\"interaction\", \"readPin\", flowsUtils.noTries);\n            }\n        });\n    },\n\n    withCSBIdentifier: function (id, CSBPath = '', localFolder = process.cwd()) {\n        this.csbIdentifier = new CSBIdentifier(id);\n        this.CSBPath = CSBPath;\n        this.localFolder = localFolder;\n        this.loadMasterRawCSB();\n    },\n\n    loadMasterRawCSB: function () {\n        RootCSB.loadWithIdentifier(this.localFolder, this.csbIdentifier, validator.reportOrContinue(this, \"loadRawCSB\", \"Failed to create RootCSB.\"));\n    },\n\n    validatePin: function (pin, noTries) {\n        validator.validatePin(this.localFolder, this, 'loadRawCSB', pin, noTries);\n    },\n\n    loadRawCSB: function (rootCSB) {\n        if(typeof this.rootCSB === \"undefined\" && rootCSB){\n            this.rootCSB = rootCSB;\n        }\n        this.rootCSB.loadRawCSB(this.CSBPath, validator.reportOrContinue(this, 'getCSBs', 'Failed to load rawCSB'));\n    },\n\n    getCSBs: function (rawCSB) {\n        const csbReferences = rawCSB.getAllAssets('global.CSBReference');\n        const csbsAliases = csbReferences.map((ref) => ref.alias);\n\n        const fileReferences = rawCSB.getAllAssets('global.FileReference');\n        const filesAliases = fileReferences.map((ref) => ref.alias);\n\n        this.swarm(\"interaction\", \"__return__\", {\n            csbs: csbsAliases,\n            files: filesAliases\n        });\n    }\n\n});\n","\n$$.swarm.describe(\"receive\", {\n    start: function (endpoint, channel) {\n\n        const alias = 'remote';\n        $$.remote.createRequestManager(1000);\n        $$.remote.newEndPoint(alias, endpoint, channel);\n        $$.remote[alias].on('*', '*', (err, swarm) => {\n            if (err) {\n                return this.swarm('interaction', 'handleError', err, 'Failed to get data from channel' + channel);\n            }\n            const seed = swarm.meta.args[0];\n            this.swarm(\"interaction\", \"printSensitiveInfo\", seed);\n\n            $$.remote[alias].off(\"*\", \"*\");\n        });\n\n    }\n});","const utils = require(\"./../../utils/flowsUtils\");\nconst RootCSB = require(\"../RootCSB\");\nconst DseedCage = require(\"../../utils/DseedCage\");\nconst CSBIdentifier = require(\"../CSBIdentifier\");\n\n$$.swarm.describe(\"resetPin\", {\n    start: function (localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        this.swarm(\"interaction\", \"readSeed\", utils.noTries);\n    },\n\n    validateSeed: function (seed, noTries) {\n        try{\n            this.csbIdentifier = new CSBIdentifier(seed);\n            RootCSB.loadWithIdentifier(this.localFolder, this.csbIdentifier, (err, rootCSB) => {\n                if (err) {\n                    this.swarm(\"interaction\", \"readSeed\", noTries - 1);\n                }else{\n                    this.swarm(\"interaction\", \"insertPin\", utils.noTries);\n                }\n            });\n        } catch (e) {\n            return this.swarm('interaction', 'handleError', new Error('Invalid seed'));\n        }\n    },\n\n    actualizePin: function (pin) {\n        const dseedCage = new DseedCage(this.localFolder);\n        dseedCage.saveDseedBackups(pin, this.csbIdentifier, undefined, (err)=>{\n            if(err){\n                return this.swarm(\"interaction\", \"handleError\", \"Failed to save dseed.\");\n            }\n\n            this.swarm(\"interaction\", \"printInfo\", \"The pin has been changed successfully.\");\n        });\n    }\n});\n","const path = require(\"path\");\nconst flowsUtils = require(\"./../../utils/flowsUtils\");\nconst utils = require(\"./../../utils/utils\");\nconst crypto = require(\"pskcrypto\");\nconst fs = require(\"fs\");\nconst validator = require(\"../../utils/validator\");\nconst DseedCage = require(\"../../utils/DseedCage\");\nconst RootCSB = require('../RootCSB');\nconst CSBIdentifier = require('../CSBIdentifier');\nconst BackupEngine = require('../BackupEngine');\nconst HashCage = require('../../utils/HashCage');\nconst AsyncDispatcher = require('../../utils/AsyncDispatcher');\n\n\n$$.swarm.describe(\"restore\", {\n    start: function (url, localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        if (url) {\n            const {CSBPath, alias} = utils.processUrl(url, 'global.CSBReference');\n            this.CSBPath = CSBPath;\n            this.CSBAlias = alias;\n        }\n\n        this.swarm(\"interaction\", \"readSeed\");\n    },\n\n    withSeed: function (url, localFolder = process.cwd(), seedRestore, localSeed) {\n        this.localFolder = localFolder;\n        if (url) {\n            const {CSBPath, alias} = utils.processUrl(url, 'global.CSBReference');\n            this.CSBPath = CSBPath;\n            this.CSBAlias = alias;\n        }\n\n        if (localSeed) {\n            this.localCSBIdentifier = new CSBIdentifier(localSeed);\n        }\n\n        this.restoreCSB(seedRestore);\n    },\n\n    restoreCSB: function (restoreSeed) {\n        this.hashCage = new HashCage(this.localFolder);\n        this.hashObj = {};\n        this.csbRestoreIdentifier = new CSBIdentifier(restoreSeed);\n        let backupUrls;\n        try {\n            backupUrls = this.csbRestoreIdentifier.getBackupUrls();\n        } catch (e) {\n            return this.swarm('interaction', 'handleError', new Error('Invalid seed'));\n        }\n\n        this.backupUrls = backupUrls;\n        this.restoreDseedCage = new DseedCage(this.localFolder);\n        const backupEngine = new BackupEngine.getBackupEngine(this.backupUrls);\n\n        backupEngine.load(this.csbRestoreIdentifier, (err, encryptedCSB) => {\n            if (err) {\n                return this.swarm(\"interaction\", \"handleError\", err, \"Failed to restore CSB\");\n            }\n\n            this.__addCSBHash(this.csbRestoreIdentifier, encryptedCSB);\n            this.encryptedCSB = encryptedCSB;\n\n            validator.checkMasterCSBExists(this.localFolder, (err, status) => {\n                if (err) {\n                    console.log(err);\n                }\n                if (status === false) {\n                    this.createAuxFolder();\n                } else if (this.localCSBIdentifier) {\n                    if (!this.CSBAlias) {\n                        utils.deleteRecursively(this.localFolder, true, (err) => {\n                            if (err) {\n                                console.log(err);\n                            }\n                            return this.swarm(\"interaction\", \"handleError\", new Error(\"No CSB alias was specified\"));\n                        });\n                    } else {\n                        this.writeCSB();\n                    }\n                } else {\n                    if (!this.CSBAlias) {\n                        return this.swarm(\"interaction\", \"handleError\", new Error(\"No CSB alias was specified\"));\n                    } else {\n                        this.swarm(\"interaction\", \"readPin\", flowsUtils.noTries);\n                    }\n                }\n            });\n        });\n    },\n\n    validatePin: function (pin, noTries) {\n        validator.validatePin(this.localFolder, this, \"writeCSB\", pin, noTries);\n    },\n\n    createAuxFolder: function () {\n        fs.mkdir(path.join(this.localFolder, \".privateSky\"), {recursive: true}, validator.reportOrContinue(this, \"writeCSB\", \"Failed to create folder .privateSky\"));\n    },\n\n\n    writeCSB: function () {\n        fs.writeFile(utils.generatePath(this.localFolder, this.csbRestoreIdentifier), this.encryptedCSB, validator.reportOrContinue(this, \"createRootCSB\", \"Failed to write masterCSB to disk\"));\n    },\n\n    createRootCSB: function () {\n        RootCSB.loadWithIdentifier(this.localFolder, this.csbRestoreIdentifier, validator.reportOrContinue(this, \"loadRawCSB\", \"Failed to create rootCSB with dseed\"));\n    },\n\n    loadRawCSB: function (rootCSB) {\n\n        this.asyncDispatcher = new AsyncDispatcher(( errs, succs) => {\n            this.hashCage.saveHash(this.hashObj, (err) => {\n                if (err) {\n                    return this.swarm('interaction', 'handleError', err, 'Failed to save hashObj');\n                }\n                this.swarm('interaction', 'printInfo', 'All CSBs have been restored.');\n                this.swarm('interaction', '__return__');\n\n            });\n        });\n        rootCSB.loadRawCSB('', validator.reportOrContinue(this, \"checkCSBStatus\", \"Failed to load RawCSB\", rootCSB));\n    },\n\n    checkCSBStatus: function (rawCSB, rootCSB) {\n        this.rawCSB = rawCSB;\n        const meta = this.rawCSB.getAsset('global.CSBMeta', 'meta');\n        if (this.rootCSB) {\n            this.attachCSB(this.rootCSB, this.CSBPath, this.CSBAlias, this.csbRestoreIdentifier);\n        } else {\n            if (meta.isMaster) {\n                this.rootCSB = rootCSB;\n                this.saveDseed();\n            } else {\n                this.createMasterCSB();\n            }\n        }\n    },\n\n    saveDseed: function () {\n        this.restoreDseedCage.saveDseedBackups(flowsUtils.defaultPin, this.csbRestoreIdentifier, undefined, validator.reportOrContinue(this, \"collectFiles\", \"Failed to save dseed\", this.rawCSB, this.csbRestoreIdentifier, '', 'master'));\n    },\n\n\n    createMasterCSB: function () {\n        const csbIdentifier = new CSBIdentifier(undefined, this.backupUrls);\n        this.swarm(\"interaction\", \"printSensitiveInfo\", csbIdentifier.getSeed(), flowsUtils.defaultPin);\n        this.rootCSB = RootCSB.createNew(this.localFolder, csbIdentifier);\n        this.restoreDseedCage.saveDseedBackups(flowsUtils.defaultPin, csbIdentifier, undefined, validator.reportOrContinue(this, \"attachCSB\", \"Failed to save master dseed \", this.rootCSB, this.CSBPath, this.CSBAlias, this.csbRestoreIdentifier));\n    },\n\n\n    attachCSB: function (rootCSB, CSBPath, CSBAlias, csbIdentifier) {\n        this.__attachCSB(rootCSB, CSBPath, CSBAlias, csbIdentifier, validator.reportOrContinue(this, 'loadRestoredRawCSB', 'Failed to attach rawCSB'));\n\n    },\n\n    loadRestoredRawCSB: function () {\n        this.CSBPath = this.CSBPath.split(':')[0] + '/' + this.CSBAlias;\n        this.rootCSB.loadRawCSB(this.CSBPath, validator.reportOrContinue(this, \"collectFiles\", \"Failed to load restored RawCSB\", this.csbRestoreIdentifier, this.CSBPath, this.CSBAlias));\n    },\n\n    collectFiles: function (rawCSB, csbIdentifier, currentPath, alias, callback) {\n\n        const listFiles = rawCSB.getAllAssets('global.FileReference');\n        const asyncDispatcher = new AsyncDispatcher((errs, succs) => {\n            this.collectCSBs(rawCSB, csbIdentifier, currentPath, alias);\n            if (callback) {\n                return callback(errs, succs);\n            }\n        });\n\n        if (listFiles.length === 0) {\n            asyncDispatcher.markOneAsFinished();\n        }\n\n        listFiles.forEach((fileReference) => {\n            const csbIdentifier = new CSBIdentifier(fileReference.dseed);\n            const fileAlias = fileReference.alias;\n            const urls = csbIdentifier.getBackupUrls();\n            const backupEngine = BackupEngine.getBackupEngine(urls);\n            asyncDispatcher.dispatchEmpty();\n            backupEngine.load(csbIdentifier, (err, encryptedFile) => {\n                if (err) {\n                    return this.swarm('interaction', 'handleError', err, 'Could not download file ' + fileAlias);\n                }\n\n                this.__addCSBHash(csbIdentifier, encryptedFile);\n\n                fs.writeFile(utils.generatePath(this.localFolder, csbIdentifier), encryptedFile, (err) => {\n                    if (err) {\n                        return this.swarm('interaction', 'handleError', err, 'Could not save file ' + fileAlias);\n                    }\n\n                    asyncDispatcher.markOneAsFinished(undefined, fileAlias);\n                });\n            });\n        });\n    },\n\n    collectCSBs: function (rawCSB, csbIdentifier, currentPath, alias) {\n\n        const listCSBs = rawCSB.getAllAssets('global.CSBReference');\n        const nextArguments = [];\n        let counter = 0;\n\n        if (listCSBs.length === 0) {\n            this.asyncDispatcher.dispatchEmpty();\n            this.asyncDispatcher.markOneAsFinished();\n        }\n\n        if (listCSBs && listCSBs.length > 0) {\n            listCSBs.forEach((CSBReference) => {\n                const nextPath = currentPath + '/' + CSBReference.alias;\n                const nextCSBIdentifier = new CSBIdentifier(CSBReference.dseed);\n                const nextAlias = CSBReference.alias;\n                const nextURLs = csbIdentifier.getBackupUrls();\n                const backupEngine = BackupEngine.getBackupEngine(nextURLs);\n                this.asyncDispatcher.dispatchEmpty();\n                backupEngine.load(nextCSBIdentifier, (err, encryptedCSB) => {\n                    if (err) {\n                        return this.swarm('interaction', 'handleError', err, 'Could not download CSB ' + nextAlias);\n                    }\n\n                    this.__addCSBHash(nextCSBIdentifier, encryptedCSB);\n\n                    fs.writeFile(utils.generatePath(this.localFolder, nextCSBIdentifier), encryptedCSB, (err) => {\n                        if (err) {\n                            return this.swarm('interaction', 'handleError', err, 'Could not save CSB ' + nextAlias);\n                        }\n\n                        this.rootCSB.loadRawCSB(nextPath, (err, nextRawCSB) => {\n\n                            if (err) {\n                                return this.swarm('interaction', 'handleError', err, 'Failed to load CSB ' + nextAlias);\n                            }\n                            nextArguments.push([ nextRawCSB, nextCSBIdentifier, nextPath, nextAlias ]);\n\n                            if (++counter === listCSBs.length) {\n                                nextArguments.forEach((args) => {\n                                    this.collectFiles(...args, () => {\n                                        this.asyncDispatcher.markOneAsFinished(undefined, alias);\n                                    });\n                                });\n                            }\n                        });\n                    });\n                });\n            });\n        }\n    },\n\n    __tryDownload(urls, csbIdentifier, index, callback) {\n        if (index === urls.length) {\n            return callback(new Error('Could not download resource'));\n        }\n\n        const url = urls[index];\n        this.backupEngine.load(url, csbIdentifier, (err, resource) => {\n            if (err) {\n                return this.__tryDownload(urls, csbIdentifier, ++index, callback);\n            }\n\n            callback(undefined, resource);\n        });\n\n    },\n\n    __addCSBHash: function (csbIdentifier, encryptedCSB) {\n        const pskHash = new crypto.PskHash();\n        pskHash.update(encryptedCSB);\n        this.hashObj[csbIdentifier.getUid()] = pskHash.digest().toString('hex');\n\n    },\n\n    __attachCSB: function (rootCSB, CSBPath, CSBAlias, csbIdentifier, callback) {\n        if (!CSBAlias) {\n            return callback(new Error(\"No CSB alias was specified\"));\n        }\n\n        rootCSB.loadRawCSB(CSBPath, (err, rawCSB) => {\n            if (err) {\n                rootCSB.loadAssetFromPath(CSBPath, (err, csbRef) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    csbRef.init(CSBAlias, csbIdentifier.getSeed(), csbIdentifier.getDseed());\n                    rootCSB.saveAssetToPath(CSBPath, csbRef, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        callback();\n                    });\n\n                });\n            } else {\n                return callback(new Error(`A CSB having the alias ${CSBAlias} already exists.`));\n            }\n        });\n    }\n});\n\n","const utils = require(\"./../../utils/utils\");\nconst fs = require(\"fs\");\nconst validator = require(\"../../utils/validator\");\nconst HashCage = require('../../utils/HashCage');\nconst AsyncDispatcher = require(\"../../utils/AsyncDispatcher\");\nconst RootCSB = require('../RootCSB');\nconst CSBIdentifier = require('../CSBIdentifier');\nconst BackupEngine = require('../BackupEngine');\nconst path = require('path');\n\n\n$$.swarm.describe(\"saveBackup\", {\n    start: function (localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        this.swarm(\"interaction\", \"readPin\", 3);\n    },\n\n    validatePin: function (pin, noTries) {\n        validator.validatePin(this.localFolder, this, \"loadHashFile\", pin, noTries);\n    },\n\n    withCSBIdentifier: function (id, localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        this.csbIdentifier = new CSBIdentifier(id);\n        RootCSB.loadWithIdentifier(localFolder, this.csbIdentifier, (err, rootCSB) => {\n            if (err) {\n                this.swarm('interaction', 'handleError', err, 'Failed to load root CSB');\n                return;\n            }\n\n            this.rootCSB = rootCSB;\n            this.loadHashFile();\n        });\n    },\n\n    loadHashFile: function (pin, backups) {\n        this.backups = backups;\n        this.hashCage = new HashCage(this.localFolder);\n        this.hashCage.loadHash(validator.reportOrContinue(this, 'readEncryptedMaster', 'Failed to load hash file'));\n    },\n\n    readEncryptedMaster: function (hashFile) {\n        this.hashFile = hashFile;\n        this.masterID = utils.generatePath(this.localFolder, this.csbIdentifier);\n        fs.readFile(this.masterID, validator.reportOrContinue(this, 'loadMasterRawCSB', 'Failed to read masterCSB.'));\n    },\n\n\n    loadMasterRawCSB: function () {\n        this.rootCSB.loadRawCSB('', validator.reportOrContinue(this, \"dispatcher\", \"Failed to load masterCSB\"));\n    },\n\n    dispatcher: function (rawCSB) {\n        this.asyncDispatcher = new AsyncDispatcher((errors, results) => {\n            if (errors) {\n                this.swarm('interaction', 'handleError', JSON.stringify(errors, null, '\\t'), 'Failed to collect all CSBs');\n                return;\n            }\n            this.collectFiles(results);\n        });\n\n        this.asyncDispatcher.dispatchEmpty();\n        this.collectCSBs(rawCSB, this.csbIdentifier, '', 'master');\n    },\n\n    collectCSBs: function (rawCSB, csbIdentifier, currentPath, alias) {\n        const listCSBs = rawCSB.getAllAssets('global.CSBReference');\n\n        const nextArguments = [];\n        let counter = 0;\n\n        listCSBs.forEach((CSBReference) => {\n            const nextPath = currentPath + '/' + CSBReference.alias;\n            const nextCSBIdentifier = new CSBIdentifier(CSBReference.dseed);\n            const nextAlias = CSBReference.alias;\n            this.rootCSB.loadRawCSB(nextPath, (err, nextRawCSB) => {\n                if (err) {\n                    console.log(err);\n                }\n                nextArguments.push([ nextRawCSB, nextCSBIdentifier, nextPath, nextAlias ]);\n                if (++counter === listCSBs.length) {\n                    nextArguments.forEach((args) => {\n                        this.asyncDispatcher.dispatchEmpty();\n                        this.collectCSBs(...args);\n                    });\n                    this.asyncDispatcher.markOneAsFinished(undefined, {rawCSB, csbIdentifier, alias});\n                }\n            });\n        });\n\n        if (listCSBs.length === 0) {\n            this.asyncDispatcher.markOneAsFinished(undefined, {rawCSB, csbIdentifier, alias});\n        }\n    },\n\n    collectFiles: function (collectedCSBs) {\n        this.asyncDispatcher = new AsyncDispatcher((errors, newResults) => {\n            if (errors) {\n                this.swarm('interaction', 'handleError', JSON.stringify(errors, null, '\\t'), 'Failed to collect files attached to CSBs');\n            }\n\n            if (!newResults) {\n                newResults = [];\n            }\n            this.__categorize(collectedCSBs.concat(newResults));\n        });\n\n        this.asyncDispatcher.dispatchEmpty(collectedCSBs.length);\n        collectedCSBs.forEach(({rawCSB, csbIdentifier, alias}) => {\n            this.__collectFiles(rawCSB, alias);\n        });\n\n    },\n\n    __categorize: function (files) {\n        const categories = {};\n        let backups;\n        files.forEach(({csbIdentifier, alias}) => {\n            if (!this.backups || this.backups.length === 0) {\n                backups = csbIdentifier.getBackupUrls();\n            } else {\n                backups = this.backups;\n            }\n            const uid = csbIdentifier.getUid();\n            categories[uid] = {backups, alias};\n        });\n\n        this.asyncDispatcher = new AsyncDispatcher((errors, successes) => {\n            this.swarm('interaction', 'csbBackupReport', {errors, successes});\n        });\n\n        this.backupEngine = BackupEngine.getBackupEngine(backups);\n        this.filterFiles(categories);\n        // Object.entries(categories).forEach(([uid, {alias, backups}]) => {\n        //     this.filterFiles(uid, alias, backups);\n        // });\n    },\n\n    filterFiles: function (filesBackups) {\n        const filesToUpdate = {};\n        Object.keys(this.hashFile).forEach((uid) => {\n            if (filesBackups[uid]) {\n                filesToUpdate[uid] = this.hashFile[uid];\n            }\n        });\n\n        this.asyncDispatcher.dispatchEmpty();\n        this.backupEngine.compareVersions(filesToUpdate, (err, modifiedFiles) => {\n            if (err) {\n                return this.swarm(\"interaction\", \"handleError\", err, \"Failed to retrieve list of modified files\");\n            }\n\n            this.__backupFiles(JSON.parse(modifiedFiles), filesBackups);\n        });\n    },\n\n    __backupFiles: function (files, filesBackups) {\n        this.asyncDispatcher.dispatchEmpty(files.length);\n        files.forEach((file) => {\n            const fileStream = fs.createReadStream(path.join(this.localFolder, file));\n            const backupUrls = filesBackups[file].backups;\n            const backupEngine = BackupEngine.getBackupEngine(backupUrls);\n            backupEngine.save(new CSBIdentifier(file), fileStream, (err, url) => {\n                if (err) {\n                    return  this.asyncDispatcher.markOneAsFinished({alias: filesBackups[file].alias, backupURL: url});\n                }\n\n                this.asyncDispatcher.markOneAsFinished(undefined, {alias: filesBackups[file].alias, backupURL: url});\n            });\n        });\n\n        this.asyncDispatcher.markOneAsFinished(); // for http request to compareVersions\n    },\n\n    __collectFiles: function (rawCSB, csbAlias) {\n        const files = rawCSB.getAllAssets('global.FileReference');\n        this.asyncDispatcher.dispatchEmpty(files.length);\n        files.forEach((FileReference) => {\n            const alias = FileReference.alias;\n            const csbIdentifier = new CSBIdentifier(FileReference.dseed);\n            this.asyncDispatcher.markOneAsFinished(undefined, {csbIdentifier, alias});\n        });\n        this.asyncDispatcher.markOneAsFinished();\n    }\n});\n\n","const validator = require(\"../../utils/validator\");\nconst DseedCage = require('../../utils/DseedCage');\n\n$$.swarm.describe(\"setPin\", {\n    start: function (localFolder = process.cwd()) {\n        this.localFolder = localFolder;\n        this.swarm(\"interaction\", \"readPin\", 3);\n    },\n\n    validatePin: function (oldPin, noTries) {\n        this.oldPin = oldPin;\n        validator.validatePin(this.localFolder, this, \"interactionJumper\", oldPin, noTries);\n    },\n\n    interactionJumper: function () {\n        this.swarm(\"interaction\", \"enterNewPin\");\n    },\n\n    actualizePin: function (newPin) {\n        this.dseedCage = new DseedCage(this.localFolder);\n        this.dseedCage.loadDseedBackups(this.oldPin, validator.reportOrContinue(this, \"saveDseed\", \"Failed to load dseed.\", newPin));\n    },\n\n    saveDseed: function (csbIdentifier, backups, pin) {\n        this.dseedCage.saveDseedBackups(pin, csbIdentifier, backups, validator.reportOrContinue(this, \"successState\", \"Failed to save dseed\"));\n    },\n\n    successState: function () {\n        this.swarm(\"interaction\", \"printInfo\", \"The pin has been successfully changed.\");\n    }\n});","\nfunction AsyncDispatcher(finalCallback) {\n\tlet results = [];\n\tlet errors = [];\n\n\tlet started = 0;\n\n\tfunction markOneAsFinished(err, res) {\n\t\tif(err) {\n\t\t\terrors.push(err);\n\t\t}\n\n\t\tif(arguments.length > 2) {\n\t\t\targuments[0] = undefined;\n\t\t\tres = arguments;\n\t\t}\n\n\t\tif(typeof res !== \"undefined\") {\n\t\t\tresults.push(res);\n\t\t}\n\n\t\tif(--started <= 0) {\n            callCallback();\n\t\t}\n\t}\n\n\tfunction dispatchEmpty(amount = 1) {\n\t\tstarted += amount;\n\t}\n\n\tfunction callCallback() {\n\t    if(errors.length === 0) {\n\t        errors = undefined;\n        }\n\n\t    if(results.length === 0) {\n\t        results = undefined;\n        }\n\n        finalCallback(errors, results);\n    }\n\n\treturn {\n\t\tdispatchEmpty,\n\t\tmarkOneAsFinished\n\t};\n}\n\nmodule.exports = AsyncDispatcher;","const crypto = require('pskcrypto');\nconst path = require('path');\nconst fs = require(\"fs\");\nconst CSBIdentifier = require(\"../libraries/CSBIdentifier\");\n\nfunction DseedCage(localFolder) {\n\tconst dseedFolder = path.join(localFolder, '.privateSky');\n\tconst dseedPath = path.join(dseedFolder, 'dseed');\n\n\tfunction loadDseedBackups(pin, callback) {\n\t\tfs.mkdir(dseedFolder, {recursive: true}, (err) => {\n\t\t\tif (err) {\n\t\t\t\treturn callback(err);\n\t\t\t}\n\n\t\t\tcrypto.loadData(pin, dseedPath, (err, dseedBackups) => {\n\t\t\t\tif (err) {\n\t\t\t\t\treturn callback(err);\n\t\t\t\t}\n\t\t\t\ttry{\n\t\t\t\t\tdseedBackups = JSON.parse(dseedBackups.toString());\n\t\t\t\t}catch (e) {\n\t\t\t\t\treturn callback(e);\n\t\t\t\t}\n\n\t\t\t\tlet csbIdentifier;\n\t\t\t\tif (dseedBackups.dseed && !Buffer.isBuffer(dseedBackups.dseed)) {\n\t\t\t\t\tdseedBackups.dseed = Buffer.from(dseedBackups.dseed);\n\t\t\t\t\tcsbIdentifier = new CSBIdentifier(dseedBackups.dseed);\n\t\t\t\t}\n\n\t\t\t\tcallback(undefined, csbIdentifier, dseedBackups.backups);\n\t\t\t});\n\t\t});\n\t}\n\n\tfunction saveDseedBackups(pin, csbIdentifier, backups, callback) {\n\t\tfs.mkdir(dseedFolder, {recursive: true}, (err) => {\n\t\t\tif (err) {\n\t\t\t\treturn callback(err);\n\t\t\t}\n\n\t\t\tlet dseed;\n\t\t\tif(csbIdentifier){\n\t\t\t\tdseed = csbIdentifier.getDseed();\n\t\t\t}\n\t\t\tconst dseedBackups = JSON.stringify({\n\t\t\t\tdseed,\n\t\t\t\tbackups\n\t\t\t});\n\n\t\t\tcrypto.saveData(Buffer.from(dseedBackups), pin, dseedPath, callback);\n\t\t});\n\t}\n\n\n\treturn {\n\t\tloadDseedBackups,\n\t\tsaveDseedBackups,\n\t};\n}\n\n\nmodule.exports = DseedCage;","const path = require('path');\nconst fs = require('fs');\n\nfunction HashCage(localFolder) {\n\tconst hashFolder = path.join(localFolder, '.privateSky');\n\tconst hashPath = path.join(hashFolder, 'hash');\n\n\tfunction loadHash(callback) {\n\t\tfs.mkdir(hashFolder, {recursive: true}, (err) => {\n\t\t\tif (err) {\n\t\t\t\treturn callback(err);\n\t\t\t}\n\n\t\t\tfs.readFile(hashPath, (err, data) => {\n\t\t\t\tif(err){\n\t\t\t\t\treturn callback(null, {});\n\t\t\t\t}\n\n\t\t\t\tcallback(null, JSON.parse(data));\n\t\t\t});\n\n\t\t});\n\t}\n\n\tfunction saveHash(hashObj, callback) {\n\t\tfs.mkdir(hashFolder, {recursive: true}, (err) => {\n\t\t\tif (err) {\n\t\t\t\treturn callback(err);\n\t\t\t}\n\n\t\t\tfs.writeFile(hashPath, JSON.stringify(hashObj, null, '\\t'), (err) => {\n\t\t\t\tif (err) {\n\t\t\t\t\treturn callback(err);\n\t\t\t\t}\n\t\t\t\tcallback();\n\t\t\t});\n\t\t});\n\t}\n\n\treturn {\n\t\tloadHash,\n\t\tsaveHash\n\t};\n}\n\nmodule.exports = HashCage;\n","// const path = require(\"path\");\n\n\nexports.defaultBackup = \"http://localhost:8080\";\nexports.defaultPin = \"12345678\";\nexports.noTries = 3;\n\n","const fs = require(\"fs\");\nconst path = require('path');\n// const crypto = require(\"pskcrypto\");\n\nfunction generatePath(localFolder, csbIdentifier) {\n    return path.join(localFolder, csbIdentifier.getUid());\n}\n\nfunction processUrl(url, assetType) {\n    const splitUrl = url.split('/');\n    const aliasAsset = splitUrl.pop();\n    const CSBPath = splitUrl.join('/');\n    return {\n        CSBPath: CSBPath + ':' + assetType + ':' + aliasAsset,\n        alias: aliasAsset\n    };\n}\n\nfunction deleteRecursively(inputPath, isRoot = true, callback) {\n\n    fs.stat(inputPath, function (err, stats) {\n        if (err) {\n            callback(err, stats);\n            return;\n        }\n        if (stats.isFile()) {\n            fs.unlink(inputPath, (err) => {\n                if (err) {\n                    return callback(err, null);\n                } else {\n                    return callback(null, true);\n                }\n            });\n        } else if (stats.isDirectory()) {\n            fs.readdir(inputPath, (err, files) => {\n                if (err) {\n                    callback(err, null);\n                    return;\n                }\n                const f_length = files.length;\n                let f_delete_index = 0;\n\n                const checkStatus = () => {\n                    if (f_length === f_delete_index) {\n                        if(!isRoot) {\n                            fs.rmdir(inputPath, (err) => {\n                                if (err) {\n                                    return callback(err, null);\n                                } else {\n                                    return callback(null, true);\n                                }\n                            });\n                        }\n                        callback(null, true);\n                        return true;\n                    }\n                    return false;\n                };\n                if (!checkStatus()) {\n                    files.forEach((file) => {\n                        const tempPath = path.join(inputPath, file);\n                        deleteRecursively(tempPath, false,(err, status) => {\n                            if (!err) {\n                                f_delete_index++;\n                                checkStatus();\n                            } else {\n                                return callback(err, null);\n                            }\n                        });\n                    });\n                }\n            });\n        }\n    });\n}\n\nmodule.exports = {\n    generatePath,\n    processUrl,\n    deleteRecursively\n};\n\n","const RootCSB = require(\"../libraries/RootCSB\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\n\n\nmodule.exports.validatePin = function (localFolder, swarm, phaseName, pin, noTries, ...args) {\n\tRootCSB.createRootCSB(localFolder, undefined, undefined, pin, (err, rootCSB, csbIdentifier, backups) =>{\n\t\tif(err){\n\t\t\tswarm.swarm(\"interaction\", \"readPin\", noTries - 1);\n\t\t}else{\n\t\t\tif(csbIdentifier){\n\t\t\t\tswarm.rootCSB = rootCSB;\n\t\t\t\tswarm.csbIdentifier = csbIdentifier;\n\t\t\t}\n\t\t\targs.push(backups);\n\t\t\tswarm[phaseName](pin, ...args);\n\t\t}\n\t});\n};\n\nmodule.exports.reportOrContinue = function(swarm, phaseName, errorMessage, ...args){\n\treturn function(err,...res) {\n\t\tif (err) {\n\t\t\tswarm.swarm(\"interaction\", \"handleError\", err, errorMessage);\n\t\t} else {\n\t\t\tif (phaseName) {\n\t\t\t\t\tswarm[phaseName](...res, ...args);\n\t\t\t}\n\t\t}\n\t};\n};\n\nmodule.exports.checkMasterCSBExists = function (localFolder, callback) {\n\tfs.stat(path.join(localFolder, \".privateSky/hash\"), (err, stats)=>{\n\t\tif(err){\n\t\t\treturn callback(err, false);\n\t\t}\n\n\t\treturn callback(undefined, true);\n\t});\n};","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar has = Object.prototype.hasOwnProperty;\nvar hasNativeMap = typeof Map !== \"undefined\";\n\n/**\n * A data structure which is a combination of an array and a set. Adding a new\n * member is O(1), testing for membership is O(1), and finding the index of an\n * element is O(1). Removing elements from the set is not supported. Only\n * strings are supported for membership.\n */\nfunction ArraySet() {\n  this._array = [];\n  this._set = hasNativeMap ? new Map() : Object.create(null);\n}\n\n/**\n * Static method for creating ArraySet instances from an existing array.\n */\nArraySet.fromArray = function ArraySet_fromArray(aArray, aAllowDuplicates) {\n  var set = new ArraySet();\n  for (var i = 0, len = aArray.length; i < len; i++) {\n    set.add(aArray[i], aAllowDuplicates);\n  }\n  return set;\n};\n\n/**\n * Return how many unique items are in this ArraySet. If duplicates have been\n * added, than those do not count towards the size.\n *\n * @returns Number\n */\nArraySet.prototype.size = function ArraySet_size() {\n  return hasNativeMap ? this._set.size : Object.getOwnPropertyNames(this._set).length;\n};\n\n/**\n * Add the given string to this set.\n *\n * @param String aStr\n */\nArraySet.prototype.add = function ArraySet_add(aStr, aAllowDuplicates) {\n  var sStr = hasNativeMap ? aStr : util.toSetString(aStr);\n  var isDuplicate = hasNativeMap ? this.has(aStr) : has.call(this._set, sStr);\n  var idx = this._array.length;\n  if (!isDuplicate || aAllowDuplicates) {\n    this._array.push(aStr);\n  }\n  if (!isDuplicate) {\n    if (hasNativeMap) {\n      this._set.set(aStr, idx);\n    } else {\n      this._set[sStr] = idx;\n    }\n  }\n};\n\n/**\n * Is the given string a member of this set?\n *\n * @param String aStr\n */\nArraySet.prototype.has = function ArraySet_has(aStr) {\n  if (hasNativeMap) {\n    return this._set.has(aStr);\n  } else {\n    var sStr = util.toSetString(aStr);\n    return has.call(this._set, sStr);\n  }\n};\n\n/**\n * What is the index of the given string in the array?\n *\n * @param String aStr\n */\nArraySet.prototype.indexOf = function ArraySet_indexOf(aStr) {\n  if (hasNativeMap) {\n    var idx = this._set.get(aStr);\n    if (idx >= 0) {\n        return idx;\n    }\n  } else {\n    var sStr = util.toSetString(aStr);\n    if (has.call(this._set, sStr)) {\n      return this._set[sStr];\n    }\n  }\n\n  throw new Error('\"' + aStr + '\" is not in the set.');\n};\n\n/**\n * What is the element at the given index?\n *\n * @param Number aIdx\n */\nArraySet.prototype.at = function ArraySet_at(aIdx) {\n  if (aIdx >= 0 && aIdx < this._array.length) {\n    return this._array[aIdx];\n  }\n  throw new Error('No element indexed by ' + aIdx);\n};\n\n/**\n * Returns the array representation of this set (which has the proper indices\n * indicated by indexOf). Note that this is a copy of the internal array used\n * for storing the members so that no one can mess with internal state.\n */\nArraySet.prototype.toArray = function ArraySet_toArray() {\n  return this._array.slice();\n};\n\nexports.ArraySet = ArraySet;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n *\n * Based on the Base 64 VLQ implementation in Closure Compiler:\n * https://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/debugging/sourcemap/Base64VLQ.java\n *\n * Copyright 2011 The Closure Compiler Authors. All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above\n *    copyright notice, this list of conditions and the following\n *    disclaimer in the documentation and/or other materials provided\n *    with the distribution.\n *  * Neither the name of Google Inc. nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nvar base64 = require('./base64');\n\n// A single base 64 digit can contain 6 bits of data. For the base 64 variable\n// length quantities we use in the source map spec, the first bit is the sign,\n// the next four bits are the actual value, and the 6th bit is the\n// continuation bit. The continuation bit tells us whether there are more\n// digits in this value following this digit.\n//\n//   Continuation\n//   |    Sign\n//   |    |\n//   V    V\n//   101011\n\nvar VLQ_BASE_SHIFT = 5;\n\n// binary: 100000\nvar VLQ_BASE = 1 << VLQ_BASE_SHIFT;\n\n// binary: 011111\nvar VLQ_BASE_MASK = VLQ_BASE - 1;\n\n// binary: 100000\nvar VLQ_CONTINUATION_BIT = VLQ_BASE;\n\n/**\n * Converts from a two-complement value to a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   1 becomes 2 (10 binary), -1 becomes 3 (11 binary)\n *   2 becomes 4 (100 binary), -2 becomes 5 (101 binary)\n */\nfunction toVLQSigned(aValue) {\n  return aValue < 0\n    ? ((-aValue) << 1) + 1\n    : (aValue << 1) + 0;\n}\n\n/**\n * Converts to a two-complement value from a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   2 (10 binary) becomes 1, 3 (11 binary) becomes -1\n *   4 (100 binary) becomes 2, 5 (101 binary) becomes -2\n */\nfunction fromVLQSigned(aValue) {\n  var isNegative = (aValue & 1) === 1;\n  var shifted = aValue >> 1;\n  return isNegative\n    ? -shifted\n    : shifted;\n}\n\n/**\n * Returns the base 64 VLQ encoded value.\n */\nexports.encode = function base64VLQ_encode(aValue) {\n  var encoded = \"\";\n  var digit;\n\n  var vlq = toVLQSigned(aValue);\n\n  do {\n    digit = vlq & VLQ_BASE_MASK;\n    vlq >>>= VLQ_BASE_SHIFT;\n    if (vlq > 0) {\n      // There are still more digits in this value, so we must make sure the\n      // continuation bit is marked.\n      digit |= VLQ_CONTINUATION_BIT;\n    }\n    encoded += base64.encode(digit);\n  } while (vlq > 0);\n\n  return encoded;\n};\n\n/**\n * Decodes the next base 64 VLQ value from the given string and returns the\n * value and the rest of the string via the out parameter.\n */\nexports.decode = function base64VLQ_decode(aStr, aIndex, aOutParam) {\n  var strLen = aStr.length;\n  var result = 0;\n  var shift = 0;\n  var continuation, digit;\n\n  do {\n    if (aIndex >= strLen) {\n      throw new Error(\"Expected more digits in base 64 VLQ value.\");\n    }\n\n    digit = base64.decode(aStr.charCodeAt(aIndex++));\n    if (digit === -1) {\n      throw new Error(\"Invalid base64 digit: \" + aStr.charAt(aIndex - 1));\n    }\n\n    continuation = !!(digit & VLQ_CONTINUATION_BIT);\n    digit &= VLQ_BASE_MASK;\n    result = result + (digit << shift);\n    shift += VLQ_BASE_SHIFT;\n  } while (continuation);\n\n  aOutParam.value = fromVLQSigned(result);\n  aOutParam.rest = aIndex;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar intToCharMap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');\n\n/**\n * Encode an integer in the range of 0 to 63 to a single base 64 digit.\n */\nexports.encode = function (number) {\n  if (0 <= number && number < intToCharMap.length) {\n    return intToCharMap[number];\n  }\n  throw new TypeError(\"Must be between 0 and 63: \" + number);\n};\n\n/**\n * Decode a single base 64 character code digit to an integer. Returns -1 on\n * failure.\n */\nexports.decode = function (charCode) {\n  var bigA = 65;     // 'A'\n  var bigZ = 90;     // 'Z'\n\n  var littleA = 97;  // 'a'\n  var littleZ = 122; // 'z'\n\n  var zero = 48;     // '0'\n  var nine = 57;     // '9'\n\n  var plus = 43;     // '+'\n  var slash = 47;    // '/'\n\n  var littleOffset = 26;\n  var numberOffset = 52;\n\n  // 0 - 25: ABCDEFGHIJKLMNOPQRSTUVWXYZ\n  if (bigA <= charCode && charCode <= bigZ) {\n    return (charCode - bigA);\n  }\n\n  // 26 - 51: abcdefghijklmnopqrstuvwxyz\n  if (littleA <= charCode && charCode <= littleZ) {\n    return (charCode - littleA + littleOffset);\n  }\n\n  // 52 - 61: 0123456789\n  if (zero <= charCode && charCode <= nine) {\n    return (charCode - zero + numberOffset);\n  }\n\n  // 62: +\n  if (charCode == plus) {\n    return 62;\n  }\n\n  // 63: /\n  if (charCode == slash) {\n    return 63;\n  }\n\n  // Invalid base64 digit.\n  return -1;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nexports.GREATEST_LOWER_BOUND = 1;\nexports.LEAST_UPPER_BOUND = 2;\n\n/**\n * Recursive implementation of binary search.\n *\n * @param aLow Indices here and lower do not contain the needle.\n * @param aHigh Indices here and higher do not contain the needle.\n * @param aNeedle The element being searched for.\n * @param aHaystack The non-empty array being searched.\n * @param aCompare Function which takes two elements and returns -1, 0, or 1.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n */\nfunction recursiveSearch(aLow, aHigh, aNeedle, aHaystack, aCompare, aBias) {\n  // This function terminates when one of the following is true:\n  //\n  //   1. We find the exact element we are looking for.\n  //\n  //   2. We did not find the exact element, but we can return the index of\n  //      the next-closest element.\n  //\n  //   3. We did not find the exact element, and there is no next-closest\n  //      element than the one we are searching for, so we return -1.\n  var mid = Math.floor((aHigh - aLow) / 2) + aLow;\n  var cmp = aCompare(aNeedle, aHaystack[mid], true);\n  if (cmp === 0) {\n    // Found the element we are looking for.\n    return mid;\n  }\n  else if (cmp > 0) {\n    // Our needle is greater than aHaystack[mid].\n    if (aHigh - mid > 1) {\n      // The element is in the upper half.\n      return recursiveSearch(mid, aHigh, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // The exact needle element was not found in this haystack. Determine if\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return aHigh < aHaystack.length ? aHigh : -1;\n    } else {\n      return mid;\n    }\n  }\n  else {\n    // Our needle is less than aHaystack[mid].\n    if (mid - aLow > 1) {\n      // The element is in the lower half.\n      return recursiveSearch(aLow, mid, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return mid;\n    } else {\n      return aLow < 0 ? -1 : aLow;\n    }\n  }\n}\n\n/**\n * This is an implementation of binary search which will always try and return\n * the index of the closest element if there is no exact hit. This is because\n * mappings between original and generated line/col pairs are single points,\n * and there is an implicit region between each of them, so a miss just means\n * that you aren't on the very start of a region.\n *\n * @param aNeedle The element you are looking for.\n * @param aHaystack The array that is being searched.\n * @param aCompare A function which takes the needle and an element in the\n *     array and returns -1, 0, or 1 depending on whether the needle is less\n *     than, equal to, or greater than the element, respectively.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'binarySearch.GREATEST_LOWER_BOUND'.\n */\nexports.search = function search(aNeedle, aHaystack, aCompare, aBias) {\n  if (aHaystack.length === 0) {\n    return -1;\n  }\n\n  var index = recursiveSearch(-1, aHaystack.length, aNeedle, aHaystack,\n                              aCompare, aBias || exports.GREATEST_LOWER_BOUND);\n  if (index < 0) {\n    return -1;\n  }\n\n  // We have found either the exact element, or the next-closest element than\n  // the one we are searching for. However, there may be more than one such\n  // element. Make sure we always return the smallest of these.\n  while (index - 1 >= 0) {\n    if (aCompare(aHaystack[index], aHaystack[index - 1], true) !== 0) {\n      break;\n    }\n    --index;\n  }\n\n  return index;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2014 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\n\n/**\n * Determine whether mappingB is after mappingA with respect to generated\n * position.\n */\nfunction generatedPositionAfter(mappingA, mappingB) {\n  // Optimized for most common case\n  var lineA = mappingA.generatedLine;\n  var lineB = mappingB.generatedLine;\n  var columnA = mappingA.generatedColumn;\n  var columnB = mappingB.generatedColumn;\n  return lineB > lineA || lineB == lineA && columnB >= columnA ||\n         util.compareByGeneratedPositionsInflated(mappingA, mappingB) <= 0;\n}\n\n/**\n * A data structure to provide a sorted view of accumulated mappings in a\n * performance conscious manner. It trades a neglibable overhead in general\n * case for a large speedup in case of mappings being added in order.\n */\nfunction MappingList() {\n  this._array = [];\n  this._sorted = true;\n  // Serves as infimum\n  this._last = {generatedLine: -1, generatedColumn: 0};\n}\n\n/**\n * Iterate through internal items. This method takes the same arguments that\n * `Array.prototype.forEach` takes.\n *\n * NOTE: The order of the mappings is NOT guaranteed.\n */\nMappingList.prototype.unsortedForEach =\n  function MappingList_forEach(aCallback, aThisArg) {\n    this._array.forEach(aCallback, aThisArg);\n  };\n\n/**\n * Add the given source mapping.\n *\n * @param Object aMapping\n */\nMappingList.prototype.add = function MappingList_add(aMapping) {\n  if (generatedPositionAfter(this._last, aMapping)) {\n    this._last = aMapping;\n    this._array.push(aMapping);\n  } else {\n    this._sorted = false;\n    this._array.push(aMapping);\n  }\n};\n\n/**\n * Returns the flat, sorted array of mappings. The mappings are sorted by\n * generated position.\n *\n * WARNING: This method returns internal data without copying, for\n * performance. The return value must NOT be mutated, and should be treated as\n * an immutable borrow. If you want to take ownership, you must make your own\n * copy.\n */\nMappingList.prototype.toArray = function MappingList_toArray() {\n  if (!this._sorted) {\n    this._array.sort(util.compareByGeneratedPositionsInflated);\n    this._sorted = true;\n  }\n  return this._array;\n};\n\nexports.MappingList = MappingList;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n// It turns out that some (most?) JavaScript engines don't self-host\n// `Array.prototype.sort`. This makes sense because C++ will likely remain\n// faster than JS when doing raw CPU-intensive sorting. However, when using a\n// custom comparator function, calling back and forth between the VM's C++ and\n// JIT'd JS is rather slow *and* loses JIT type information, resulting in\n// worse generated code for the comparator function than would be optimal. In\n// fact, when sorting with a comparator, these costs outweigh the benefits of\n// sorting in C++. By using our own JS-implemented Quick Sort (below), we get\n// a ~3500ms mean speed-up in `bench/bench.html`.\n\n/**\n * Swap the elements indexed by `x` and `y` in the array `ary`.\n *\n * @param {Array} ary\n *        The array.\n * @param {Number} x\n *        The index of the first item.\n * @param {Number} y\n *        The index of the second item.\n */\nfunction swap(ary, x, y) {\n  var temp = ary[x];\n  ary[x] = ary[y];\n  ary[y] = temp;\n}\n\n/**\n * Returns a random integer within the range `low .. high` inclusive.\n *\n * @param {Number} low\n *        The lower bound on the range.\n * @param {Number} high\n *        The upper bound on the range.\n */\nfunction randomIntInRange(low, high) {\n  return Math.round(low + (Math.random() * (high - low)));\n}\n\n/**\n * The Quick Sort algorithm.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n * @param {Number} p\n *        Start index of the array\n * @param {Number} r\n *        End index of the array\n */\nfunction doQuickSort(ary, comparator, p, r) {\n  // If our lower bound is less than our upper bound, we (1) partition the\n  // array into two pieces and (2) recurse on each half. If it is not, this is\n  // the empty array and our base case.\n\n  if (p < r) {\n    // (1) Partitioning.\n    //\n    // The partitioning chooses a pivot between `p` and `r` and moves all\n    // elements that are less than or equal to the pivot to the before it, and\n    // all the elements that are greater than it after it. The effect is that\n    // once partition is done, the pivot is in the exact place it will be when\n    // the array is put in sorted order, and it will not need to be moved\n    // again. This runs in O(n) time.\n\n    // Always choose a random pivot so that an input array which is reverse\n    // sorted does not cause O(n^2) running time.\n    var pivotIndex = randomIntInRange(p, r);\n    var i = p - 1;\n\n    swap(ary, pivotIndex, r);\n    var pivot = ary[r];\n\n    // Immediately after `j` is incremented in this loop, the following hold\n    // true:\n    //\n    //   * Every element in `ary[p .. i]` is less than or equal to the pivot.\n    //\n    //   * Every element in `ary[i+1 .. j-1]` is greater than the pivot.\n    for (var j = p; j < r; j++) {\n      if (comparator(ary[j], pivot) <= 0) {\n        i += 1;\n        swap(ary, i, j);\n      }\n    }\n\n    swap(ary, i + 1, j);\n    var q = i + 1;\n\n    // (2) Recurse on each half.\n\n    doQuickSort(ary, comparator, p, q - 1);\n    doQuickSort(ary, comparator, q + 1, r);\n  }\n}\n\n/**\n * Sort the given array in-place with the given comparator function.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n */\nexports.quickSort = function (ary, comparator) {\n  doQuickSort(ary, comparator, 0, ary.length - 1);\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar binarySearch = require('./binary-search');\nvar ArraySet = require('./array-set').ArraySet;\nvar base64VLQ = require('./base64-vlq');\nvar quickSort = require('./quick-sort').quickSort;\n\nfunction SourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  return sourceMap.sections != null\n    ? new IndexedSourceMapConsumer(sourceMap)\n    : new BasicSourceMapConsumer(sourceMap);\n}\n\nSourceMapConsumer.fromSourceMap = function(aSourceMap) {\n  return BasicSourceMapConsumer.fromSourceMap(aSourceMap);\n}\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nSourceMapConsumer.prototype._version = 3;\n\n// `__generatedMappings` and `__originalMappings` are arrays that hold the\n// parsed mapping coordinates from the source map's \"mappings\" attribute. They\n// are lazily instantiated, accessed via the `_generatedMappings` and\n// `_originalMappings` getters respectively, and we only parse the mappings\n// and create these arrays once queried for a source location. We jump through\n// these hoops because there can be many thousands of mappings, and parsing\n// them is expensive, so we only want to do it if we must.\n//\n// Each object in the arrays is of the form:\n//\n//     {\n//       generatedLine: The line number in the generated code,\n//       generatedColumn: The column number in the generated code,\n//       source: The path to the original source file that generated this\n//               chunk of code,\n//       originalLine: The line number in the original source that\n//                     corresponds to this chunk of generated code,\n//       originalColumn: The column number in the original source that\n//                       corresponds to this chunk of generated code,\n//       name: The name of the original symbol which generated this chunk of\n//             code.\n//     }\n//\n// All properties except for `generatedLine` and `generatedColumn` can be\n// `null`.\n//\n// `_generatedMappings` is ordered by the generated positions.\n//\n// `_originalMappings` is ordered by the original positions.\n\nSourceMapConsumer.prototype.__generatedMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_generatedMappings', {\n  get: function () {\n    if (!this.__generatedMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__generatedMappings;\n  }\n});\n\nSourceMapConsumer.prototype.__originalMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_originalMappings', {\n  get: function () {\n    if (!this.__originalMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__originalMappings;\n  }\n});\n\nSourceMapConsumer.prototype._charIsMappingSeparator =\n  function SourceMapConsumer_charIsMappingSeparator(aStr, index) {\n    var c = aStr.charAt(index);\n    return c === \";\" || c === \",\";\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    throw new Error(\"Subclasses must implement _parseMappings\");\n  };\n\nSourceMapConsumer.GENERATED_ORDER = 1;\nSourceMapConsumer.ORIGINAL_ORDER = 2;\n\nSourceMapConsumer.GREATEST_LOWER_BOUND = 1;\nSourceMapConsumer.LEAST_UPPER_BOUND = 2;\n\n/**\n * Iterate over each mapping between an original source/line/column and a\n * generated line/column in this source map.\n *\n * @param Function aCallback\n *        The function that is called with each mapping.\n * @param Object aContext\n *        Optional. If specified, this object will be the value of `this` every\n *        time that `aCallback` is called.\n * @param aOrder\n *        Either `SourceMapConsumer.GENERATED_ORDER` or\n *        `SourceMapConsumer.ORIGINAL_ORDER`. Specifies whether you want to\n *        iterate over the mappings sorted by the generated file's line/column\n *        order or the original's source/line/column order, respectively. Defaults to\n *        `SourceMapConsumer.GENERATED_ORDER`.\n */\nSourceMapConsumer.prototype.eachMapping =\n  function SourceMapConsumer_eachMapping(aCallback, aContext, aOrder) {\n    var context = aContext || null;\n    var order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n\n    var mappings;\n    switch (order) {\n    case SourceMapConsumer.GENERATED_ORDER:\n      mappings = this._generatedMappings;\n      break;\n    case SourceMapConsumer.ORIGINAL_ORDER:\n      mappings = this._originalMappings;\n      break;\n    default:\n      throw new Error(\"Unknown order of iteration.\");\n    }\n\n    var sourceRoot = this.sourceRoot;\n    mappings.map(function (mapping) {\n      var source = mapping.source === null ? null : this._sources.at(mapping.source);\n      if (source != null && sourceRoot != null) {\n        source = util.join(sourceRoot, source);\n      }\n      return {\n        source: source,\n        generatedLine: mapping.generatedLine,\n        generatedColumn: mapping.generatedColumn,\n        originalLine: mapping.originalLine,\n        originalColumn: mapping.originalColumn,\n        name: mapping.name === null ? null : this._names.at(mapping.name)\n      };\n    }, this).forEach(aCallback, context);\n  };\n\n/**\n * Returns all generated line and column information for the original source,\n * line, and column provided. If no column is provided, returns all mappings\n * corresponding to a either the line we are searching for or the next\n * closest line that has any mappings. Otherwise, returns all mappings\n * corresponding to the given line and either the column we are searching for\n * or the next closest column that has any offsets.\n *\n * The only argument is an object with the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: Optional. the column number in the original source.\n *\n * and an array of objects is returned, each with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nSourceMapConsumer.prototype.allGeneratedPositionsFor =\n  function SourceMapConsumer_allGeneratedPositionsFor(aArgs) {\n    var line = util.getArg(aArgs, 'line');\n\n    // When there is no exact match, BasicSourceMapConsumer.prototype._findMapping\n    // returns the index of the closest mapping less than the needle. By\n    // setting needle.originalColumn to 0, we thus find the last mapping for\n    // the given line, provided such a mapping exists.\n    var needle = {\n      source: util.getArg(aArgs, 'source'),\n      originalLine: line,\n      originalColumn: util.getArg(aArgs, 'column', 0)\n    };\n\n    if (this.sourceRoot != null) {\n      needle.source = util.relative(this.sourceRoot, needle.source);\n    }\n    if (!this._sources.has(needle.source)) {\n      return [];\n    }\n    needle.source = this._sources.indexOf(needle.source);\n\n    var mappings = [];\n\n    var index = this._findMapping(needle,\n                                  this._originalMappings,\n                                  \"originalLine\",\n                                  \"originalColumn\",\n                                  util.compareByOriginalPositions,\n                                  binarySearch.LEAST_UPPER_BOUND);\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (aArgs.column === undefined) {\n        var originalLine = mapping.originalLine;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we found. Since\n        // mappings are sorted, this is guaranteed to find all mappings for\n        // the line we found.\n        while (mapping && mapping.originalLine === originalLine) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      } else {\n        var originalColumn = mapping.originalColumn;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we were searching for.\n        // Since mappings are sorted, this is guaranteed to find all mappings for\n        // the line we are searching for.\n        while (mapping &&\n               mapping.originalLine === line &&\n               mapping.originalColumn == originalColumn) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      }\n    }\n\n    return mappings;\n  };\n\nexports.SourceMapConsumer = SourceMapConsumer;\n\n/**\n * A BasicSourceMapConsumer instance represents a parsed source map which we can\n * query for information about the original file positions by giving it a file\n * position in the generated source.\n *\n * The only parameter is the raw source map (either as a JSON string, or\n * already parsed to an object). According to the spec, source maps have the\n * following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - sources: An array of URLs to the original source files.\n *   - names: An array of identifiers which can be referrenced by individual mappings.\n *   - sourceRoot: Optional. The URL root from which all sources are relative.\n *   - sourcesContent: Optional. An array of contents of the original source files.\n *   - mappings: A string of base64 VLQs which contain the actual mappings.\n *   - file: Optional. The generated file this source map is associated with.\n *\n * Here is an example source map, taken from the source map spec[0]:\n *\n *     {\n *       version : 3,\n *       file: \"out.js\",\n *       sourceRoot : \"\",\n *       sources: [\"foo.js\", \"bar.js\"],\n *       names: [\"src\", \"maps\", \"are\", \"fun\"],\n *       mappings: \"AA,AB;;ABCDE;\"\n *     }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?pli=1#\n */\nfunction BasicSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sources = util.getArg(sourceMap, 'sources');\n  // Sass 3.3 leaves out the 'names' array, so we deviate from the spec (which\n  // requires the array) to play nice here.\n  var names = util.getArg(sourceMap, 'names', []);\n  var sourceRoot = util.getArg(sourceMap, 'sourceRoot', null);\n  var sourcesContent = util.getArg(sourceMap, 'sourcesContent', null);\n  var mappings = util.getArg(sourceMap, 'mappings');\n  var file = util.getArg(sourceMap, 'file', null);\n\n  // Once again, Sass deviates from the spec and supplies the version as a\n  // string rather than a number, so we use loose equality checking here.\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  sources = sources\n    .map(String)\n    // Some source maps produce relative source paths like \"./foo.js\" instead of\n    // \"foo.js\".  Normalize these first so that future comparisons will succeed.\n    // See bugzil.la/1090768.\n    .map(util.normalize)\n    // Always ensure that absolute sources are internally stored relative to\n    // the source root, if the source root is absolute. Not doing this would\n    // be particularly problematic when the source root is a prefix of the\n    // source (valid, but why??). See github issue #199 and bugzil.la/1188982.\n    .map(function (source) {\n      return sourceRoot && util.isAbsolute(sourceRoot) && util.isAbsolute(source)\n        ? util.relative(sourceRoot, source)\n        : source;\n    });\n\n  // Pass `true` below to allow duplicate names and sources. While source maps\n  // are intended to be compressed and deduplicated, the TypeScript compiler\n  // sometimes generates source maps with duplicates in them. See Github issue\n  // #72 and bugzil.la/889492.\n  this._names = ArraySet.fromArray(names.map(String), true);\n  this._sources = ArraySet.fromArray(sources, true);\n\n  this.sourceRoot = sourceRoot;\n  this.sourcesContent = sourcesContent;\n  this._mappings = mappings;\n  this.file = file;\n}\n\nBasicSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nBasicSourceMapConsumer.prototype.consumer = SourceMapConsumer;\n\n/**\n * Create a BasicSourceMapConsumer from a SourceMapGenerator.\n *\n * @param SourceMapGenerator aSourceMap\n *        The source map that will be consumed.\n * @returns BasicSourceMapConsumer\n */\nBasicSourceMapConsumer.fromSourceMap =\n  function SourceMapConsumer_fromSourceMap(aSourceMap) {\n    var smc = Object.create(BasicSourceMapConsumer.prototype);\n\n    var names = smc._names = ArraySet.fromArray(aSourceMap._names.toArray(), true);\n    var sources = smc._sources = ArraySet.fromArray(aSourceMap._sources.toArray(), true);\n    smc.sourceRoot = aSourceMap._sourceRoot;\n    smc.sourcesContent = aSourceMap._generateSourcesContent(smc._sources.toArray(),\n                                                            smc.sourceRoot);\n    smc.file = aSourceMap._file;\n\n    // Because we are modifying the entries (by converting string sources and\n    // names to indices into the sources and names ArraySets), we have to make\n    // a copy of the entry or else bad things happen. Shared mutable state\n    // strikes again! See github issue #191.\n\n    var generatedMappings = aSourceMap._mappings.toArray().slice();\n    var destGeneratedMappings = smc.__generatedMappings = [];\n    var destOriginalMappings = smc.__originalMappings = [];\n\n    for (var i = 0, length = generatedMappings.length; i < length; i++) {\n      var srcMapping = generatedMappings[i];\n      var destMapping = new Mapping;\n      destMapping.generatedLine = srcMapping.generatedLine;\n      destMapping.generatedColumn = srcMapping.generatedColumn;\n\n      if (srcMapping.source) {\n        destMapping.source = sources.indexOf(srcMapping.source);\n        destMapping.originalLine = srcMapping.originalLine;\n        destMapping.originalColumn = srcMapping.originalColumn;\n\n        if (srcMapping.name) {\n          destMapping.name = names.indexOf(srcMapping.name);\n        }\n\n        destOriginalMappings.push(destMapping);\n      }\n\n      destGeneratedMappings.push(destMapping);\n    }\n\n    quickSort(smc.__originalMappings, util.compareByOriginalPositions);\n\n    return smc;\n  };\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nBasicSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(BasicSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    return this._sources.toArray().map(function (s) {\n      return this.sourceRoot != null ? util.join(this.sourceRoot, s) : s;\n    }, this);\n  }\n});\n\n/**\n * Provide the JIT with a nice shape / hidden class.\n */\nfunction Mapping() {\n  this.generatedLine = 0;\n  this.generatedColumn = 0;\n  this.source = null;\n  this.originalLine = null;\n  this.originalColumn = null;\n  this.name = null;\n}\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nBasicSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    var generatedLine = 1;\n    var previousGeneratedColumn = 0;\n    var previousOriginalLine = 0;\n    var previousOriginalColumn = 0;\n    var previousSource = 0;\n    var previousName = 0;\n    var length = aStr.length;\n    var index = 0;\n    var cachedSegments = {};\n    var temp = {};\n    var originalMappings = [];\n    var generatedMappings = [];\n    var mapping, str, segment, end, value;\n\n    while (index < length) {\n      if (aStr.charAt(index) === ';') {\n        generatedLine++;\n        index++;\n        previousGeneratedColumn = 0;\n      }\n      else if (aStr.charAt(index) === ',') {\n        index++;\n      }\n      else {\n        mapping = new Mapping();\n        mapping.generatedLine = generatedLine;\n\n        // Because each offset is encoded relative to the previous one,\n        // many segments often have the same encoding. We can exploit this\n        // fact by caching the parsed variable length fields of each segment,\n        // allowing us to avoid a second parse if we encounter the same\n        // segment again.\n        for (end = index; end < length; end++) {\n          if (this._charIsMappingSeparator(aStr, end)) {\n            break;\n          }\n        }\n        str = aStr.slice(index, end);\n\n        segment = cachedSegments[str];\n        if (segment) {\n          index += str.length;\n        } else {\n          segment = [];\n          while (index < end) {\n            base64VLQ.decode(aStr, index, temp);\n            value = temp.value;\n            index = temp.rest;\n            segment.push(value);\n          }\n\n          if (segment.length === 2) {\n            throw new Error('Found a source, but no line and column');\n          }\n\n          if (segment.length === 3) {\n            throw new Error('Found a source and line, but no column');\n          }\n\n          cachedSegments[str] = segment;\n        }\n\n        // Generated column.\n        mapping.generatedColumn = previousGeneratedColumn + segment[0];\n        previousGeneratedColumn = mapping.generatedColumn;\n\n        if (segment.length > 1) {\n          // Original source.\n          mapping.source = previousSource + segment[1];\n          previousSource += segment[1];\n\n          // Original line.\n          mapping.originalLine = previousOriginalLine + segment[2];\n          previousOriginalLine = mapping.originalLine;\n          // Lines are stored 0-based\n          mapping.originalLine += 1;\n\n          // Original column.\n          mapping.originalColumn = previousOriginalColumn + segment[3];\n          previousOriginalColumn = mapping.originalColumn;\n\n          if (segment.length > 4) {\n            // Original name.\n            mapping.name = previousName + segment[4];\n            previousName += segment[4];\n          }\n        }\n\n        generatedMappings.push(mapping);\n        if (typeof mapping.originalLine === 'number') {\n          originalMappings.push(mapping);\n        }\n      }\n    }\n\n    quickSort(generatedMappings, util.compareByGeneratedPositionsDeflated);\n    this.__generatedMappings = generatedMappings;\n\n    quickSort(originalMappings, util.compareByOriginalPositions);\n    this.__originalMappings = originalMappings;\n  };\n\n/**\n * Find the mapping that best matches the hypothetical \"needle\" mapping that\n * we are searching for in the given \"haystack\" of mappings.\n */\nBasicSourceMapConsumer.prototype._findMapping =\n  function SourceMapConsumer_findMapping(aNeedle, aMappings, aLineName,\n                                         aColumnName, aComparator, aBias) {\n    // To return the position we are searching for, we must first find the\n    // mapping for the given position and then return the opposite position it\n    // points to. Because the mappings are sorted, we can use binary search to\n    // find the best mapping.\n\n    if (aNeedle[aLineName] <= 0) {\n      throw new TypeError('Line must be greater than or equal to 1, got '\n                          + aNeedle[aLineName]);\n    }\n    if (aNeedle[aColumnName] < 0) {\n      throw new TypeError('Column must be greater than or equal to 0, got '\n                          + aNeedle[aColumnName]);\n    }\n\n    return binarySearch.search(aNeedle, aMappings, aComparator, aBias);\n  };\n\n/**\n * Compute the last column for each generated mapping. The last column is\n * inclusive.\n */\nBasicSourceMapConsumer.prototype.computeColumnSpans =\n  function SourceMapConsumer_computeColumnSpans() {\n    for (var index = 0; index < this._generatedMappings.length; ++index) {\n      var mapping = this._generatedMappings[index];\n\n      // Mappings do not contain a field for the last generated columnt. We\n      // can come up with an optimistic estimate, however, by assuming that\n      // mappings are contiguous (i.e. given two consecutive mappings, the\n      // first mapping ends where the second one starts).\n      if (index + 1 < this._generatedMappings.length) {\n        var nextMapping = this._generatedMappings[index + 1];\n\n        if (mapping.generatedLine === nextMapping.generatedLine) {\n          mapping.lastGeneratedColumn = nextMapping.generatedColumn - 1;\n          continue;\n        }\n      }\n\n      // The last mapping for each line spans the entire line.\n      mapping.lastGeneratedColumn = Infinity;\n    }\n  };\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nBasicSourceMapConsumer.prototype.originalPositionFor =\n  function SourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._generatedMappings,\n      \"generatedLine\",\n      \"generatedColumn\",\n      util.compareByGeneratedPositionsDeflated,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._generatedMappings[index];\n\n      if (mapping.generatedLine === needle.generatedLine) {\n        var source = util.getArg(mapping, 'source', null);\n        if (source !== null) {\n          source = this._sources.at(source);\n          if (this.sourceRoot != null) {\n            source = util.join(this.sourceRoot, source);\n          }\n        }\n        var name = util.getArg(mapping, 'name', null);\n        if (name !== null) {\n          name = this._names.at(name);\n        }\n        return {\n          source: source,\n          line: util.getArg(mapping, 'originalLine', null),\n          column: util.getArg(mapping, 'originalColumn', null),\n          name: name\n        };\n      }\n    }\n\n    return {\n      source: null,\n      line: null,\n      column: null,\n      name: null\n    };\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nBasicSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function BasicSourceMapConsumer_hasContentsOfAllSources() {\n    if (!this.sourcesContent) {\n      return false;\n    }\n    return this.sourcesContent.length >= this._sources.size() &&\n      !this.sourcesContent.some(function (sc) { return sc == null; });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nBasicSourceMapConsumer.prototype.sourceContentFor =\n  function SourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    if (!this.sourcesContent) {\n      return null;\n    }\n\n    if (this.sourceRoot != null) {\n      aSource = util.relative(this.sourceRoot, aSource);\n    }\n\n    if (this._sources.has(aSource)) {\n      return this.sourcesContent[this._sources.indexOf(aSource)];\n    }\n\n    var url;\n    if (this.sourceRoot != null\n        && (url = util.urlParse(this.sourceRoot))) {\n      // XXX: file:// URIs and absolute paths lead to unexpected behavior for\n      // many users. We can help them out when they expect file:// URIs to\n      // behave like it would if they were running a local HTTP server. See\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=885597.\n      var fileUriAbsPath = aSource.replace(/^file:\\/\\//, \"\");\n      if (url.scheme == \"file\"\n          && this._sources.has(fileUriAbsPath)) {\n        return this.sourcesContent[this._sources.indexOf(fileUriAbsPath)]\n      }\n\n      if ((!url.path || url.path == \"/\")\n          && this._sources.has(\"/\" + aSource)) {\n        return this.sourcesContent[this._sources.indexOf(\"/\" + aSource)];\n      }\n    }\n\n    // This function is used recursively from\n    // IndexedSourceMapConsumer.prototype.sourceContentFor. In that case, we\n    // don't want to throw if we can't find the source - we just want to\n    // return null, so we provide a flag to exit gracefully.\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nBasicSourceMapConsumer.prototype.generatedPositionFor =\n  function SourceMapConsumer_generatedPositionFor(aArgs) {\n    var source = util.getArg(aArgs, 'source');\n    if (this.sourceRoot != null) {\n      source = util.relative(this.sourceRoot, source);\n    }\n    if (!this._sources.has(source)) {\n      return {\n        line: null,\n        column: null,\n        lastColumn: null\n      };\n    }\n    source = this._sources.indexOf(source);\n\n    var needle = {\n      source: source,\n      originalLine: util.getArg(aArgs, 'line'),\n      originalColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._originalMappings,\n      \"originalLine\",\n      \"originalColumn\",\n      util.compareByOriginalPositions,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (mapping.source === needle.source) {\n        return {\n          line: util.getArg(mapping, 'generatedLine', null),\n          column: util.getArg(mapping, 'generatedColumn', null),\n          lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n        };\n      }\n    }\n\n    return {\n      line: null,\n      column: null,\n      lastColumn: null\n    };\n  };\n\nexports.BasicSourceMapConsumer = BasicSourceMapConsumer;\n\n/**\n * An IndexedSourceMapConsumer instance represents a parsed source map which\n * we can query for information. It differs from BasicSourceMapConsumer in\n * that it takes \"indexed\" source maps (i.e. ones with a \"sections\" field) as\n * input.\n *\n * The only parameter is a raw source map (either as a JSON string, or already\n * parsed to an object). According to the spec for indexed source maps, they\n * have the following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - file: Optional. The generated file this source map is associated with.\n *   - sections: A list of section definitions.\n *\n * Each value under the \"sections\" field has two fields:\n *   - offset: The offset into the original specified at which this section\n *       begins to apply, defined as an object with a \"line\" and \"column\"\n *       field.\n *   - map: A source map definition. This source map could also be indexed,\n *       but doesn't have to be.\n *\n * Instead of the \"map\" field, it's also possible to have a \"url\" field\n * specifying a URL to retrieve a source map from, but that's currently\n * unsupported.\n *\n * Here's an example source map, taken from the source map spec[0], but\n * modified to omit a section which uses the \"url\" field.\n *\n *  {\n *    version : 3,\n *    file: \"app.js\",\n *    sections: [{\n *      offset: {line:100, column:10},\n *      map: {\n *        version : 3,\n *        file: \"section.js\",\n *        sources: [\"foo.js\", \"bar.js\"],\n *        names: [\"src\", \"maps\", \"are\", \"fun\"],\n *        mappings: \"AAAA,E;;ABCDE;\"\n *      }\n *    }],\n *  }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.535es3xeprgt\n */\nfunction IndexedSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sections = util.getArg(sourceMap, 'sections');\n\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n\n  var lastOffset = {\n    line: -1,\n    column: 0\n  };\n  this._sections = sections.map(function (s) {\n    if (s.url) {\n      // The url field will require support for asynchronicity.\n      // See https://github.com/mozilla/source-map/issues/16\n      throw new Error('Support for url field in sections not implemented.');\n    }\n    var offset = util.getArg(s, 'offset');\n    var offsetLine = util.getArg(offset, 'line');\n    var offsetColumn = util.getArg(offset, 'column');\n\n    if (offsetLine < lastOffset.line ||\n        (offsetLine === lastOffset.line && offsetColumn < lastOffset.column)) {\n      throw new Error('Section offsets must be ordered and non-overlapping.');\n    }\n    lastOffset = offset;\n\n    return {\n      generatedOffset: {\n        // The offset fields are 0-based, but we use 1-based indices when\n        // encoding/decoding from VLQ.\n        generatedLine: offsetLine + 1,\n        generatedColumn: offsetColumn + 1\n      },\n      consumer: new SourceMapConsumer(util.getArg(s, 'map'))\n    }\n  });\n}\n\nIndexedSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nIndexedSourceMapConsumer.prototype.constructor = SourceMapConsumer;\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nIndexedSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(IndexedSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    var sources = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      for (var j = 0; j < this._sections[i].consumer.sources.length; j++) {\n        sources.push(this._sections[i].consumer.sources[j]);\n      }\n    }\n    return sources;\n  }\n});\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nIndexedSourceMapConsumer.prototype.originalPositionFor =\n  function IndexedSourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    // Find the section containing the generated position we're trying to map\n    // to an original position.\n    var sectionIndex = binarySearch.search(needle, this._sections,\n      function(needle, section) {\n        var cmp = needle.generatedLine - section.generatedOffset.generatedLine;\n        if (cmp) {\n          return cmp;\n        }\n\n        return (needle.generatedColumn -\n                section.generatedOffset.generatedColumn);\n      });\n    var section = this._sections[sectionIndex];\n\n    if (!section) {\n      return {\n        source: null,\n        line: null,\n        column: null,\n        name: null\n      };\n    }\n\n    return section.consumer.originalPositionFor({\n      line: needle.generatedLine -\n        (section.generatedOffset.generatedLine - 1),\n      column: needle.generatedColumn -\n        (section.generatedOffset.generatedLine === needle.generatedLine\n         ? section.generatedOffset.generatedColumn - 1\n         : 0),\n      bias: aArgs.bias\n    });\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nIndexedSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function IndexedSourceMapConsumer_hasContentsOfAllSources() {\n    return this._sections.every(function (s) {\n      return s.consumer.hasContentsOfAllSources();\n    });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nIndexedSourceMapConsumer.prototype.sourceContentFor =\n  function IndexedSourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      var content = section.consumer.sourceContentFor(aSource, true);\n      if (content) {\n        return content;\n      }\n    }\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nIndexedSourceMapConsumer.prototype.generatedPositionFor =\n  function IndexedSourceMapConsumer_generatedPositionFor(aArgs) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      // Only consider this section if the requested source is in the list of\n      // sources of the consumer.\n      if (section.consumer.sources.indexOf(util.getArg(aArgs, 'source')) === -1) {\n        continue;\n      }\n      var generatedPosition = section.consumer.generatedPositionFor(aArgs);\n      if (generatedPosition) {\n        var ret = {\n          line: generatedPosition.line +\n            (section.generatedOffset.generatedLine - 1),\n          column: generatedPosition.column +\n            (section.generatedOffset.generatedLine === generatedPosition.line\n             ? section.generatedOffset.generatedColumn - 1\n             : 0)\n        };\n        return ret;\n      }\n    }\n\n    return {\n      line: null,\n      column: null\n    };\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nIndexedSourceMapConsumer.prototype._parseMappings =\n  function IndexedSourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    this.__generatedMappings = [];\n    this.__originalMappings = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n      var sectionMappings = section.consumer._generatedMappings;\n      for (var j = 0; j < sectionMappings.length; j++) {\n        var mapping = sectionMappings[j];\n\n        var source = section.consumer._sources.at(mapping.source);\n        if (section.consumer.sourceRoot !== null) {\n          source = util.join(section.consumer.sourceRoot, source);\n        }\n        this._sources.add(source);\n        source = this._sources.indexOf(source);\n\n        var name = section.consumer._names.at(mapping.name);\n        this._names.add(name);\n        name = this._names.indexOf(name);\n\n        // The mappings coming from the consumer for the section have\n        // generated positions relative to the start of the section, so we\n        // need to offset them to be relative to the start of the concatenated\n        // generated file.\n        var adjustedMapping = {\n          source: source,\n          generatedLine: mapping.generatedLine +\n            (section.generatedOffset.generatedLine - 1),\n          generatedColumn: mapping.generatedColumn +\n            (section.generatedOffset.generatedLine === mapping.generatedLine\n            ? section.generatedOffset.generatedColumn - 1\n            : 0),\n          originalLine: mapping.originalLine,\n          originalColumn: mapping.originalColumn,\n          name: name\n        };\n\n        this.__generatedMappings.push(adjustedMapping);\n        if (typeof adjustedMapping.originalLine === 'number') {\n          this.__originalMappings.push(adjustedMapping);\n        }\n      }\n    }\n\n    quickSort(this.__generatedMappings, util.compareByGeneratedPositionsDeflated);\n    quickSort(this.__originalMappings, util.compareByOriginalPositions);\n  };\n\nexports.IndexedSourceMapConsumer = IndexedSourceMapConsumer;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar base64VLQ = require('./base64-vlq');\nvar util = require('./util');\nvar ArraySet = require('./array-set').ArraySet;\nvar MappingList = require('./mapping-list').MappingList;\n\n/**\n * An instance of the SourceMapGenerator represents a source map which is\n * being built incrementally. You may pass an object with the following\n * properties:\n *\n *   - file: The filename of the generated source.\n *   - sourceRoot: A root for all relative URLs in this source map.\n */\nfunction SourceMapGenerator(aArgs) {\n  if (!aArgs) {\n    aArgs = {};\n  }\n  this._file = util.getArg(aArgs, 'file', null);\n  this._sourceRoot = util.getArg(aArgs, 'sourceRoot', null);\n  this._skipValidation = util.getArg(aArgs, 'skipValidation', false);\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n  this._mappings = new MappingList();\n  this._sourcesContents = null;\n}\n\nSourceMapGenerator.prototype._version = 3;\n\n/**\n * Creates a new SourceMapGenerator based on a SourceMapConsumer\n *\n * @param aSourceMapConsumer The SourceMap.\n */\nSourceMapGenerator.fromSourceMap =\n  function SourceMapGenerator_fromSourceMap(aSourceMapConsumer) {\n    var sourceRoot = aSourceMapConsumer.sourceRoot;\n    var generator = new SourceMapGenerator({\n      file: aSourceMapConsumer.file,\n      sourceRoot: sourceRoot\n    });\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      var newMapping = {\n        generated: {\n          line: mapping.generatedLine,\n          column: mapping.generatedColumn\n        }\n      };\n\n      if (mapping.source != null) {\n        newMapping.source = mapping.source;\n        if (sourceRoot != null) {\n          newMapping.source = util.relative(sourceRoot, newMapping.source);\n        }\n\n        newMapping.original = {\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        };\n\n        if (mapping.name != null) {\n          newMapping.name = mapping.name;\n        }\n      }\n\n      generator.addMapping(newMapping);\n    });\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        generator.setSourceContent(sourceFile, content);\n      }\n    });\n    return generator;\n  };\n\n/**\n * Add a single mapping from original source line and column to the generated\n * source's line and column for this source map being created. The mapping\n * object should have the following properties:\n *\n *   - generated: An object with the generated line and column positions.\n *   - original: An object with the original line and column positions.\n *   - source: The original source file (relative to the sourceRoot).\n *   - name: An optional original token name for this mapping.\n */\nSourceMapGenerator.prototype.addMapping =\n  function SourceMapGenerator_addMapping(aArgs) {\n    var generated = util.getArg(aArgs, 'generated');\n    var original = util.getArg(aArgs, 'original', null);\n    var source = util.getArg(aArgs, 'source', null);\n    var name = util.getArg(aArgs, 'name', null);\n\n    if (!this._skipValidation) {\n      this._validateMapping(generated, original, source, name);\n    }\n\n    if (source != null) {\n      source = String(source);\n      if (!this._sources.has(source)) {\n        this._sources.add(source);\n      }\n    }\n\n    if (name != null) {\n      name = String(name);\n      if (!this._names.has(name)) {\n        this._names.add(name);\n      }\n    }\n\n    this._mappings.add({\n      generatedLine: generated.line,\n      generatedColumn: generated.column,\n      originalLine: original != null && original.line,\n      originalColumn: original != null && original.column,\n      source: source,\n      name: name\n    });\n  };\n\n/**\n * Set the source content for a source file.\n */\nSourceMapGenerator.prototype.setSourceContent =\n  function SourceMapGenerator_setSourceContent(aSourceFile, aSourceContent) {\n    var source = aSourceFile;\n    if (this._sourceRoot != null) {\n      source = util.relative(this._sourceRoot, source);\n    }\n\n    if (aSourceContent != null) {\n      // Add the source content to the _sourcesContents map.\n      // Create a new _sourcesContents map if the property is null.\n      if (!this._sourcesContents) {\n        this._sourcesContents = Object.create(null);\n      }\n      this._sourcesContents[util.toSetString(source)] = aSourceContent;\n    } else if (this._sourcesContents) {\n      // Remove the source file from the _sourcesContents map.\n      // If the _sourcesContents map is empty, set the property to null.\n      delete this._sourcesContents[util.toSetString(source)];\n      if (Object.keys(this._sourcesContents).length === 0) {\n        this._sourcesContents = null;\n      }\n    }\n  };\n\n/**\n * Applies the mappings of a sub-source-map for a specific source file to the\n * source map being generated. Each mapping to the supplied source file is\n * rewritten using the supplied source map. Note: The resolution for the\n * resulting mappings is the minimium of this map and the supplied map.\n *\n * @param aSourceMapConsumer The source map to be applied.\n * @param aSourceFile Optional. The filename of the source file.\n *        If omitted, SourceMapConsumer's file property will be used.\n * @param aSourceMapPath Optional. The dirname of the path to the source map\n *        to be applied. If relative, it is relative to the SourceMapConsumer.\n *        This parameter is needed when the two source maps aren't in the same\n *        directory, and the source map to be applied contains relative source\n *        paths. If so, those relative source paths need to be rewritten\n *        relative to the SourceMapGenerator.\n */\nSourceMapGenerator.prototype.applySourceMap =\n  function SourceMapGenerator_applySourceMap(aSourceMapConsumer, aSourceFile, aSourceMapPath) {\n    var sourceFile = aSourceFile;\n    // If aSourceFile is omitted, we will use the file property of the SourceMap\n    if (aSourceFile == null) {\n      if (aSourceMapConsumer.file == null) {\n        throw new Error(\n          'SourceMapGenerator.prototype.applySourceMap requires either an explicit source file, ' +\n          'or the source map\\'s \"file\" property. Both were omitted.'\n        );\n      }\n      sourceFile = aSourceMapConsumer.file;\n    }\n    var sourceRoot = this._sourceRoot;\n    // Make \"sourceFile\" relative if an absolute Url is passed.\n    if (sourceRoot != null) {\n      sourceFile = util.relative(sourceRoot, sourceFile);\n    }\n    // Applying the SourceMap can add and remove items from the sources and\n    // the names array.\n    var newSources = new ArraySet();\n    var newNames = new ArraySet();\n\n    // Find mappings for the \"sourceFile\"\n    this._mappings.unsortedForEach(function (mapping) {\n      if (mapping.source === sourceFile && mapping.originalLine != null) {\n        // Check if it can be mapped by the source map, then update the mapping.\n        var original = aSourceMapConsumer.originalPositionFor({\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        });\n        if (original.source != null) {\n          // Copy mapping\n          mapping.source = original.source;\n          if (aSourceMapPath != null) {\n            mapping.source = util.join(aSourceMapPath, mapping.source)\n          }\n          if (sourceRoot != null) {\n            mapping.source = util.relative(sourceRoot, mapping.source);\n          }\n          mapping.originalLine = original.line;\n          mapping.originalColumn = original.column;\n          if (original.name != null) {\n            mapping.name = original.name;\n          }\n        }\n      }\n\n      var source = mapping.source;\n      if (source != null && !newSources.has(source)) {\n        newSources.add(source);\n      }\n\n      var name = mapping.name;\n      if (name != null && !newNames.has(name)) {\n        newNames.add(name);\n      }\n\n    }, this);\n    this._sources = newSources;\n    this._names = newNames;\n\n    // Copy sourcesContents of applied map.\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aSourceMapPath != null) {\n          sourceFile = util.join(aSourceMapPath, sourceFile);\n        }\n        if (sourceRoot != null) {\n          sourceFile = util.relative(sourceRoot, sourceFile);\n        }\n        this.setSourceContent(sourceFile, content);\n      }\n    }, this);\n  };\n\n/**\n * A mapping can have one of the three levels of data:\n *\n *   1. Just the generated position.\n *   2. The Generated position, original position, and original source.\n *   3. Generated and original position, original source, as well as a name\n *      token.\n *\n * To maintain consistency, we validate that any new mapping being added falls\n * in to one of these categories.\n */\nSourceMapGenerator.prototype._validateMapping =\n  function SourceMapGenerator_validateMapping(aGenerated, aOriginal, aSource,\n                                              aName) {\n    // When aOriginal is truthy but has empty values for .line and .column,\n    // it is most likely a programmer error. In this case we throw a very\n    // specific error message to try to guide them the right way.\n    // For example: https://github.com/Polymer/polymer-bundler/pull/519\n    if (aOriginal && typeof aOriginal.line !== 'number' && typeof aOriginal.column !== 'number') {\n        throw new Error(\n            'original.line and original.column are not numbers -- you probably meant to omit ' +\n            'the original mapping entirely and only map the generated position. If so, pass ' +\n            'null for the original mapping instead of an object with empty or null values.'\n        );\n    }\n\n    if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n        && aGenerated.line > 0 && aGenerated.column >= 0\n        && !aOriginal && !aSource && !aName) {\n      // Case 1.\n      return;\n    }\n    else if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n             && aOriginal && 'line' in aOriginal && 'column' in aOriginal\n             && aGenerated.line > 0 && aGenerated.column >= 0\n             && aOriginal.line > 0 && aOriginal.column >= 0\n             && aSource) {\n      // Cases 2 and 3.\n      return;\n    }\n    else {\n      throw new Error('Invalid mapping: ' + JSON.stringify({\n        generated: aGenerated,\n        source: aSource,\n        original: aOriginal,\n        name: aName\n      }));\n    }\n  };\n\n/**\n * Serialize the accumulated mappings in to the stream of base 64 VLQs\n * specified by the source map format.\n */\nSourceMapGenerator.prototype._serializeMappings =\n  function SourceMapGenerator_serializeMappings() {\n    var previousGeneratedColumn = 0;\n    var previousGeneratedLine = 1;\n    var previousOriginalColumn = 0;\n    var previousOriginalLine = 0;\n    var previousName = 0;\n    var previousSource = 0;\n    var result = '';\n    var next;\n    var mapping;\n    var nameIdx;\n    var sourceIdx;\n\n    var mappings = this._mappings.toArray();\n    for (var i = 0, len = mappings.length; i < len; i++) {\n      mapping = mappings[i];\n      next = ''\n\n      if (mapping.generatedLine !== previousGeneratedLine) {\n        previousGeneratedColumn = 0;\n        while (mapping.generatedLine !== previousGeneratedLine) {\n          next += ';';\n          previousGeneratedLine++;\n        }\n      }\n      else {\n        if (i > 0) {\n          if (!util.compareByGeneratedPositionsInflated(mapping, mappings[i - 1])) {\n            continue;\n          }\n          next += ',';\n        }\n      }\n\n      next += base64VLQ.encode(mapping.generatedColumn\n                                 - previousGeneratedColumn);\n      previousGeneratedColumn = mapping.generatedColumn;\n\n      if (mapping.source != null) {\n        sourceIdx = this._sources.indexOf(mapping.source);\n        next += base64VLQ.encode(sourceIdx - previousSource);\n        previousSource = sourceIdx;\n\n        // lines are stored 0-based in SourceMap spec version 3\n        next += base64VLQ.encode(mapping.originalLine - 1\n                                   - previousOriginalLine);\n        previousOriginalLine = mapping.originalLine - 1;\n\n        next += base64VLQ.encode(mapping.originalColumn\n                                   - previousOriginalColumn);\n        previousOriginalColumn = mapping.originalColumn;\n\n        if (mapping.name != null) {\n          nameIdx = this._names.indexOf(mapping.name);\n          next += base64VLQ.encode(nameIdx - previousName);\n          previousName = nameIdx;\n        }\n      }\n\n      result += next;\n    }\n\n    return result;\n  };\n\nSourceMapGenerator.prototype._generateSourcesContent =\n  function SourceMapGenerator_generateSourcesContent(aSources, aSourceRoot) {\n    return aSources.map(function (source) {\n      if (!this._sourcesContents) {\n        return null;\n      }\n      if (aSourceRoot != null) {\n        source = util.relative(aSourceRoot, source);\n      }\n      var key = util.toSetString(source);\n      return Object.prototype.hasOwnProperty.call(this._sourcesContents, key)\n        ? this._sourcesContents[key]\n        : null;\n    }, this);\n  };\n\n/**\n * Externalize the source map.\n */\nSourceMapGenerator.prototype.toJSON =\n  function SourceMapGenerator_toJSON() {\n    var map = {\n      version: this._version,\n      sources: this._sources.toArray(),\n      names: this._names.toArray(),\n      mappings: this._serializeMappings()\n    };\n    if (this._file != null) {\n      map.file = this._file;\n    }\n    if (this._sourceRoot != null) {\n      map.sourceRoot = this._sourceRoot;\n    }\n    if (this._sourcesContents) {\n      map.sourcesContent = this._generateSourcesContent(map.sources, map.sourceRoot);\n    }\n\n    return map;\n  };\n\n/**\n * Render the source map being generated to a string.\n */\nSourceMapGenerator.prototype.toString =\n  function SourceMapGenerator_toString() {\n    return JSON.stringify(this.toJSON());\n  };\n\nexports.SourceMapGenerator = SourceMapGenerator;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar SourceMapGenerator = require('./source-map-generator').SourceMapGenerator;\nvar util = require('./util');\n\n// Matches a Windows-style `\\r\\n` newline or a `\\n` newline used by all other\n// operating systems these days (capturing the result).\nvar REGEX_NEWLINE = /(\\r?\\n)/;\n\n// Newline character code for charCodeAt() comparisons\nvar NEWLINE_CODE = 10;\n\n// Private symbol for identifying `SourceNode`s when multiple versions of\n// the source-map library are loaded. This MUST NOT CHANGE across\n// versions!\nvar isSourceNode = \"$$$isSourceNode$$$\";\n\n/**\n * SourceNodes provide a way to abstract over interpolating/concatenating\n * snippets of generated JavaScript source code while maintaining the line and\n * column information associated with the original source code.\n *\n * @param aLine The original line number.\n * @param aColumn The original column number.\n * @param aSource The original source's filename.\n * @param aChunks Optional. An array of strings which are snippets of\n *        generated JS, or other SourceNodes.\n * @param aName The original identifier.\n */\nfunction SourceNode(aLine, aColumn, aSource, aChunks, aName) {\n  this.children = [];\n  this.sourceContents = {};\n  this.line = aLine == null ? null : aLine;\n  this.column = aColumn == null ? null : aColumn;\n  this.source = aSource == null ? null : aSource;\n  this.name = aName == null ? null : aName;\n  this[isSourceNode] = true;\n  if (aChunks != null) this.add(aChunks);\n}\n\n/**\n * Creates a SourceNode from generated code and a SourceMapConsumer.\n *\n * @param aGeneratedCode The generated code\n * @param aSourceMapConsumer The SourceMap for the generated code\n * @param aRelativePath Optional. The path that relative sources in the\n *        SourceMapConsumer should be relative to.\n */\nSourceNode.fromStringWithSourceMap =\n  function SourceNode_fromStringWithSourceMap(aGeneratedCode, aSourceMapConsumer, aRelativePath) {\n    // The SourceNode we want to fill with the generated code\n    // and the SourceMap\n    var node = new SourceNode();\n\n    // All even indices of this array are one line of the generated code,\n    // while all odd indices are the newlines between two adjacent lines\n    // (since `REGEX_NEWLINE` captures its match).\n    // Processed fragments are accessed by calling `shiftNextLine`.\n    var remainingLines = aGeneratedCode.split(REGEX_NEWLINE);\n    var remainingLinesIndex = 0;\n    var shiftNextLine = function() {\n      var lineContents = getNextLine();\n      // The last line of a file might not have a newline.\n      var newLine = getNextLine() || \"\";\n      return lineContents + newLine;\n\n      function getNextLine() {\n        return remainingLinesIndex < remainingLines.length ?\n            remainingLines[remainingLinesIndex++] : undefined;\n      }\n    };\n\n    // We need to remember the position of \"remainingLines\"\n    var lastGeneratedLine = 1, lastGeneratedColumn = 0;\n\n    // The generate SourceNodes we need a code range.\n    // To extract it current and last mapping is used.\n    // Here we store the last mapping.\n    var lastMapping = null;\n\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      if (lastMapping !== null) {\n        // We add the code from \"lastMapping\" to \"mapping\":\n        // First check if there is a new line in between.\n        if (lastGeneratedLine < mapping.generatedLine) {\n          // Associate first line with \"lastMapping\"\n          addMappingWithCode(lastMapping, shiftNextLine());\n          lastGeneratedLine++;\n          lastGeneratedColumn = 0;\n          // The remaining code is added without mapping\n        } else {\n          // There is no new line in between.\n          // Associate the code between \"lastGeneratedColumn\" and\n          // \"mapping.generatedColumn\" with \"lastMapping\"\n          var nextLine = remainingLines[remainingLinesIndex];\n          var code = nextLine.substr(0, mapping.generatedColumn -\n                                        lastGeneratedColumn);\n          remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn -\n                                              lastGeneratedColumn);\n          lastGeneratedColumn = mapping.generatedColumn;\n          addMappingWithCode(lastMapping, code);\n          // No more remaining code, continue\n          lastMapping = mapping;\n          return;\n        }\n      }\n      // We add the generated code until the first mapping\n      // to the SourceNode without any mapping.\n      // Each line is added as separate string.\n      while (lastGeneratedLine < mapping.generatedLine) {\n        node.add(shiftNextLine());\n        lastGeneratedLine++;\n      }\n      if (lastGeneratedColumn < mapping.generatedColumn) {\n        var nextLine = remainingLines[remainingLinesIndex];\n        node.add(nextLine.substr(0, mapping.generatedColumn));\n        remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn);\n        lastGeneratedColumn = mapping.generatedColumn;\n      }\n      lastMapping = mapping;\n    }, this);\n    // We have processed all mappings.\n    if (remainingLinesIndex < remainingLines.length) {\n      if (lastMapping) {\n        // Associate the remaining code in the current line with \"lastMapping\"\n        addMappingWithCode(lastMapping, shiftNextLine());\n      }\n      // and add the remaining lines without any mapping\n      node.add(remainingLines.splice(remainingLinesIndex).join(\"\"));\n    }\n\n    // Copy sourcesContent into SourceNode\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aRelativePath != null) {\n          sourceFile = util.join(aRelativePath, sourceFile);\n        }\n        node.setSourceContent(sourceFile, content);\n      }\n    });\n\n    return node;\n\n    function addMappingWithCode(mapping, code) {\n      if (mapping === null || mapping.source === undefined) {\n        node.add(code);\n      } else {\n        var source = aRelativePath\n          ? util.join(aRelativePath, mapping.source)\n          : mapping.source;\n        node.add(new SourceNode(mapping.originalLine,\n                                mapping.originalColumn,\n                                source,\n                                code,\n                                mapping.name));\n      }\n    }\n  };\n\n/**\n * Add a chunk of generated JS to this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.add = function SourceNode_add(aChunk) {\n  if (Array.isArray(aChunk)) {\n    aChunk.forEach(function (chunk) {\n      this.add(chunk);\n    }, this);\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    if (aChunk) {\n      this.children.push(aChunk);\n    }\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Add a chunk of generated JS to the beginning of this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.prepend = function SourceNode_prepend(aChunk) {\n  if (Array.isArray(aChunk)) {\n    for (var i = aChunk.length-1; i >= 0; i--) {\n      this.prepend(aChunk[i]);\n    }\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    this.children.unshift(aChunk);\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Walk over the tree of JS snippets in this node and its children. The\n * walking function is called once for each snippet of JS and is passed that\n * snippet and the its original associated source's line/column location.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walk = function SourceNode_walk(aFn) {\n  var chunk;\n  for (var i = 0, len = this.children.length; i < len; i++) {\n    chunk = this.children[i];\n    if (chunk[isSourceNode]) {\n      chunk.walk(aFn);\n    }\n    else {\n      if (chunk !== '') {\n        aFn(chunk, { source: this.source,\n                     line: this.line,\n                     column: this.column,\n                     name: this.name });\n      }\n    }\n  }\n};\n\n/**\n * Like `String.prototype.join` except for SourceNodes. Inserts `aStr` between\n * each of `this.children`.\n *\n * @param aSep The separator.\n */\nSourceNode.prototype.join = function SourceNode_join(aSep) {\n  var newChildren;\n  var i;\n  var len = this.children.length;\n  if (len > 0) {\n    newChildren = [];\n    for (i = 0; i < len-1; i++) {\n      newChildren.push(this.children[i]);\n      newChildren.push(aSep);\n    }\n    newChildren.push(this.children[i]);\n    this.children = newChildren;\n  }\n  return this;\n};\n\n/**\n * Call String.prototype.replace on the very right-most source snippet. Useful\n * for trimming whitespace from the end of a source node, etc.\n *\n * @param aPattern The pattern to replace.\n * @param aReplacement The thing to replace the pattern with.\n */\nSourceNode.prototype.replaceRight = function SourceNode_replaceRight(aPattern, aReplacement) {\n  var lastChild = this.children[this.children.length - 1];\n  if (lastChild[isSourceNode]) {\n    lastChild.replaceRight(aPattern, aReplacement);\n  }\n  else if (typeof lastChild === 'string') {\n    this.children[this.children.length - 1] = lastChild.replace(aPattern, aReplacement);\n  }\n  else {\n    this.children.push(''.replace(aPattern, aReplacement));\n  }\n  return this;\n};\n\n/**\n * Set the source content for a source file. This will be added to the SourceMapGenerator\n * in the sourcesContent field.\n *\n * @param aSourceFile The filename of the source file\n * @param aSourceContent The content of the source file\n */\nSourceNode.prototype.setSourceContent =\n  function SourceNode_setSourceContent(aSourceFile, aSourceContent) {\n    this.sourceContents[util.toSetString(aSourceFile)] = aSourceContent;\n  };\n\n/**\n * Walk over the tree of SourceNodes. The walking function is called for each\n * source file content and is passed the filename and source content.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walkSourceContents =\n  function SourceNode_walkSourceContents(aFn) {\n    for (var i = 0, len = this.children.length; i < len; i++) {\n      if (this.children[i][isSourceNode]) {\n        this.children[i].walkSourceContents(aFn);\n      }\n    }\n\n    var sources = Object.keys(this.sourceContents);\n    for (var i = 0, len = sources.length; i < len; i++) {\n      aFn(util.fromSetString(sources[i]), this.sourceContents[sources[i]]);\n    }\n  };\n\n/**\n * Return the string representation of this source node. Walks over the tree\n * and concatenates all the various snippets together to one string.\n */\nSourceNode.prototype.toString = function SourceNode_toString() {\n  var str = \"\";\n  this.walk(function (chunk) {\n    str += chunk;\n  });\n  return str;\n};\n\n/**\n * Returns the string representation of this source node along with a source\n * map.\n */\nSourceNode.prototype.toStringWithSourceMap = function SourceNode_toStringWithSourceMap(aArgs) {\n  var generated = {\n    code: \"\",\n    line: 1,\n    column: 0\n  };\n  var map = new SourceMapGenerator(aArgs);\n  var sourceMappingActive = false;\n  var lastOriginalSource = null;\n  var lastOriginalLine = null;\n  var lastOriginalColumn = null;\n  var lastOriginalName = null;\n  this.walk(function (chunk, original) {\n    generated.code += chunk;\n    if (original.source !== null\n        && original.line !== null\n        && original.column !== null) {\n      if(lastOriginalSource !== original.source\n         || lastOriginalLine !== original.line\n         || lastOriginalColumn !== original.column\n         || lastOriginalName !== original.name) {\n        map.addMapping({\n          source: original.source,\n          original: {\n            line: original.line,\n            column: original.column\n          },\n          generated: {\n            line: generated.line,\n            column: generated.column\n          },\n          name: original.name\n        });\n      }\n      lastOriginalSource = original.source;\n      lastOriginalLine = original.line;\n      lastOriginalColumn = original.column;\n      lastOriginalName = original.name;\n      sourceMappingActive = true;\n    } else if (sourceMappingActive) {\n      map.addMapping({\n        generated: {\n          line: generated.line,\n          column: generated.column\n        }\n      });\n      lastOriginalSource = null;\n      sourceMappingActive = false;\n    }\n    for (var idx = 0, length = chunk.length; idx < length; idx++) {\n      if (chunk.charCodeAt(idx) === NEWLINE_CODE) {\n        generated.line++;\n        generated.column = 0;\n        // Mappings end at eol\n        if (idx + 1 === length) {\n          lastOriginalSource = null;\n          sourceMappingActive = false;\n        } else if (sourceMappingActive) {\n          map.addMapping({\n            source: original.source,\n            original: {\n              line: original.line,\n              column: original.column\n            },\n            generated: {\n              line: generated.line,\n              column: generated.column\n            },\n            name: original.name\n          });\n        }\n      } else {\n        generated.column++;\n      }\n    }\n  });\n  this.walkSourceContents(function (sourceFile, sourceContent) {\n    map.setSourceContent(sourceFile, sourceContent);\n  });\n\n  return { code: generated.code, map: map };\n};\n\nexports.SourceNode = SourceNode;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * This is a helper function for getting values from parameter/options\n * objects.\n *\n * @param args The object we are extracting values from\n * @param name The name of the property we are getting.\n * @param defaultValue An optional value to return if the property is missing\n * from the object. If this is not specified and the property is missing, an\n * error will be thrown.\n */\nfunction getArg(aArgs, aName, aDefaultValue) {\n  if (aName in aArgs) {\n    return aArgs[aName];\n  } else if (arguments.length === 3) {\n    return aDefaultValue;\n  } else {\n    throw new Error('\"' + aName + '\" is a required argument.');\n  }\n}\nexports.getArg = getArg;\n\nvar urlRegexp = /^(?:([\\w+\\-.]+):)?\\/\\/(?:(\\w+:\\w+)@)?([\\w.]*)(?::(\\d+))?(\\S*)$/;\nvar dataUrlRegexp = /^data:.+\\,.+$/;\n\nfunction urlParse(aUrl) {\n  var match = aUrl.match(urlRegexp);\n  if (!match) {\n    return null;\n  }\n  return {\n    scheme: match[1],\n    auth: match[2],\n    host: match[3],\n    port: match[4],\n    path: match[5]\n  };\n}\nexports.urlParse = urlParse;\n\nfunction urlGenerate(aParsedUrl) {\n  var url = '';\n  if (aParsedUrl.scheme) {\n    url += aParsedUrl.scheme + ':';\n  }\n  url += '//';\n  if (aParsedUrl.auth) {\n    url += aParsedUrl.auth + '@';\n  }\n  if (aParsedUrl.host) {\n    url += aParsedUrl.host;\n  }\n  if (aParsedUrl.port) {\n    url += \":\" + aParsedUrl.port\n  }\n  if (aParsedUrl.path) {\n    url += aParsedUrl.path;\n  }\n  return url;\n}\nexports.urlGenerate = urlGenerate;\n\n/**\n * Normalizes a path, or the path portion of a URL:\n *\n * - Replaces consecutive slashes with one slash.\n * - Removes unnecessary '.' parts.\n * - Removes unnecessary '<dir>/..' parts.\n *\n * Based on code in the Node.js 'path' core module.\n *\n * @param aPath The path or url to normalize.\n */\nfunction normalize(aPath) {\n  var path = aPath;\n  var url = urlParse(aPath);\n  if (url) {\n    if (!url.path) {\n      return aPath;\n    }\n    path = url.path;\n  }\n  var isAbsolute = exports.isAbsolute(path);\n\n  var parts = path.split(/\\/+/);\n  for (var part, up = 0, i = parts.length - 1; i >= 0; i--) {\n    part = parts[i];\n    if (part === '.') {\n      parts.splice(i, 1);\n    } else if (part === '..') {\n      up++;\n    } else if (up > 0) {\n      if (part === '') {\n        // The first part is blank if the path is absolute. Trying to go\n        // above the root is a no-op. Therefore we can remove all '..' parts\n        // directly after the root.\n        parts.splice(i + 1, up);\n        up = 0;\n      } else {\n        parts.splice(i, 2);\n        up--;\n      }\n    }\n  }\n  path = parts.join('/');\n\n  if (path === '') {\n    path = isAbsolute ? '/' : '.';\n  }\n\n  if (url) {\n    url.path = path;\n    return urlGenerate(url);\n  }\n  return path;\n}\nexports.normalize = normalize;\n\n/**\n * Joins two paths/URLs.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be joined with the root.\n *\n * - If aPath is a URL or a data URI, aPath is returned, unless aPath is a\n *   scheme-relative URL: Then the scheme of aRoot, if any, is prepended\n *   first.\n * - Otherwise aPath is a path. If aRoot is a URL, then its path portion\n *   is updated with the result and aRoot is returned. Otherwise the result\n *   is returned.\n *   - If aPath is absolute, the result is aPath.\n *   - Otherwise the two paths are joined with a slash.\n * - Joining for example 'http://' and 'www.example.com' is also supported.\n */\nfunction join(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n  if (aPath === \"\") {\n    aPath = \".\";\n  }\n  var aPathUrl = urlParse(aPath);\n  var aRootUrl = urlParse(aRoot);\n  if (aRootUrl) {\n    aRoot = aRootUrl.path || '/';\n  }\n\n  // `join(foo, '//www.example.org')`\n  if (aPathUrl && !aPathUrl.scheme) {\n    if (aRootUrl) {\n      aPathUrl.scheme = aRootUrl.scheme;\n    }\n    return urlGenerate(aPathUrl);\n  }\n\n  if (aPathUrl || aPath.match(dataUrlRegexp)) {\n    return aPath;\n  }\n\n  // `join('http://', 'www.example.com')`\n  if (aRootUrl && !aRootUrl.host && !aRootUrl.path) {\n    aRootUrl.host = aPath;\n    return urlGenerate(aRootUrl);\n  }\n\n  var joined = aPath.charAt(0) === '/'\n    ? aPath\n    : normalize(aRoot.replace(/\\/+$/, '') + '/' + aPath);\n\n  if (aRootUrl) {\n    aRootUrl.path = joined;\n    return urlGenerate(aRootUrl);\n  }\n  return joined;\n}\nexports.join = join;\n\nexports.isAbsolute = function (aPath) {\n  return aPath.charAt(0) === '/' || !!aPath.match(urlRegexp);\n};\n\n/**\n * Make a path relative to a URL or another path.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be made relative to aRoot.\n */\nfunction relative(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n\n  aRoot = aRoot.replace(/\\/$/, '');\n\n  // It is possible for the path to be above the root. In this case, simply\n  // checking whether the root is a prefix of the path won't work. Instead, we\n  // need to remove components from the root one by one, until either we find\n  // a prefix that fits, or we run out of components to remove.\n  var level = 0;\n  while (aPath.indexOf(aRoot + '/') !== 0) {\n    var index = aRoot.lastIndexOf(\"/\");\n    if (index < 0) {\n      return aPath;\n    }\n\n    // If the only part of the root that is left is the scheme (i.e. http://,\n    // file:///, etc.), one or more slashes (/), or simply nothing at all, we\n    // have exhausted all components, so the path is not relative to the root.\n    aRoot = aRoot.slice(0, index);\n    if (aRoot.match(/^([^\\/]+:\\/)?\\/*$/)) {\n      return aPath;\n    }\n\n    ++level;\n  }\n\n  // Make sure we add a \"../\" for each component we removed from the root.\n  return Array(level + 1).join(\"../\") + aPath.substr(aRoot.length + 1);\n}\nexports.relative = relative;\n\nvar supportsNullProto = (function () {\n  var obj = Object.create(null);\n  return !('__proto__' in obj);\n}());\n\nfunction identity (s) {\n  return s;\n}\n\n/**\n * Because behavior goes wacky when you set `__proto__` on objects, we\n * have to prefix all the strings in our set with an arbitrary character.\n *\n * See https://github.com/mozilla/source-map/pull/31 and\n * https://github.com/mozilla/source-map/issues/30\n *\n * @param String aStr\n */\nfunction toSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return '$' + aStr;\n  }\n\n  return aStr;\n}\nexports.toSetString = supportsNullProto ? identity : toSetString;\n\nfunction fromSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return aStr.slice(1);\n  }\n\n  return aStr;\n}\nexports.fromSetString = supportsNullProto ? identity : fromSetString;\n\nfunction isProtoString(s) {\n  if (!s) {\n    return false;\n  }\n\n  var length = s.length;\n\n  if (length < 9 /* \"__proto__\".length */) {\n    return false;\n  }\n\n  if (s.charCodeAt(length - 1) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 2) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 3) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 4) !== 116 /* 't' */ ||\n      s.charCodeAt(length - 5) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 6) !== 114 /* 'r' */ ||\n      s.charCodeAt(length - 7) !== 112 /* 'p' */ ||\n      s.charCodeAt(length - 8) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 9) !== 95  /* '_' */) {\n    return false;\n  }\n\n  for (var i = length - 10; i >= 0; i--) {\n    if (s.charCodeAt(i) !== 36 /* '$' */) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Comparator between two mappings where the original positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same original source/line/column, but different generated\n * line and column the same. Useful when searching for a mapping with a\n * stubbed out mapping.\n */\nfunction compareByOriginalPositions(mappingA, mappingB, onlyCompareOriginal) {\n  var cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0 || onlyCompareOriginal) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByOriginalPositions = compareByOriginalPositions;\n\n/**\n * Comparator between two mappings with deflated source and name indices where\n * the generated positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same generated line and column, but different\n * source/name/original line and column the same. Useful when searching for a\n * mapping with a stubbed out mapping.\n */\nfunction compareByGeneratedPositionsDeflated(mappingA, mappingB, onlyCompareGenerated) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0 || onlyCompareGenerated) {\n    return cmp;\n  }\n\n  cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByGeneratedPositionsDeflated = compareByGeneratedPositionsDeflated;\n\nfunction strcmp(aStr1, aStr2) {\n  if (aStr1 === aStr2) {\n    return 0;\n  }\n\n  if (aStr1 > aStr2) {\n    return 1;\n  }\n\n  return -1;\n}\n\n/**\n * Comparator between two mappings with inflated source and name strings where\n * the generated positions are compared.\n */\nfunction compareByGeneratedPositionsInflated(mappingA, mappingB) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsInflated = compareByGeneratedPositionsInflated;\n","\n\"use strict\";\n\nvar algorithm = require('./lib/algorithm');\nvar Hash = require('./lib/Hash');\nvar register = require('./lib/register');\n\nexports.sum = algorithm.sum.bind(algorithm);\nexports.roll = algorithm.roll.bind(algorithm);\nexports.Hash = Hash;\nexports.register = register;\n","\nconst ArchiveConfigurator = require(\"./lib/ArchiveConfigurator\");\nconst createFolderBrickStorage = require(\"./lib/FolderBrickStorage\").createFolderBrickStorage;\nconst createFileBrickStorage = require(\"./lib/FileBrickStorage\").createFileBrickStorage;\n\nArchiveConfigurator.prototype.registerStorageProvider(\"FolderBrickStorage\", createFolderBrickStorage);\nArchiveConfigurator.prototype.registerStorageProvider(\"FileBrickStorage\", createFileBrickStorage);\n\nmodule.exports.ArchiveConfigurator = ArchiveConfigurator;\nmodule.exports.Brick = require(\"./lib/Brick\");\nmodule.exports.Archive = require(\"./lib/Archive\");\nmodule.exports.FolderBarMap = require(\"./lib/FolderBarMap\");\nmodule.exports.createFolderBrickStorage = createFolderBrickStorage;\nmodule.exports.createFileBrickStorage = createFileBrickStorage;\n","___DISABLE_OBSOLETE_ZIP_ARCHIVER_WAIT_FOR_BARS = true;\n//require(\"../../../psknode/bundles/pskruntime.js\");\nvar callflowModule = require(\"callflow\");\nvar pskcrypto = require(\"pskcrypto\");\n\n/*\n    class for Command or Result transactions\n */\nfunction CRTransaction(swarmType, command, input, output, currentPulse) {\n    this.swarmType = swarmType;\n\n    if(input && output){\n        this.input      = input;\n        this.output     = output;\n    }\n    this.command      = command;\n\n    let arr = process.hrtime();\n    this.second     = arr[0];\n    this.nanosecod  = arr[1];\n    this.transactionPulse = currentPulse;\n    this.digest     = pskcrypto.hashValues(this);\n}\n\n\nlet assetUtils = require(\"./blockchainSwarmTypes/asset_swarm_template\");\nlet transactionUtils = require(\"./blockchainSwarmTypes/transaction_swarm_template\");\n$$.assets           = callflowModule.createSwarmEngine(\"asset\", assetUtils);\n$$.asset            = $$.assets;\n$$.transactions     = callflowModule.createSwarmEngine(\"transaction\", transactionUtils);\n$$.transaction      = $$.transactions;\n\nlet pskcrypt = require(\"pskcrypto\");\n\n\nmodule.exports = {\n    createBlockchain:function(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution, forcedBoot){\n        return require(\"./pskdb\").startDefaultDB(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution, forcedBoot);\n    },\n    createABlockchain:function(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution, forcedBoot){\n        return require(\"./pskdb\").startDB(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, loadDefaultConstitution, forcedBoot);\n    },\n    createHistoryStorage:function(storageType,...args){\n        return require(\"./strategies/historyStorages/historyStoragesRegistry\").createStorage(storageType,...args);\n    },\n    createWorldStateCache:function(storageType,...args){\n        return require(\"./strategies/worldStateCaches/worldStateCacheRegistry\").createCache(storageType,...args);\n    },\n    createConsensusAlgorithm:function(name,...args){\n        return require(\"./strategies/consensusAlgortims/consensusAlgoritmsRegistry\").createAlgorithm(name,...args);\n    },\n    createCRTransaction:function (swarmType, command, input, output, currentPulse) {\n        return new CRTransaction(swarmType, command, input, output, currentPulse);\n    },\n     createBlock:function (blockset, pulse, previous) {\n        var block = {blockset, pulse, previous};\n        block.hash = pskcrypt.hashValues(block);\n        return block;\n\n    },\n    createSignatureProvider:function(name,...args){\n        return require(\"./strategies/signatureProvidersRegistry/signatureProvidersRegistry\").createSignatureProvider(name,...args);\n    },\n    createNetworkCommunicationStrategy:function(name,...args){\n        return require(\"./strategies/networkCommunication/networkCommunicationStrategiesRegistry\").createNetworkAdapter(name,...args);\n    },\n    createVotingStrategy:function(name,...args){\n        return require(\"./strategies/votingStrategies/votingStrategiesRegistry\").createVotingStrategy(name,...args);\n    }\n}\n\n","var Buffer = require('buffer').Buffer;\n\nvar CRC_TABLE = [\n  0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419,\n  0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4,\n  0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07,\n  0x90bf1d91, 0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de,\n  0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856,\n  0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,\n  0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4,\n  0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n  0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3,\n  0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a,\n  0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599,\n  0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,\n  0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190,\n  0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f,\n  0x9fbfe4a5, 0xe8b8d433, 0x7807c9a2, 0x0f00f934, 0x9609a88e,\n  0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n  0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed,\n  0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,\n  0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3,\n  0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2,\n  0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a,\n  0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5,\n  0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010,\n  0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n  0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17,\n  0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6,\n  0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615,\n  0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8,\n  0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1, 0xf00f9344,\n  0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,\n  0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a,\n  0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n  0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1,\n  0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c,\n  0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef,\n  0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,\n  0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe,\n  0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31,\n  0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c,\n  0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n  0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b,\n  0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,\n  0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1,\n  0x18b74777, 0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c,\n  0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278,\n  0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7,\n  0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc, 0x40df0b66,\n  0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n  0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605,\n  0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8,\n  0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b,\n  0x2d02ef8d\n];\n\nif (typeof Int32Array !== 'undefined') {\n  CRC_TABLE = new Int32Array(CRC_TABLE);\n}\n\nfunction newEmptyBuffer(length) {\n  var buffer = new Buffer(length);\n  buffer.fill(0x00);\n  return buffer;\n}\n\nfunction ensureBuffer(input) {\n  if (Buffer.isBuffer(input)) {\n    return input;\n  }\n\n  var hasNewBufferAPI =\n      typeof Buffer.alloc === \"function\" &&\n      typeof Buffer.from === \"function\";\n\n  if (typeof input === \"number\") {\n    return hasNewBufferAPI ? Buffer.alloc(input) : newEmptyBuffer(input);\n  }\n  else if (typeof input === \"string\") {\n    return hasNewBufferAPI ? Buffer.from(input) : new Buffer(input);\n  }\n  else {\n    throw new Error(\"input must be buffer, number, or string, received \" +\n                    typeof input);\n  }\n}\n\nfunction bufferizeInt(num) {\n  var tmp = ensureBuffer(4);\n  tmp.writeInt32BE(num, 0);\n  return tmp;\n}\n\nfunction _crc32(buf, previous) {\n  buf = ensureBuffer(buf);\n  if (Buffer.isBuffer(previous)) {\n    previous = previous.readUInt32BE(0);\n  }\n  var crc = ~~previous ^ -1;\n  for (var n = 0; n < buf.length; n++) {\n    crc = CRC_TABLE[(crc ^ buf[n]) & 0xff] ^ (crc >>> 8);\n  }\n  return (crc ^ -1);\n}\n\nfunction crc32() {\n  return bufferizeInt(_crc32.apply(null, arguments));\n}\ncrc32.signed = function () {\n  return _crc32.apply(null, arguments);\n};\ncrc32.unsigned = function () {\n  return _crc32.apply(null, arguments) >>> 0;\n};\n\nmodule.exports = crc32;\n","var toString = Object.prototype.toString\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction isArrayBuffer (input) {\n  return toString.call(input).slice(8, -1) === 'ArrayBuffer'\n}\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n","module.exports.RawCSB = require('./lib/RawCSB');\n// $$.loadLibrary(\"csb\", require(\"./flows/index\"));\n\n\n\n\n","const createEDFSBrickStorage = require(\"./EDFSBrickStorage\").createEDFSBrickStorage;\nmodule.exports.createEDFSBrickStorage = createEDFSBrickStorage;\n","module.exports.getEDFSMiddleware = () => require(\"./lib/EDFSMiddleware\");\nmodule.exports.createEDFSClient = (url) => {\n    const EDFSClient = require(\"./lib/EDFSClient\");\n    return new EDFSClient(url);\n};\n\n","module.exports = {\n\t\t\t\t\tcreateQue: require(\"./lib/folderMQ\").getFolderQueue\n\t\t\t\t\t//folderMQ: require(\"./lib/folderMQ\")\n};","/*\nModule that offers APIs to interact with PrivateSky web sandboxes\n */\n\n\nconst exportBrowserInteract = {\n    enableIframeInteractions: function () {\n        module.exports.createWindowMQ = require(\"./lib/interactionSpaceImpl/specificMQImpl/ChildWndMQ\").createMQ;\n        module.exports.createWindowInteractionSpace = require(\"./lib/interactionSpaceImpl/WindowMQInteractionSpace\").createInteractionSpace;\n    },\n    enableReactInteractions: function () {\n        module.exports.createWindowMQ = require(\"./lib/interactionSpaceImpl/specificMQImpl/ChildWndMQ\").createMQ;\n        module.exports.createWindowInteractionSpace = require(\"./lib/interactionSpaceImpl/WindowMQInteractionSpace\").createInteractionSpace;\n    },\n    enableWebViewInteractions:function(){\n        module.exports.createWindowInteractionSpace = require(\"./lib/interactionSpaceImpl/WebViewMQInteractionSpace\").createInteractionSpace;\n        module.exports.createWindowMQ = require(\"./lib/interactionSpaceImpl/specificMQImpl/ChildWebViewMQ\").createMQ;\n    },\n    enableLocalInteractions: function () {\n        module.exports.createInteractionSpace = require(\"./lib/interactionSpaceImpl/SoundPubSubMQBasedInteractionSpace\").createInteractionSpace;\n    },\n    enableRemoteInteractions: function () {\n        module.exports.createRemoteInteractionSpace = require('./lib/interactionSpaceImpl/httpInteractionSpace').createInteractionSpace;\n    }\n};\n\n\nif (typeof navigator !== \"undefined\") {\n    module.exports = exportBrowserInteract;\n}\nelse {\n    module.exports = {\n        createNodeInteractionSpace: require(\"./lib/interactionSpaceImpl/folderMQBasedInteractionSpace\").createInteractionSpace,\n        createInteractionSpace: require(\"./lib/interactionSpaceImpl/SoundPubSubMQBasedInteractionSpace\").createInteractionSpace,\n        createRemoteInteractionSpace: require('./lib/interactionSpaceImpl/httpInteractionSpace').createInteractionSpace\n    };\n}","var fs = require('fs');\nvar util = require('util');\nvar stream = require('stream');\nvar Readable = stream.Readable;\nvar Writable = stream.Writable;\nvar PassThrough = stream.PassThrough;\nvar Pend = require('./modules/node-pend');\nvar EventEmitter = require('events').EventEmitter;\n\nexports.createFromBuffer = createFromBuffer;\nexports.createFromFd = createFromFd;\nexports.BufferSlicer = BufferSlicer;\nexports.FdSlicer = FdSlicer;\n\nutil.inherits(FdSlicer, EventEmitter);\nfunction FdSlicer(fd, options) {\n  options = options || {};\n  EventEmitter.call(this);\n\n  this.fd = fd;\n  this.pend = new Pend();\n  this.pend.max = 1;\n  this.refCount = 0;\n  this.autoClose = !!options.autoClose;\n}\n\nFdSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.read(self.fd, buffer, offset, length, position, function(err, bytesRead, buffer) {\n      cb();\n      callback(err, bytesRead, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.write(self.fd, buffer, offset, length, position, function(err, written, buffer) {\n      cb();\n      callback(err, written, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.createReadStream = function(options) {\n  return new ReadStream(this, options);\n};\n\nFdSlicer.prototype.createWriteStream = function(options) {\n  return new WriteStream(this, options);\n};\n\nFdSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nFdSlicer.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  if (self.autoClose) {\n    fs.close(self.fd, onCloseDone);\n  }\n\n  function onCloseDone(err) {\n    if (err) {\n      self.emit('error', err);\n    } else {\n      self.emit('close');\n    }\n  }\n};\n\nutil.inherits(ReadStream, Readable);\nfunction ReadStream(context, options) {\n  options = options || {};\n  Readable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = options.end;\n  this.pos = this.start;\n  this.destroyed = false;\n}\n\nReadStream.prototype._read = function(n) {\n  var self = this;\n  if (self.destroyed) return;\n\n  var toRead = Math.min(self._readableState.highWaterMark, n);\n  if (self.endOffset != null) {\n    toRead = Math.min(toRead, self.endOffset - self.pos);\n  }\n  if (toRead <= 0) {\n    self.destroyed = true;\n    self.push(null);\n    self.context.unref();\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    var buffer = new Buffer(toRead);\n    fs.read(self.context.fd, buffer, 0, toRead, self.pos, function(err, bytesRead) {\n      if (err) {\n        self.destroy(err);\n      } else if (bytesRead === 0) {\n        self.destroyed = true;\n        self.push(null);\n        self.context.unref();\n      } else {\n        self.pos += bytesRead;\n        self.push(buffer.slice(0, bytesRead));\n      }\n      cb();\n    });\n  });\n};\n\nReadStream.prototype.destroy = function(err) {\n  if (this.destroyed) return;\n  err = err || new Error(\"stream destroyed\");\n  this.destroyed = true;\n  this.emit('error', err);\n  this.context.unref();\n};\n\nutil.inherits(WriteStream, Writable);\nfunction WriteStream(context, options) {\n  options = options || {};\n  Writable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = (options.end == null) ? Infinity : +options.end;\n  this.bytesWritten = 0;\n  this.pos = this.start;\n  this.destroyed = false;\n\n  this.on('finish', this.destroy.bind(this));\n}\n\nWriteStream.prototype._write = function(buffer, encoding, callback) {\n  var self = this;\n  if (self.destroyed) return;\n\n  if (self.pos + buffer.length > self.endOffset) {\n    var err = new Error(\"maximum file length exceeded\");\n    err.code = 'ETOOBIG';\n    self.destroy();\n    callback(err);\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    fs.write(self.context.fd, buffer, 0, buffer.length, self.pos, function(err, bytes) {\n      if (err) {\n        self.destroy();\n        cb();\n        callback(err);\n      } else {\n        self.bytesWritten += bytes;\n        self.pos += bytes;\n        self.emit('progress');\n        cb();\n        callback();\n      }\n    });\n  });\n};\n\nWriteStream.prototype.destroy = function() {\n  if (this.destroyed) return;\n  this.destroyed = true;\n  this.context.unref();\n};\n\nutil.inherits(BufferSlicer, EventEmitter);\nfunction BufferSlicer(buffer, options) {\n  EventEmitter.call(this);\n\n  options = options || {};\n  this.refCount = 0;\n  this.buffer = buffer;\n  this.maxChunkSize = options.maxChunkSize || Number.MAX_SAFE_INTEGER;\n}\n\nBufferSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var end = position + length;\n  var delta = end - this.buffer.length;\n  var written = (delta > 0) ? delta : length;\n  this.buffer.copy(buffer, offset, position, end);\n  setImmediate(function() {\n    callback(null, written);\n  });\n};\n\nBufferSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  buffer.copy(this.buffer, position, offset, offset + length);\n  setImmediate(function() {\n    callback(null, length, buffer);\n  });\n};\n\nBufferSlicer.prototype.createReadStream = function(options) {\n  options = options || {};\n  var readStream = new PassThrough(options);\n  readStream.destroyed = false;\n  readStream.start = options.start || 0;\n  readStream.endOffset = options.end;\n  // by the time this function returns, we'll be done.\n  readStream.pos = readStream.endOffset || this.buffer.length;\n\n  // respect the maxChunkSize option to slice up the chunk into smaller pieces.\n  var entireSlice = this.buffer.slice(readStream.start, readStream.pos);\n  var offset = 0;\n  while (true) {\n    var nextOffset = offset + this.maxChunkSize;\n    if (nextOffset >= entireSlice.length) {\n      // last chunk\n      if (offset < entireSlice.length) {\n        readStream.write(entireSlice.slice(offset, entireSlice.length));\n      }\n      break;\n    }\n    readStream.write(entireSlice.slice(offset, nextOffset));\n    offset = nextOffset;\n  }\n\n  readStream.end();\n  readStream.destroy = function() {\n    readStream.destroyed = true;\n  };\n  return readStream;\n};\n\nBufferSlicer.prototype.createWriteStream = function(options) {\n  var bufferSlicer = this;\n  options = options || {};\n  var writeStream = new Writable(options);\n  writeStream.start = options.start || 0;\n  writeStream.endOffset = (options.end == null) ? this.buffer.length : +options.end;\n  writeStream.bytesWritten = 0;\n  writeStream.pos = writeStream.start;\n  writeStream.destroyed = false;\n  writeStream._write = function(buffer, encoding, callback) {\n    if (writeStream.destroyed) return;\n\n    var end = writeStream.pos + buffer.length;\n    if (end > writeStream.endOffset) {\n      var err = new Error(\"maximum file length exceeded\");\n      err.code = 'ETOOBIG';\n      writeStream.destroyed = true;\n      callback(err);\n      return;\n    }\n    buffer.copy(bufferSlicer.buffer, writeStream.pos, 0, buffer.length);\n\n    writeStream.bytesWritten += buffer.length;\n    writeStream.pos = end;\n    writeStream.emit('progress');\n    callback();\n  };\n  writeStream.destroy = function() {\n    writeStream.destroyed = true;\n  };\n  return writeStream;\n};\n\nBufferSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nBufferSlicer.prototype.unref = function() {\n  this.refCount -= 1;\n\n  if (this.refCount < 0) {\n    throw new Error(\"invalid unref\");\n  }\n};\n\nfunction createFromBuffer(buffer, options) {\n  return new BufferSlicer(buffer, options);\n}\n\nfunction createFromFd(fd, options) {\n  return new FdSlicer(fd, options);\n}\n","//to look nice the requireModule on Node\nrequire(\"./lib/psk-abstract-client\");\nif(!$$.browserRuntime){\n\trequire(\"./lib/psk-node-client\");\n}else{\n\trequire(\"./lib/psk-browser-client\");\n}","module.exports.utils  = require(\"./utils/flowsUtils\");\nconst RootCSB = require('./libraries/RootCSB');\nmodule.exports.createRootCSB = RootCSB.createRootCSB;\nmodule.exports.loadWithIdentifier = RootCSB.loadWithIdentifier;\nmodule.exports.loadWithPin   = RootCSB.loadWithPin;\nmodule.exports.writeNewMasterCSB = RootCSB.writeNewMasterCSB;\nmodule.exports.RootCSB = RootCSB;\nmodule.exports.RawCSB = require('./libraries/RawCSB');\nmodule.exports.CSBIdentifier = require('./libraries/CSBIdentifier');\nmodule.exports.init = function () {\n\t$$.loadLibrary(\"pskwallet\", require(\"./libraries/flows/index\"));\n};\n\n","var SourceMapConsumer = require('source-map').SourceMapConsumer;\nvar path = require('path');\n\nvar fs;\ntry {\n  fs = require('fs');\n  if (!fs.existsSync || !fs.readFileSync) {\n    // fs doesn't have all methods we need\n    fs = null;\n  }\n} catch (err) {\n  /* nop */\n}\n\nvar bufferFrom = require('buffer-from');\n\n// Only install once if called multiple times\nvar errorFormatterInstalled = false;\nvar uncaughtShimInstalled = false;\n\n// If true, the caches are reset before a stack trace formatting operation\nvar emptyCacheBetweenOperations = false;\n\n// Supports {browser, node, auto}\nvar environment = \"auto\";\n\n// Maps a file path to a string containing the file contents\nvar fileContentsCache = {};\n\n// Maps a file path to a source map for that file\nvar sourceMapCache = {};\n\n// Regex for detecting source maps\nvar reSourceMap = /^data:application\\/json[^,]+base64,/;\n\n// Priority list of retrieve handlers\nvar retrieveFileHandlers = [];\nvar retrieveMapHandlers = [];\n\nfunction isInBrowser() {\n  if (environment === \"browser\")\n    return true;\n  if (environment === \"node\")\n    return false;\n  return ((typeof window !== 'undefined') && (typeof XMLHttpRequest === 'function') && !(window.require && window.module && window.process && window.process.type === \"renderer\"));\n}\n\nfunction hasGlobalProcessEventEmitter() {\n  return ((typeof process === 'object') && (process !== null) && (typeof process.on === 'function'));\n}\n\nfunction handlerExec(list) {\n  return function(arg) {\n    for (var i = 0; i < list.length; i++) {\n      var ret = list[i](arg);\n      if (ret) {\n        return ret;\n      }\n    }\n    return null;\n  };\n}\n\nvar retrieveFile = handlerExec(retrieveFileHandlers);\n\nretrieveFileHandlers.push(function(path) {\n  // Trim the path to make sure there is no extra whitespace.\n  path = path.trim();\n  if (/^file:/.test(path)) {\n    // existsSync/readFileSync can't handle file protocol, but once stripped, it works\n    path = path.replace(/file:\\/\\/\\/(\\w:)?/, function(protocol, drive) {\n      return drive ?\n        '' : // file:///C:/dir/file -> C:/dir/file\n        '/'; // file:///root-dir/file -> /root-dir/file\n    });\n  }\n  if (path in fileContentsCache) {\n    return fileContentsCache[path];\n  }\n\n  var contents = '';\n  try {\n    if (!fs) {\n      // Use SJAX if we are in the browser\n      var xhr = new XMLHttpRequest();\n      xhr.open('GET', path, /** async */ false);\n      xhr.send(null);\n      if (xhr.readyState === 4 && xhr.status === 200) {\n        contents = xhr.responseText;\n      }\n    } else if (fs.existsSync(path)) {\n      // Otherwise, use the filesystem\n      contents = fs.readFileSync(path, 'utf8');\n    }\n  } catch (er) {\n    /* ignore any errors */\n  }\n\n  return fileContentsCache[path] = contents;\n});\n\n// Support URLs relative to a directory, but be careful about a protocol prefix\n// in case we are in the browser (i.e. directories may start with \"http://\" or \"file:///\")\nfunction supportRelativeURL(file, url) {\n  if (!file) return url;\n  var dir = path.dirname(file);\n  var match = /^\\w+:\\/\\/[^\\/]*/.exec(dir);\n  var protocol = match ? match[0] : '';\n  var startPath = dir.slice(protocol.length);\n  if (protocol && /^\\/\\w\\:/.test(startPath)) {\n    // handle file:///C:/ paths\n    protocol += '/';\n    return protocol + path.resolve(dir.slice(protocol.length), url).replace(/\\\\/g, '/');\n  }\n  return protocol + path.resolve(dir.slice(protocol.length), url);\n}\n\nfunction retrieveSourceMapURL(source) {\n  var fileData;\n\n  if (isInBrowser()) {\n     try {\n       var xhr = new XMLHttpRequest();\n       xhr.open('GET', source, false);\n       xhr.send(null);\n       fileData = xhr.readyState === 4 ? xhr.responseText : null;\n\n       // Support providing a sourceMappingURL via the SourceMap header\n       var sourceMapHeader = xhr.getResponseHeader(\"SourceMap\") ||\n                             xhr.getResponseHeader(\"X-SourceMap\");\n       if (sourceMapHeader) {\n         return sourceMapHeader;\n       }\n     } catch (e) {\n     }\n  }\n\n  // Get the URL of the source map\n  fileData = retrieveFile(source);\n  var re = /(?:\\/\\/[@#][\\s]*sourceMappingURL=([^\\s'\"]+)[\\s]*$)|(?:\\/\\*[@#][\\s]*sourceMappingURL=([^\\s*'\"]+)[\\s]*(?:\\*\\/)[\\s]*$)/mg;\n  // Keep executing the search to find the *last* sourceMappingURL to avoid\n  // picking up sourceMappingURLs from comments, strings, etc.\n  var lastMatch, match;\n  while (match = re.exec(fileData)) lastMatch = match;\n  if (!lastMatch) return null;\n  return lastMatch[1];\n};\n\n// Can be overridden by the retrieveSourceMap option to install. Takes a\n// generated source filename; returns a {map, optional url} object, or null if\n// there is no source map.  The map field may be either a string or the parsed\n// JSON object (ie, it must be a valid argument to the SourceMapConsumer\n// constructor).\nvar retrieveSourceMap = handlerExec(retrieveMapHandlers);\nretrieveMapHandlers.push(function(source) {\n  var sourceMappingURL = retrieveSourceMapURL(source);\n  if (!sourceMappingURL) return null;\n\n  // Read the contents of the source map\n  var sourceMapData;\n  if (reSourceMap.test(sourceMappingURL)) {\n    // Support source map URL as a data url\n    var rawData = sourceMappingURL.slice(sourceMappingURL.indexOf(',') + 1);\n    sourceMapData = bufferFrom(rawData, \"base64\").toString();\n    sourceMappingURL = source;\n  } else {\n    // Support source map URLs relative to the source URL\n    sourceMappingURL = supportRelativeURL(source, sourceMappingURL);\n    sourceMapData = retrieveFile(sourceMappingURL);\n  }\n\n  if (!sourceMapData) {\n    return null;\n  }\n\n  return {\n    url: sourceMappingURL,\n    map: sourceMapData\n  };\n});\n\nfunction mapSourcePosition(position) {\n  var sourceMap = sourceMapCache[position.source];\n  if (!sourceMap) {\n    // Call the (overrideable) retrieveSourceMap function to get the source map.\n    var urlAndMap = retrieveSourceMap(position.source);\n    if (urlAndMap) {\n      sourceMap = sourceMapCache[position.source] = {\n        url: urlAndMap.url,\n        map: new SourceMapConsumer(urlAndMap.map)\n      };\n\n      // Load all sources stored inline with the source map into the file cache\n      // to pretend like they are already loaded. They may not exist on disk.\n      if (sourceMap.map.sourcesContent) {\n        sourceMap.map.sources.forEach(function(source, i) {\n          var contents = sourceMap.map.sourcesContent[i];\n          if (contents) {\n            var url = supportRelativeURL(sourceMap.url, source);\n            fileContentsCache[url] = contents;\n          }\n        });\n      }\n    } else {\n      sourceMap = sourceMapCache[position.source] = {\n        url: null,\n        map: null\n      };\n    }\n  }\n\n  // Resolve the source URL relative to the URL of the source map\n  if (sourceMap && sourceMap.map && typeof sourceMap.map.originalPositionFor === 'function') {\n    var originalPosition = sourceMap.map.originalPositionFor(position);\n\n    // Only return the original position if a matching line was found. If no\n    // matching line is found then we return position instead, which will cause\n    // the stack trace to print the path and line for the compiled file. It is\n    // better to give a precise location in the compiled file than a vague\n    // location in the original file.\n    if (originalPosition.source !== null) {\n      originalPosition.source = supportRelativeURL(\n        sourceMap.url, originalPosition.source);\n      return originalPosition;\n    }\n  }\n\n  return position;\n}\n\n// Parses code generated by FormatEvalOrigin(), a function inside V8:\n// https://code.google.com/p/v8/source/browse/trunk/src/messages.js\nfunction mapEvalOrigin(origin) {\n  // Most eval() calls are in this format\n  var match = /^eval at ([^(]+) \\((.+):(\\d+):(\\d+)\\)$/.exec(origin);\n  if (match) {\n    var position = mapSourcePosition({\n      source: match[2],\n      line: +match[3],\n      column: match[4] - 1\n    });\n    return 'eval at ' + match[1] + ' (' + position.source + ':' +\n      position.line + ':' + (position.column + 1) + ')';\n  }\n\n  // Parse nested eval() calls using recursion\n  match = /^eval at ([^(]+) \\((.+)\\)$/.exec(origin);\n  if (match) {\n    return 'eval at ' + match[1] + ' (' + mapEvalOrigin(match[2]) + ')';\n  }\n\n  // Make sure we still return useful information if we didn't find anything\n  return origin;\n}\n\n// This is copied almost verbatim from the V8 source code at\n// https://code.google.com/p/v8/source/browse/trunk/src/messages.js. The\n// implementation of wrapCallSite() used to just forward to the actual source\n// code of CallSite.prototype.toString but unfortunately a new release of V8\n// did something to the prototype chain and broke the shim. The only fix I\n// could find was copy/paste.\nfunction CallSiteToString() {\n  var fileName;\n  var fileLocation = \"\";\n  if (this.isNative()) {\n    fileLocation = \"native\";\n  } else {\n    fileName = this.getScriptNameOrSourceURL();\n    if (!fileName && this.isEval()) {\n      fileLocation = this.getEvalOrigin();\n      fileLocation += \", \";  // Expecting source position to follow.\n    }\n\n    if (fileName) {\n      fileLocation += fileName;\n    } else {\n      // Source code does not originate from a file and is not native, but we\n      // can still get the source position inside the source string, e.g. in\n      // an eval string.\n      fileLocation += \"<anonymous>\";\n    }\n    var lineNumber = this.getLineNumber();\n    if (lineNumber != null) {\n      fileLocation += \":\" + lineNumber;\n      var columnNumber = this.getColumnNumber();\n      if (columnNumber) {\n        fileLocation += \":\" + columnNumber;\n      }\n    }\n  }\n\n  var line = \"\";\n  var functionName = this.getFunctionName();\n  var addSuffix = true;\n  var isConstructor = this.isConstructor();\n  var isMethodCall = !(this.isToplevel() || isConstructor);\n  if (isMethodCall) {\n    var typeName = this.getTypeName();\n    // Fixes shim to be backward compatable with Node v0 to v4\n    if (typeName === \"[object Object]\") {\n      typeName = \"null\";\n    }\n    var methodName = this.getMethodName();\n    if (functionName) {\n      if (typeName && functionName.indexOf(typeName) != 0) {\n        line += typeName + \".\";\n      }\n      line += functionName;\n      if (methodName && functionName.indexOf(\".\" + methodName) != functionName.length - methodName.length - 1) {\n        line += \" [as \" + methodName + \"]\";\n      }\n    } else {\n      line += typeName + \".\" + (methodName || \"<anonymous>\");\n    }\n  } else if (isConstructor) {\n    line += \"new \" + (functionName || \"<anonymous>\");\n  } else if (functionName) {\n    line += functionName;\n  } else {\n    line += fileLocation;\n    addSuffix = false;\n  }\n  if (addSuffix) {\n    line += \" (\" + fileLocation + \")\";\n  }\n  return line;\n}\n\nfunction cloneCallSite(frame) {\n  var object = {};\n  Object.getOwnPropertyNames(Object.getPrototypeOf(frame)).forEach(function(name) {\n    object[name] = /^(?:is|get)/.test(name) ? function() { return frame[name].call(frame); } : frame[name];\n  });\n  object.toString = CallSiteToString;\n  return object;\n}\n\nfunction wrapCallSite(frame) {\n  if(frame.isNative()) {\n    return frame;\n  }\n\n  // Most call sites will return the source file from getFileName(), but code\n  // passed to eval() ending in \"//# sourceURL=...\" will return the source file\n  // from getScriptNameOrSourceURL() instead\n  var source = frame.getFileName() || frame.getScriptNameOrSourceURL();\n  if (source) {\n    var line = frame.getLineNumber();\n    var column = frame.getColumnNumber() - 1;\n\n    // Fix position in Node where some (internal) code is prepended.\n    // See https://github.com/evanw/node-source-map-support/issues/36\n    var headerLength = 62;\n    if (line === 1 && column > headerLength && !isInBrowser() && !frame.isEval()) {\n      column -= headerLength;\n    }\n\n    var position = mapSourcePosition({\n      source: source,\n      line: line,\n      column: column\n    });\n    frame = cloneCallSite(frame);\n    var originalFunctionName = frame.getFunctionName;\n    frame.getFunctionName = function() { return position.name || originalFunctionName(); };\n    frame.getFileName = function() { return position.source; };\n    frame.getLineNumber = function() { return position.line; };\n    frame.getColumnNumber = function() { return position.column + 1; };\n    frame.getScriptNameOrSourceURL = function() { return position.source; };\n    return frame;\n  }\n\n  // Code called using eval() needs special handling\n  var origin = frame.isEval() && frame.getEvalOrigin();\n  if (origin) {\n    origin = mapEvalOrigin(origin);\n    frame = cloneCallSite(frame);\n    frame.getEvalOrigin = function() { return origin; };\n    return frame;\n  }\n\n  // If we get here then we were unable to change the source position\n  return frame;\n}\n\n// This function is part of the V8 stack trace API, for more info see:\n// https://v8.dev/docs/stack-trace-api\nfunction prepareStackTrace(error, stack) {\n  if (emptyCacheBetweenOperations) {\n    fileContentsCache = {};\n    sourceMapCache = {};\n  }\n\n  var name = error.name || 'Error';\n  var message = error.message || '';\n  var errorString = name + \": \" + message;\n\n  return errorString + stack.map(function(frame) {\n    return '\\n    at ' + wrapCallSite(frame);\n  }).join('');\n}\n\n// Generate position and snippet of original source with pointer\nfunction getErrorSource(error) {\n  var match = /\\n    at [^(]+ \\((.*):(\\d+):(\\d+)\\)/.exec(error.stack);\n  if (match) {\n    var source = match[1];\n    var line = +match[2];\n    var column = +match[3];\n\n    // Support the inline sourceContents inside the source map\n    var contents = fileContentsCache[source];\n\n    // Support files on disk\n    if (!contents && fs && fs.existsSync(source)) {\n      try {\n        contents = fs.readFileSync(source, 'utf8');\n      } catch (er) {\n        contents = '';\n      }\n    }\n\n    // Format the line from the original source code like node does\n    if (contents) {\n      var code = contents.split(/(?:\\r\\n|\\r|\\n)/)[line - 1];\n      if (code) {\n        return source + ':' + line + '\\n' + code + '\\n' +\n          new Array(column).join(' ') + '^';\n      }\n    }\n  }\n  return null;\n}\n\nfunction printErrorAndExit (error) {\n  var source = getErrorSource(error);\n\n  // Ensure error is printed synchronously and not truncated\n  if (process.stderr._handle && process.stderr._handle.setBlocking) {\n    process.stderr._handle.setBlocking(true);\n  }\n\n  if (source) {\n    console.error();\n    console.error(source);\n  }\n\n  console.error(error.stack);\n  process.exit(1);\n}\n\nfunction shimEmitUncaughtException () {\n  var origEmit = process.emit;\n\n  process.emit = function (type) {\n    if (type === 'uncaughtException') {\n      var hasStack = (arguments[1] && arguments[1].stack);\n      var hasListeners = (this.listeners(type).length > 0);\n\n      if (hasStack && !hasListeners) {\n        return printErrorAndExit(arguments[1]);\n      }\n    }\n\n    return origEmit.apply(this, arguments);\n  };\n}\n\nvar originalRetrieveFileHandlers = retrieveFileHandlers.slice(0);\nvar originalRetrieveMapHandlers = retrieveMapHandlers.slice(0);\n\nexports.wrapCallSite = wrapCallSite;\nexports.getErrorSource = getErrorSource;\nexports.mapSourcePosition = mapSourcePosition;\nexports.retrieveSourceMap = retrieveSourceMap;\n\nexports.install = function(options) {\n  options = options || {};\n\n  if (options.environment) {\n    environment = options.environment;\n    if ([\"node\", \"browser\", \"auto\"].indexOf(environment) === -1) {\n      throw new Error(\"environment \" + environment + \" was unknown. Available options are {auto, browser, node}\")\n    }\n  }\n\n  // Allow sources to be found by methods other than reading the files\n  // directly from disk.\n  if (options.retrieveFile) {\n    if (options.overrideRetrieveFile) {\n      retrieveFileHandlers.length = 0;\n    }\n\n    retrieveFileHandlers.unshift(options.retrieveFile);\n  }\n\n  // Allow source maps to be found by methods other than reading the files\n  // directly from disk.\n  if (options.retrieveSourceMap) {\n    if (options.overrideRetrieveSourceMap) {\n      retrieveMapHandlers.length = 0;\n    }\n\n    retrieveMapHandlers.unshift(options.retrieveSourceMap);\n  }\n\n  // Support runtime transpilers that include inline source maps\n  if (options.hookRequire && !isInBrowser()) {\n    var Module;\n    try {\n      Module = require('module');\n    } catch (err) {\n      // NOP: Loading in catch block to convert webpack error to warning.\n    }\n    var $compile = Module.prototype._compile;\n\n    if (!$compile.__sourceMapSupport) {\n      Module.prototype._compile = function(content, filename) {\n        fileContentsCache[filename] = content;\n        sourceMapCache[filename] = undefined;\n        return $compile.call(this, content, filename);\n      };\n\n      Module.prototype._compile.__sourceMapSupport = true;\n    }\n  }\n\n  // Configure options\n  if (!emptyCacheBetweenOperations) {\n    emptyCacheBetweenOperations = 'emptyCacheBetweenOperations' in options ?\n      options.emptyCacheBetweenOperations : false;\n  }\n\n  // Install the error reformatter\n  if (!errorFormatterInstalled) {\n    errorFormatterInstalled = true;\n    Error.prepareStackTrace = prepareStackTrace;\n  }\n\n  if (!uncaughtShimInstalled) {\n    var installHandler = 'handleUncaughtExceptions' in options ?\n      options.handleUncaughtExceptions : true;\n\n    // Provide the option to not install the uncaught exception handler. This is\n    // to support other uncaught exception handlers (in test frameworks, for\n    // example). If this handler is not installed and there are no other uncaught\n    // exception handlers, uncaught exceptions will be caught by node's built-in\n    // exception handler and the process will still be terminated. However, the\n    // generated JavaScript code will be shown above the stack trace instead of\n    // the original source code.\n    if (installHandler && hasGlobalProcessEventEmitter()) {\n      uncaughtShimInstalled = true;\n      shimEmitUncaughtException();\n    }\n  }\n};\n\nexports.resetRetrieveHandlers = function() {\n  retrieveFileHandlers.length = 0;\n  retrieveMapHandlers.length = 0;\n\n  retrieveFileHandlers = originalRetrieveFileHandlers.slice(0);\n  retrieveMapHandlers = originalRetrieveMapHandlers.slice(0);\n  \n  retrieveSourceMap = handlerExec(retrieveMapHandlers);\n  retrieveFile = handlerExec(retrieveFileHandlers);\n}\n","/*\n * Copyright 2009-2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE.txt or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\nexports.SourceMapGenerator = require('./lib/source-map-generator').SourceMapGenerator;\nexports.SourceMapConsumer = require('./lib/source-map-consumer').SourceMapConsumer;\nexports.SourceNode = require('./lib/source-node').SourceNode;\n","var fs = require(\"fs\");\nvar zlib = require(\"zlib\");\nconst fd_slicer = require(\"node-fd-slicer\");\nvar crc32 = require(\"buffer-crc32\");\nvar util = require(\"util\");\nvar EventEmitter = require(\"events\").EventEmitter;\nvar Transform = require(\"stream\").Transform;\nvar PassThrough = require(\"stream\").PassThrough;\nvar Writable = require(\"stream\").Writable;\n\nexports.open = open;\nexports.fromFd = fromFd;\nexports.fromBuffer = fromBuffer;\nexports.fromRandomAccessReader = fromRandomAccessReader;\nexports.dosDateTimeToDate = dosDateTimeToDate;\nexports.validateFileName = validateFileName;\nexports.ZipFile = ZipFile;\nexports.Entry = Entry;\nexports.RandomAccessReader = RandomAccessReader;\n\nfunction open(path, options, callback) {\n\tif (typeof options === \"function\") {\n\t\tcallback = options;\n\t\toptions = null;\n\t}\n\tif (options == null) options = {};\n\tif (options.autoClose == null) options.autoClose = true;\n\tif (options.lazyEntries == null) options.lazyEntries = false;\n\tif (options.decodeStrings == null) options.decodeStrings = true;\n\tif (options.validateEntrySizes == null) options.validateEntrySizes = true;\n\tif (options.strictFileNames == null) options.strictFileNames = false;\n\tif (callback == null) callback = defaultCallback;\n\tfs.open(path, \"r\", function (err, fd) {\n\t\tif (err) return callback(err);\n\t\tfromFd(fd, options, function (err, zipfile) {\n\t\t\tif (err) fs.close(fd, defaultCallback);\n\t\t\tcallback(err, zipfile);\n\t\t});\n\t});\n}\n\nfunction fromFd(fd, options, callback) {\n\tif (typeof options === \"function\") {\n\t\tcallback = options;\n\t\toptions = null;\n\t}\n\tif (options == null) options = {};\n\tif (options.autoClose == null) options.autoClose = false;\n\tif (options.lazyEntries == null) options.lazyEntries = false;\n\tif (options.decodeStrings == null) options.decodeStrings = true;\n\tif (options.validateEntrySizes == null) options.validateEntrySizes = true;\n\tif (options.strictFileNames == null) options.strictFileNames = false;\n\tif (callback == null) callback = defaultCallback;\n\tfs.fstat(fd, function (err, stats) {\n\t\tif (err) return callback(err);\n\t\tvar reader = fd_slicer.createFromFd(fd, {autoClose: true});\n\t\tfromRandomAccessReader(reader, stats.size, options, callback);\n\t});\n}\n\nfunction fromBuffer(buffer, options, callback) {\n\tif (typeof options === \"function\") {\n\t\tcallback = options;\n\t\toptions = null;\n\t}\n\tif (options == null) options = {};\n\toptions.autoClose = false;\n\tif (options.lazyEntries == null) options.lazyEntries = false;\n\tif (options.decodeStrings == null) options.decodeStrings = true;\n\tif (options.validateEntrySizes == null) options.validateEntrySizes = true;\n\tif (options.strictFileNames == null) options.strictFileNames = false;\n\t// limit the max chunk size. see https://github.com/thejoshwolfe/yauzl/issues/87\n\tvar reader = fd_slicer.createFromBuffer(buffer, {maxChunkSize: 0x10000});\n\tfromRandomAccessReader(reader, buffer.length, options, callback);\n}\n\nfunction fromRandomAccessReader(reader, totalSize, options, callback) {\n\tif (typeof options === \"function\") {\n\t\tcallback = options;\n\t\toptions = null;\n\t}\n\tif (options == null) options = {};\n\tif (options.autoClose == null) options.autoClose = true;\n\tif (options.lazyEntries == null) options.lazyEntries = false;\n\tif (options.decodeStrings == null) options.decodeStrings = true;\n\tvar decodeStrings = !!options.decodeStrings;\n\tif (options.validateEntrySizes == null) options.validateEntrySizes = true;\n\tif (options.strictFileNames == null) options.strictFileNames = false;\n\tif (callback == null) callback = defaultCallback;\n\tif (typeof totalSize !== \"number\") throw new Error(\"expected totalSize parameter to be a number\");\n\tif (totalSize > Number.MAX_SAFE_INTEGER) {\n\t\tthrow new Error(\"zip file too large. only file sizes up to 2^52 are supported due to JavaScript's Number type being an IEEE 754 double.\");\n\t}\n\n\t// the matching unref() call is in zipfile.close()\n\treader.ref();\n\n\t// eocdr means End of Central Directory Record.\n\t// search backwards for the eocdr signature.\n\t// the last field of the eocdr is a variable-length comment.\n\t// the comment size is encoded in a 2-byte field in the eocdr, which we can't find without trudging backwards through the comment to find it.\n\t// as a consequence of this design decision, it's possible to have ambiguous zip file metadata if a coherent eocdr was in the comment.\n\t// we search backwards for a eocdr signature, and hope that whoever made the zip file was smart enough to forbid the eocdr signature in the comment.\n\tvar eocdrWithoutCommentSize = 22;\n\tvar maxCommentSize = 0xffff; // 2-byte size\n\tvar bufferSize = Math.min(eocdrWithoutCommentSize + maxCommentSize, totalSize);\n\tvar buffer = newBuffer(bufferSize);\n\tvar bufferReadStart = totalSize - buffer.length;\n\treadAndAssertNoEof(reader, buffer, 0, bufferSize, bufferReadStart, function (err) {\n\t\tif (err) return callback(err);\n\t\tfor (var i = bufferSize - eocdrWithoutCommentSize; i >= 0; i -= 1) {\n\t\t\tif (buffer.readUInt32LE(i) !== 0x06054b50) continue;\n\t\t\t// found eocdr\n\t\t\tvar eocdrBuffer = buffer.slice(i);\n\n\t\t\t// 0 - End of central directory signature = 0x06054b50\n\t\t\t// 4 - Number of this disk\n\t\t\tvar diskNumber = eocdrBuffer.readUInt16LE(4);\n\t\t\tif (diskNumber !== 0) {\n\t\t\t\treturn callback(new Error(\"multi-disk zip files are not supported: found disk number: \" + diskNumber));\n\t\t\t}\n\t\t\t// 6 - Disk where central directory starts\n\t\t\t// 8 - Number of central directory records on this disk\n\t\t\t// 10 - Total number of central directory records\n\t\t\tvar entryCount = eocdrBuffer.readUInt16LE(10);\n\t\t\t// 12 - Size of central directory (bytes)\n\t\t\t// 16 - Offset of start of central directory, relative to start of archive\n\t\t\tvar centralDirectoryOffset = eocdrBuffer.readUInt32LE(16);\n\t\t\t// 20 - Comment length\n\t\t\tvar commentLength = eocdrBuffer.readUInt16LE(20);\n\t\t\tvar expectedCommentLength = eocdrBuffer.length - eocdrWithoutCommentSize;\n\t\t\tif (commentLength !== expectedCommentLength) {\n\t\t\t\treturn callback(new Error(\"invalid comment length. expected: \" + expectedCommentLength + \". found: \" + commentLength));\n\t\t\t}\n\t\t\t// 22 - Comment\n\t\t\t// the encoding is always cp437.\n\t\t\tvar comment = decodeStrings ? decodeBuffer(eocdrBuffer, 22, eocdrBuffer.length, false)\n\t\t\t\t: eocdrBuffer.slice(22);\n\n\t\t\tif (!(entryCount === 0xffff || centralDirectoryOffset === 0xffffffff)) {\n\t\t\t\treturn callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n\t\t\t}\n\n\t\t\t// ZIP64 format\n\n\t\t\t// ZIP64 Zip64 end of central directory locator\n\t\t\tvar zip64EocdlBuffer = newBuffer(20);\n\t\t\tvar zip64EocdlOffset = bufferReadStart + i - zip64EocdlBuffer.length;\n\t\t\treadAndAssertNoEof(reader, zip64EocdlBuffer, 0, zip64EocdlBuffer.length, zip64EocdlOffset, function (err) {\n\t\t\t\tif (err) return callback(err);\n\n\t\t\t\t// 0 - zip64 end of central dir locator signature = 0x07064b50\n\t\t\t\tif (zip64EocdlBuffer.readUInt32LE(0) !== 0x07064b50) {\n\t\t\t\t\treturn callback(new Error(\"invalid zip64 end of central directory locator signature\"));\n\t\t\t\t}\n\t\t\t\t// 4 - number of the disk with the start of the zip64 end of central directory\n\t\t\t\t// 8 - relative offset of the zip64 end of central directory record\n\t\t\t\tvar zip64EocdrOffset = readUInt64LE(zip64EocdlBuffer, 8);\n\t\t\t\t// 16 - total number of disks\n\n\t\t\t\t// ZIP64 end of central directory record\n\t\t\t\tvar zip64EocdrBuffer = newBuffer(56);\n\t\t\t\treadAndAssertNoEof(reader, zip64EocdrBuffer, 0, zip64EocdrBuffer.length, zip64EocdrOffset, function (err) {\n\t\t\t\t\tif (err) return callback(err);\n\n\t\t\t\t\t// 0 - zip64 end of central dir signature                           4 bytes  (0x06064b50)\n\t\t\t\t\tif (zip64EocdrBuffer.readUInt32LE(0) !== 0x06064b50) {\n\t\t\t\t\t\treturn callback(new Error(\"invalid zip64 end of central directory record signature\"));\n\t\t\t\t\t}\n\t\t\t\t\t// 4 - size of zip64 end of central directory record                8 bytes\n\t\t\t\t\t// 12 - version made by                                             2 bytes\n\t\t\t\t\t// 14 - version needed to extract                                   2 bytes\n\t\t\t\t\t// 16 - number of this disk                                         4 bytes\n\t\t\t\t\t// 20 - number of the disk with the start of the central directory  4 bytes\n\t\t\t\t\t// 24 - total number of entries in the central directory on this disk         8 bytes\n\t\t\t\t\t// 32 - total number of entries in the central directory            8 bytes\n\t\t\t\t\tentryCount = readUInt64LE(zip64EocdrBuffer, 32);\n\t\t\t\t\t// 40 - size of the central directory                               8 bytes\n\t\t\t\t\t// 48 - offset of start of central directory with respect to the starting disk number     8 bytes\n\t\t\t\t\tcentralDirectoryOffset = readUInt64LE(zip64EocdrBuffer, 48);\n\t\t\t\t\t// 56 - zip64 extensible data sector                                (variable size)\n\t\t\t\t\treturn callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n\t\t\t\t});\n\t\t\t});\n\t\t\treturn;\n\t\t}\n\t\tcallback(new Error(\"end of central directory record signature not found\"));\n\t});\n}\n\nutil.inherits(ZipFile, EventEmitter);\n\nfunction ZipFile(reader, centralDirectoryOffset, fileSize, entryCount, comment, autoClose, lazyEntries, decodeStrings, validateEntrySizes, strictFileNames) {\n\tvar self = this;\n\tEventEmitter.call(self);\n\tself.reader = reader;\n\t// forward close events\n\tself.reader.on(\"error\", function (err) {\n\t\t// error closing the fd\n\t\temitError(self, err);\n\t});\n\tself.reader.once(\"close\", function () {\n\t\tself.emit(\"close\");\n\t});\n\tself.readEntryCursor = centralDirectoryOffset;\n\tself.fileSize = fileSize;\n\tself.entryCount = entryCount;\n\tself.comment = comment;\n\tself.entriesRead = 0;\n\tself.autoClose = !!autoClose;\n\tself.lazyEntries = !!lazyEntries;\n\tself.decodeStrings = !!decodeStrings;\n\tself.validateEntrySizes = !!validateEntrySizes;\n\tself.strictFileNames = !!strictFileNames;\n\tself.isOpen = true;\n\tself.emittedError = false;\n\n\tif (!self.lazyEntries) self._readEntry();\n}\n\nZipFile.prototype.close = function () {\n\tif (!this.isOpen) return;\n\tthis.isOpen = false;\n\tthis.reader.unref();\n};\n\nfunction emitErrorAndAutoClose(self, err) {\n\tif (self.autoClose) self.close();\n\temitError(self, err);\n}\n\nfunction emitError(self, err) {\n\tif (self.emittedError) return;\n\tself.emittedError = true;\n\tself.emit(\"error\", err);\n}\n\nZipFile.prototype.readEntry = function () {\n\tif (!this.lazyEntries) throw new Error(\"readEntry() called without lazyEntries:true\");\n\tthis._readEntry();\n};\nZipFile.prototype._readEntry = function () {\n\tvar self = this;\n\tif (self.entryCount === self.entriesRead) {\n\t\t// done with metadata\n\t\tsetImmediate(function () {\n\t\t\tif (self.autoClose) self.close();\n\t\t\tif (self.emittedError) return;\n\t\t\tself.emit(\"end\");\n\t\t});\n\t\treturn;\n\t}\n\tif (self.emittedError) return;\n\tvar buffer = newBuffer(46);\n\treadAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function (err) {\n\t\tif (err) return emitErrorAndAutoClose(self, err);\n\t\tif (self.emittedError) return;\n\t\tvar entry = new Entry();\n\t\t// 0 - Central directory file header signature\n\t\tvar signature = buffer.readUInt32LE(0);\n\t\tif (signature !== 0x02014b50) return emitErrorAndAutoClose(self, new Error(\"invalid central directory file header signature: 0x\" + signature.toString(16)));\n\t\t// 4 - Version made by\n\t\tentry.versionMadeBy = buffer.readUInt16LE(4);\n\t\t// 6 - Version needed to extract (minimum)\n\t\tentry.versionNeededToExtract = buffer.readUInt16LE(6);\n\t\t// 8 - General purpose bit flag\n\t\tentry.generalPurposeBitFlag = buffer.readUInt16LE(8);\n\t\t// 10 - Compression method\n\t\tentry.compressionMethod = buffer.readUInt16LE(10);\n\t\t// 12 - File last modification time\n\t\tentry.lastModFileTime = buffer.readUInt16LE(12);\n\t\t// 14 - File last modification date\n\t\tentry.lastModFileDate = buffer.readUInt16LE(14);\n\t\t// 16 - CRC-32\n\t\tentry.crc32 = buffer.readUInt32LE(16);\n\t\t// 20 - Compressed size\n\t\tentry.compressedSize = buffer.readUInt32LE(20);\n\t\t// 24 - Uncompressed size\n\t\tentry.uncompressedSize = buffer.readUInt32LE(24);\n\t\t// 28 - File name length (n)\n\t\tentry.fileNameLength = buffer.readUInt16LE(28);\n\t\t// 30 - Extra field length (m)\n\t\tentry.extraFieldLength = buffer.readUInt16LE(30);\n\t\t// 32 - File comment length (k)\n\t\tentry.fileCommentLength = buffer.readUInt16LE(32);\n\t\t// 34 - Disk number where file starts\n\t\t// 36 - Internal file attributes\n\t\tentry.internalFileAttributes = buffer.readUInt16LE(36);\n\t\t// 38 - External file attributes\n\t\tentry.externalFileAttributes = buffer.readUInt32LE(38);\n\t\t// 42 - Relative offset of local file header\n\t\tentry.relativeOffsetOfLocalHeader = buffer.readUInt32LE(42);\n\n\t\tif (entry.generalPurposeBitFlag & 0x40) return emitErrorAndAutoClose(self, new Error(\"strong encryption is not supported\"));\n\n\t\tself.readEntryCursor += 46;\n\n\t\tbuffer = newBuffer(entry.fileNameLength + entry.extraFieldLength + entry.fileCommentLength);\n\t\treadAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function (err) {\n\t\t\tif (err) return emitErrorAndAutoClose(self, err);\n\t\t\tif (self.emittedError) return;\n\t\t\t// 46 - File name\n\t\t\tvar isUtf8 = (entry.generalPurposeBitFlag & 0x800) !== 0;\n\t\t\tentry.fileName = self.decodeStrings ? decodeBuffer(buffer, 0, entry.fileNameLength, isUtf8)\n\t\t\t\t: buffer.slice(0, entry.fileNameLength);\n\n\t\t\t// 46+n - Extra field\n\t\t\tvar fileCommentStart = entry.fileNameLength + entry.extraFieldLength;\n\t\t\tvar extraFieldBuffer = buffer.slice(entry.fileNameLength, fileCommentStart);\n\t\t\tentry.extraFields = [];\n\t\t\tvar i = 0;\n\t\t\twhile (i < extraFieldBuffer.length - 3) {\n\t\t\t\tvar headerId = extraFieldBuffer.readUInt16LE(i + 0);\n\t\t\t\tvar dataSize = extraFieldBuffer.readUInt16LE(i + 2);\n\t\t\t\tvar dataStart = i + 4;\n\t\t\t\tvar dataEnd = dataStart + dataSize;\n\t\t\t\tif (dataEnd > extraFieldBuffer.length) return emitErrorAndAutoClose(self, new Error(\"extra field length exceeds extra field buffer size\"));\n\t\t\t\tvar dataBuffer = newBuffer(dataSize);\n\t\t\t\textraFieldBuffer.copy(dataBuffer, 0, dataStart, dataEnd);\n\t\t\t\tentry.extraFields.push({\n\t\t\t\t\tid: headerId,\n\t\t\t\t\tdata: dataBuffer,\n\t\t\t\t});\n\t\t\t\ti = dataEnd;\n\t\t\t}\n\n\t\t\t// 46+n+m - File comment\n\t\t\tentry.fileComment = self.decodeStrings ? decodeBuffer(buffer, fileCommentStart, fileCommentStart + entry.fileCommentLength, isUtf8)\n\t\t\t\t: buffer.slice(fileCommentStart, fileCommentStart + entry.fileCommentLength);\n\t\t\t// compatibility hack for https://github.com/thejoshwolfe/yauzl/issues/47\n\t\t\tentry.comment = entry.fileComment;\n\n\t\t\tself.readEntryCursor += buffer.length;\n\t\t\tself.entriesRead += 1;\n\n\t\t\tif (entry.uncompressedSize === 0xffffffff ||\n\t\t\t\tentry.compressedSize === 0xffffffff ||\n\t\t\t\tentry.relativeOffsetOfLocalHeader === 0xffffffff) {\n\t\t\t\t// ZIP64 format\n\t\t\t\t// find the Zip64 Extended Information Extra Field\n\t\t\t\tvar zip64EiefBuffer = null;\n\t\t\t\tfor (var i = 0; i < entry.extraFields.length; i++) {\n\t\t\t\t\tvar extraField = entry.extraFields[i];\n\t\t\t\t\tif (extraField.id === 0x0001) {\n\t\t\t\t\t\tzip64EiefBuffer = extraField.data;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (zip64EiefBuffer == null) {\n\t\t\t\t\treturn emitErrorAndAutoClose(self, new Error(\"expected zip64 extended information extra field\"));\n\t\t\t\t}\n\t\t\t\tvar index = 0;\n\t\t\t\t// 0 - Original Size          8 bytes\n\t\t\t\tif (entry.uncompressedSize === 0xffffffff) {\n\t\t\t\t\tif (index + 8 > zip64EiefBuffer.length) {\n\t\t\t\t\t\treturn emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include uncompressed size\"));\n\t\t\t\t\t}\n\t\t\t\t\tentry.uncompressedSize = readUInt64LE(zip64EiefBuffer, index);\n\t\t\t\t\tindex += 8;\n\t\t\t\t}\n\t\t\t\t// 8 - Compressed Size        8 bytes\n\t\t\t\tif (entry.compressedSize === 0xffffffff) {\n\t\t\t\t\tif (index + 8 > zip64EiefBuffer.length) {\n\t\t\t\t\t\treturn emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include compressed size\"));\n\t\t\t\t\t}\n\t\t\t\t\tentry.compressedSize = readUInt64LE(zip64EiefBuffer, index);\n\t\t\t\t\tindex += 8;\n\t\t\t\t}\n\t\t\t\t// 16 - Relative Header Offset 8 bytes\n\t\t\t\tif (entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n\t\t\t\t\tif (index + 8 > zip64EiefBuffer.length) {\n\t\t\t\t\t\treturn emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include relative header offset\"));\n\t\t\t\t\t}\n\t\t\t\t\tentry.relativeOffsetOfLocalHeader = readUInt64LE(zip64EiefBuffer, index);\n\t\t\t\t\tindex += 8;\n\t\t\t\t}\n\t\t\t\t// 24 - Disk Start Number      4 bytes\n\t\t\t}\n\n\t\t\t// check for Info-ZIP Unicode Path Extra Field (0x7075)\n\t\t\t// see https://github.com/thejoshwolfe/yauzl/issues/33\n\t\t\tif (self.decodeStrings) {\n\t\t\t\tfor (var i = 0; i < entry.extraFields.length; i++) {\n\t\t\t\t\tvar extraField = entry.extraFields[i];\n\t\t\t\t\tif (extraField.id === 0x7075) {\n\t\t\t\t\t\tif (extraField.data.length < 6) {\n\t\t\t\t\t\t\t// too short to be meaningful\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Version       1 byte      version of this extra field, currently 1\n\t\t\t\t\t\tif (extraField.data.readUInt8(0) !== 1) {\n\t\t\t\t\t\t\t// > Changes may not be backward compatible so this extra\n\t\t\t\t\t\t\t// > field should not be used if the version is not recognized.\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// NameCRC32     4 bytes     File Name Field CRC32 Checksum\n\t\t\t\t\t\tvar oldNameCrc32 = extraField.data.readUInt32LE(1);\n\t\t\t\t\t\tif (crc32.unsigned(buffer.slice(0, entry.fileNameLength)) !== oldNameCrc32) {\n\t\t\t\t\t\t\t// > If the CRC check fails, this UTF-8 Path Extra Field should be\n\t\t\t\t\t\t\t// > ignored and the File Name field in the header should be used instead.\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// UnicodeName   Variable    UTF-8 version of the entry File Name\n\t\t\t\t\t\tentry.fileName = decodeBuffer(extraField.data, 5, extraField.data.length, true);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// validate file size\n\t\t\tif (self.validateEntrySizes && entry.compressionMethod === 0) {\n\t\t\t\tvar expectedCompressedSize = entry.uncompressedSize;\n\t\t\t\tif (entry.isEncrypted()) {\n\t\t\t\t\t// traditional encryption prefixes the file data with a header\n\t\t\t\t\texpectedCompressedSize += 12;\n\t\t\t\t}\n\t\t\t\tif (entry.compressedSize !== expectedCompressedSize) {\n\t\t\t\t\tvar msg = \"compressed/uncompressed size mismatch for stored file: \" + entry.compressedSize + \" != \" + entry.uncompressedSize;\n\t\t\t\t\treturn emitErrorAndAutoClose(self, new Error(msg));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (self.decodeStrings) {\n\t\t\t\tif (!self.strictFileNames) {\n\t\t\t\t\t// allow backslash\n\t\t\t\t\tentry.fileName = entry.fileName.replace(/\\\\/g, \"/\");\n\t\t\t\t}\n\t\t\t\tvar errorMessage = validateFileName(entry.fileName, self.validateFileNameOptions);\n\t\t\t\tif (errorMessage != null) return emitErrorAndAutoClose(self, new Error(errorMessage));\n\t\t\t}\n\t\t\tself.emit(\"entry\", entry);\n\n\t\t\tif (!self.lazyEntries) self._readEntry();\n\t\t});\n\t});\n};\n\nZipFile.prototype.openReadStream = function (entry, options, callback) {\n\tvar self = this;\n\t// parameter validation\n\tvar relativeStart = 0;\n\tvar relativeEnd = entry.compressedSize;\n\tif (callback == null) {\n\t\tcallback = options;\n\t\toptions = {};\n\t} else {\n\t\t// validate options that the caller has no excuse to get wrong\n\t\tif (options.decrypt != null) {\n\t\t\tif (!entry.isEncrypted()) {\n\t\t\t\tthrow new Error(\"options.decrypt can only be specified for encrypted entries\");\n\t\t\t}\n\t\t\tif (options.decrypt !== false) throw new Error(\"invalid options.decrypt value: \" + options.decrypt);\n\t\t\tif (entry.isCompressed()) {\n\t\t\t\tif (options.decompress !== false) throw new Error(\"entry is encrypted and compressed, and options.decompress !== false\");\n\t\t\t}\n\t\t}\n\t\tif (options.decompress != null) {\n\t\t\tif (!entry.isCompressed()) {\n\t\t\t\tthrow new Error(\"options.decompress can only be specified for compressed entries\");\n\t\t\t}\n\t\t\tif (!(options.decompress === false || options.decompress === true)) {\n\t\t\t\tthrow new Error(\"invalid options.decompress value: \" + options.decompress);\n\t\t\t}\n\t\t}\n\t\tif (options.start != null || options.end != null) {\n\t\t\tif (entry.isCompressed() && options.decompress !== false) {\n\t\t\t\tthrow new Error(\"start/end range not allowed for compressed entry without options.decompress === false\");\n\t\t\t}\n\t\t\tif (entry.isEncrypted() && options.decrypt !== false) {\n\t\t\t\tthrow new Error(\"start/end range not allowed for encrypted entry without options.decrypt === false\");\n\t\t\t}\n\t\t}\n\t\tif (options.start != null) {\n\t\t\trelativeStart = options.start;\n\t\t\tif (relativeStart < 0) throw new Error(\"options.start < 0\");\n\t\t\tif (relativeStart > entry.compressedSize) throw new Error(\"options.start > entry.compressedSize\");\n\t\t}\n\t\tif (options.end != null) {\n\t\t\trelativeEnd = options.end;\n\t\t\tif (relativeEnd < 0) throw new Error(\"options.end < 0\");\n\t\t\tif (relativeEnd > entry.compressedSize) throw new Error(\"options.end > entry.compressedSize\");\n\t\t\tif (relativeEnd < relativeStart) throw new Error(\"options.end < options.start\");\n\t\t}\n\t}\n\t// any further errors can either be caused by the zipfile,\n\t// or were introduced in a minor version of yauzl,\n\t// so should be passed to the client rather than thrown.\n\tif (!self.isOpen) return callback(new Error(\"closed\"));\n\tif (entry.isEncrypted()) {\n\t\tif (options.decrypt !== false) return callback(new Error(\"entry is encrypted, and options.decrypt !== false\"));\n\t}\n\t// make sure we don't lose the fd before we open the actual read stream\n\tself.reader.ref();\n\tvar buffer = newBuffer(30);\n\treadAndAssertNoEof(self.reader, buffer, 0, buffer.length, entry.relativeOffsetOfLocalHeader, function (err) {\n\t\ttry {\n\t\t\tif (err) return callback(err);\n\t\t\t// 0 - Local file header signature = 0x04034b50\n\t\t\tvar signature = buffer.readUInt32LE(0);\n\t\t\tif (signature !== 0x04034b50) {\n\t\t\t\treturn callback(new Error(\"invalid local file header signature: 0x\" + signature.toString(16)));\n\t\t\t}\n\t\t\t// all this should be redundant\n\t\t\t// 4 - Version needed to extract (minimum)\n\t\t\t// 6 - General purpose bit flag\n\t\t\t// 8 - Compression method\n\t\t\t// 10 - File last modification time\n\t\t\t// 12 - File last modification date\n\t\t\t// 14 - CRC-32\n\t\t\t// 18 - Compressed size\n\t\t\t// 22 - Uncompressed size\n\t\t\t// 26 - File name length (n)\n\t\t\tvar fileNameLength = buffer.readUInt16LE(26);\n\t\t\t// 28 - Extra field length (m)\n\t\t\tvar extraFieldLength = buffer.readUInt16LE(28);\n\t\t\t// 30 - File name\n\t\t\t// 30+n - Extra field\n\t\t\tvar localFileHeaderEnd = entry.relativeOffsetOfLocalHeader + buffer.length + fileNameLength + extraFieldLength;\n\t\t\tvar decompress;\n\t\t\tif (entry.compressionMethod === 0) {\n\t\t\t\t// 0 - The file is stored (no compression)\n\t\t\t\tdecompress = false;\n\t\t\t} else if (entry.compressionMethod === 8) {\n\t\t\t\t// 8 - The file is Deflated\n\t\t\t\tdecompress = options.decompress != null ? options.decompress : true;\n\t\t\t} else {\n\t\t\t\treturn callback(new Error(\"unsupported compression method: \" + entry.compressionMethod));\n\t\t\t}\n\t\t\tvar fileDataStart = localFileHeaderEnd;\n\t\t\tvar fileDataEnd = fileDataStart + entry.compressedSize;\n\t\t\tif (entry.compressedSize !== 0) {\n\t\t\t\t// bounds check now, because the read streams will probably not complain loud enough.\n\t\t\t\t// since we're dealing with an unsigned offset plus an unsigned size,\n\t\t\t\t// we only have 1 thing to check for.\n\t\t\t\tif (fileDataEnd > self.fileSize) {\n\t\t\t\t\treturn callback(new Error(\"file data overflows file bounds: \" +\n\t\t\t\t\t\tfileDataStart + \" + \" + entry.compressedSize + \" > \" + self.fileSize));\n\t\t\t\t}\n\t\t\t}\n\t\t\tvar readStream = self.reader.createReadStream({\n\t\t\t\tstart: fileDataStart + relativeStart,\n\t\t\t\tend: fileDataStart + relativeEnd,\n\t\t\t});\n\t\t\tvar endpointStream = readStream;\n\t\t\tif (decompress) {\n\t\t\t\tvar destroyed = false;\n\t\t\t\tvar inflateFilter = zlib.createInflateRaw();\n\t\t\t\treadStream.on(\"error\", function (err) {\n\t\t\t\t\t// setImmediate here because errors can be emitted during the first call to pipe()\n\t\t\t\t\tsetImmediate(function () {\n\t\t\t\t\t\tif (!destroyed) inflateFilter.emit(\"error\", err);\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t\treadStream.pipe(inflateFilter);\n\n\t\t\t\tif (self.validateEntrySizes) {\n\t\t\t\t\tendpointStream = new AssertByteCountStream(entry.uncompressedSize);\n\t\t\t\t\tinflateFilter.on(\"error\", function (err) {\n\t\t\t\t\t\t// forward zlib errors to the client-visible stream\n\t\t\t\t\t\tsetImmediate(function () {\n\t\t\t\t\t\t\tif (!destroyed) endpointStream.emit(\"error\", err);\n\t\t\t\t\t\t});\n\t\t\t\t\t});\n\t\t\t\t\tinflateFilter.pipe(endpointStream);\n\t\t\t\t} else {\n\t\t\t\t\t// the zlib filter is the client-visible stream\n\t\t\t\t\tendpointStream = inflateFilter;\n\t\t\t\t}\n\t\t\t\t// this is part of yauzl's API, so implement this function on the client-visible stream\n\t\t\t\tendpointStream.destroy = function () {\n\t\t\t\t\tdestroyed = true;\n\t\t\t\t\tif (inflateFilter !== endpointStream) inflateFilter.unpipe(endpointStream);\n\t\t\t\t\treadStream.unpipe(inflateFilter);\n\t\t\t\t\t// TODO: the inflateFilter may cause a memory leak. see Issue #27.\n\t\t\t\t\treadStream.destroy();\n\t\t\t\t};\n\t\t\t}\n\t\t\tcallback(null, endpointStream);\n\t\t} finally {\n\t\t\tself.reader.unref();\n\t\t}\n\t});\n};\n\nfunction Entry() {\n}\n\nEntry.prototype.getLastModDate = function () {\n\treturn dosDateTimeToDate(this.lastModFileDate, this.lastModFileTime);\n};\nEntry.prototype.isEncrypted = function () {\n\treturn (this.generalPurposeBitFlag & 0x1) !== 0;\n};\nEntry.prototype.isCompressed = function () {\n\treturn this.compressionMethod === 8;\n};\n\nfunction dosDateTimeToDate(date, time) {\n\tvar day = date & 0x1f; // 1-31\n\tvar month = (date >> 5 & 0xf) - 1; // 1-12, 0-11\n\tvar year = (date >> 9 & 0x7f) + 1980; // 0-128, 1980-2108\n\n\tvar millisecond = 0;\n\tvar second = (time & 0x1f) * 2; // 0-29, 0-58 (even numbers)\n\tvar minute = time >> 5 & 0x3f; // 0-59\n\tvar hour = time >> 11 & 0x1f; // 0-23\n\n\treturn new Date(year, month, day, hour, minute, second, millisecond);\n}\n\nfunction validateFileName(fileName) {\n\tif (fileName.indexOf(\"\\\\\") !== -1) {\n\t\treturn \"invalid characters in fileName: \" + fileName;\n\t}\n\tif (/^[a-zA-Z]:/.test(fileName) || /^\\//.test(fileName)) {\n\t\treturn \"absolute path: \" + fileName;\n\t}\n\tif (fileName.split(\"/\").indexOf(\"..\") !== -1) {\n\t\treturn \"invalid relative path: \" + fileName;\n\t}\n\t// all good\n\treturn null;\n}\n\nfunction readAndAssertNoEof(reader, buffer, offset, length, position, callback) {\n\tif (length === 0) {\n\t\t// fs.read will throw an out-of-bounds error if you try to read 0 bytes from a 0 byte file\n\t\treturn setImmediate(function () {\n\t\t\tcallback(null, newBuffer(0));\n\t\t});\n\t}\n\treader.read(buffer, offset, length, position, function (err, bytesRead) {\n\t\tif (err) return callback(err);\n\t\tif (bytesRead < length) {\n\t\t\treturn callback(new Error(\"unexpected EOF\"));\n\t\t}\n\t\tcallback();\n\t});\n}\n\nutil.inherits(AssertByteCountStream, Transform);\n\nfunction AssertByteCountStream(byteCount) {\n\tTransform.call(this);\n\tthis.actualByteCount = 0;\n\tthis.expectedByteCount = byteCount;\n}\n\nAssertByteCountStream.prototype._transform = function (chunk, encoding, cb) {\n\tthis.actualByteCount += chunk.length;\n\tif (this.actualByteCount > this.expectedByteCount) {\n\t\tvar msg = \"too many bytes in the stream. expected \" + this.expectedByteCount + \". got at least \" + this.actualByteCount;\n\t\treturn cb(new Error(msg));\n\t}\n\tcb(null, chunk);\n};\nAssertByteCountStream.prototype._flush = function (cb) {\n\tif (this.actualByteCount < this.expectedByteCount) {\n\t\tvar msg = \"not enough bytes in the stream. expected \" + this.expectedByteCount + \". got only \" + this.actualByteCount;\n\t\treturn cb(new Error(msg));\n\t}\n\tcb();\n};\n\nutil.inherits(RandomAccessReader, EventEmitter);\n\nfunction RandomAccessReader() {\n\tEventEmitter.call(this);\n\tthis.refCount = 0;\n}\n\nRandomAccessReader.prototype.ref = function () {\n\tthis.refCount += 1;\n};\nRandomAccessReader.prototype.unref = function () {\n\tvar self = this;\n\tself.refCount -= 1;\n\n\tif (self.refCount > 0) return;\n\tif (self.refCount < 0) throw new Error(\"invalid unref\");\n\n\tself.close(onCloseDone);\n\n\tfunction onCloseDone(err) {\n\t\tif (err) return self.emit('error', err);\n\t\tself.emit('close');\n\t}\n};\nRandomAccessReader.prototype.createReadStream = function (options) {\n\tvar start = options.start;\n\tvar end = options.end;\n\tif (start === end) {\n\t\tvar emptyStream = new PassThrough();\n\t\tsetImmediate(function () {\n\t\t\temptyStream.end();\n\t\t});\n\t\treturn emptyStream;\n\t}\n\tvar stream = this._readStreamForRange(start, end);\n\n\tvar destroyed = false;\n\tvar refUnrefFilter = new RefUnrefFilter(this);\n\tstream.on(\"error\", function (err) {\n\t\tsetImmediate(function () {\n\t\t\tif (!destroyed) refUnrefFilter.emit(\"error\", err);\n\t\t});\n\t});\n\trefUnrefFilter.destroy = function () {\n\t\tstream.unpipe(refUnrefFilter);\n\t\trefUnrefFilter.unref();\n\t\tstream.destroy();\n\t};\n\n\tvar byteCounter = new AssertByteCountStream(end - start);\n\trefUnrefFilter.on(\"error\", function (err) {\n\t\tsetImmediate(function () {\n\t\t\tif (!destroyed) byteCounter.emit(\"error\", err);\n\t\t});\n\t});\n\tbyteCounter.destroy = function () {\n\t\tdestroyed = true;\n\t\trefUnrefFilter.unpipe(byteCounter);\n\t\trefUnrefFilter.destroy();\n\t};\n\n\treturn stream.pipe(refUnrefFilter).pipe(byteCounter);\n};\nRandomAccessReader.prototype._readStreamForRange = function (start, end) {\n\tthrow new Error(\"not implemented\");\n};\nRandomAccessReader.prototype.read = function (buffer, offset, length, position, callback) {\n\tvar readStream = this.createReadStream({start: position, end: position + length});\n\tvar writeStream = new Writable();\n\tvar written = 0;\n\twriteStream._write = function (chunk, encoding, cb) {\n\t\tchunk.copy(buffer, offset + written, 0, chunk.length);\n\t\twritten += chunk.length;\n\t\tcb();\n\t};\n\twriteStream.on(\"finish\", callback);\n\treadStream.on(\"error\", function (error) {\n\t\tcallback(error);\n\t});\n\treadStream.pipe(writeStream);\n};\nRandomAccessReader.prototype.close = function (callback) {\n\tsetImmediate(callback);\n};\n\nutil.inherits(RefUnrefFilter, PassThrough);\n\nfunction RefUnrefFilter(context) {\n\tPassThrough.call(this);\n\tthis.context = context;\n\tthis.context.ref();\n\tthis.unreffedYet = false;\n}\n\nRefUnrefFilter.prototype._flush = function (cb) {\n\tthis.unref();\n\tcb();\n};\nRefUnrefFilter.prototype.unref = function (cb) {\n\tif (this.unreffedYet) return;\n\tthis.unreffedYet = true;\n\tthis.context.unref();\n};\n\nvar cp437 = '\\u0000☺☻♥♦♣♠•◘○◙♂♀♪♫☼►◄↕‼¶§▬↨↑↓→←∟↔▲▼ !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~⌂ÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜ¢£¥₧ƒáíóúñÑªº¿⌐¬½¼¡«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ ';\n\nfunction decodeBuffer(buffer, start, end, isUtf8) {\n\tif (isUtf8) {\n\t\treturn buffer.toString(\"utf8\", start, end);\n\t} else {\n\t\tvar result = \"\";\n\t\tfor (var i = start; i < end; i++) {\n\t\t\tresult += cp437[buffer[i]];\n\t\t}\n\t\treturn result;\n\t}\n}\n\nfunction readUInt64LE(buffer, offset) {\n\t// there is no native function for this, because we can't actually store 64-bit integers precisely.\n\t// after 53 bits, JavaScript's Number type (IEEE 754 double) can't store individual integers anymore.\n\t// but since 53 bits is a whole lot more than 32 bits, we do our best anyway.\n\tvar lower32 = buffer.readUInt32LE(offset);\n\tvar upper32 = buffer.readUInt32LE(offset + 4);\n\t// we can't use bitshifting here, because JavaScript bitshifting only works on 32-bit integers.\n\treturn upper32 * 0x100000000 + lower32;\n\t// as long as we're bounds checking the result of this function against the total file size,\n\t// we'll catch any overflow errors, because we already made sure the total file size was within reason.\n}\n\n// Node 10 deprecated new Buffer().\nvar newBuffer;\nif (typeof Buffer.allocUnsafe === \"function\") {\n\tnewBuffer = function (len) {\n\t\treturn Buffer.allocUnsafe(len);\n\t};\n} else {\n\tnewBuffer = function (len) {\n\t\treturn new Buffer(len);\n\t};\n}\n\nfunction defaultCallback(err) {\n\tif (err) throw err;\n}\n","var fs = require(\"fs\");\nvar Transform = require(\"stream\").Transform;\nvar PassThrough = require(\"stream\").PassThrough;\nvar zlib = require(\"zlib\");\nvar util = require(\"util\");\nvar EventEmitter = require(\"events\").EventEmitter;\nvar crc32 = require(\"buffer-crc32\");\n\nexports.ZipFile = ZipFile;\nexports.dateToDosDateTime = dateToDosDateTime;\n\nutil.inherits(ZipFile, EventEmitter);\n\nfunction ZipFile() {\n\tthis.outputStream = new PassThrough();\n\tthis.entries = [];\n\tthis.outputStreamCursor = 0;\n\tthis.ended = false; // .end() sets this\n\tthis.allDone = false; // set when we've written the last bytes\n\tthis.forceZip64Eocd = false; // configurable in .end()\n}\n\nZipFile.prototype.addFile = function (realPath, metadataPath, options) {\n\tvar self = this;\n\tmetadataPath = validateMetadataPath(metadataPath, false);\n\tif (options == null) options = {};\n\n\tvar entry = new Entry(metadataPath, false, options);\n\tself.entries.push(entry);\n\tfs.stat(realPath, function (err, stats) {\n\t\tif (err) return self.emit(\"error\", err);\n\t\tif (!stats.isFile()) return self.emit(\"error\", new Error(\"not a file: \" + realPath));\n\t\tentry.uncompressedSize = stats.size;\n\t\tif (options.mtime == null) entry.setLastModDate(stats.mtime);\n\t\tif (options.mode == null) entry.setFileAttributesMode(stats.mode);\n\t\tentry.setFileDataPumpFunction(function () {\n\t\t\tvar readStream = fs.createReadStream(realPath);\n\t\t\tentry.state = Entry.FILE_DATA_IN_PROGRESS;\n\t\t\treadStream.on(\"error\", function (err) {\n\t\t\t\tself.emit(\"error\", err);\n\t\t\t});\n\t\t\tpumpFileDataReadStream(self, entry, readStream);\n\t\t});\n\t\tpumpEntries(self);\n\t});\n};\n\nZipFile.prototype.addReadStream = function (readStream, metadataPath, options) {\n\tvar self = this;\n\tmetadataPath = validateMetadataPath(metadataPath, false);\n\tif (options == null) options = {};\n\tvar entry = new Entry(metadataPath, false, options);\n\tself.entries.push(entry);\n\tentry.setFileDataPumpFunction(function () {\n\t\tentry.state = Entry.FILE_DATA_IN_PROGRESS;\n\t\tpumpFileDataReadStream(self, entry, readStream);\n\t});\n\tpumpEntries(self);\n};\n\nZipFile.prototype.addBuffer = function (buffer, metadataPath, options) {\n\tvar self = this;\n\tmetadataPath = validateMetadataPath(metadataPath, false);\n\tif (buffer.length > 0x3fffffff) throw new Error(\"buffer too large: \" + buffer.length + \" > \" + 0x3fffffff);\n\tif (options == null) options = {};\n\tif (options.size != null) throw new Error(\"options.size not allowed\");\n\tvar entry = new Entry(metadataPath, false, options);\n\tentry.uncompressedSize = buffer.length;\n\tentry.crc32 = crc32.unsigned(buffer);\n\tentry.crcAndFileSizeKnown = true;\n\tself.entries.push(entry);\n\tif (!entry.compress) {\n\t\tsetCompressedBuffer(buffer);\n\t} else {\n\t\tzlib.deflateRaw(buffer, function (err, compressedBuffer) {\n\t\t\tsetCompressedBuffer(compressedBuffer);\n\t\t\t\n\t\t});\n\t}\n\n\tfunction setCompressedBuffer(compressedBuffer) {\n\t\tentry.compressedSize = compressedBuffer.length;\n\t\tentry.setFileDataPumpFunction(function () {\n\t\t\twriteToOutputStream(self, compressedBuffer);\n\t\t\twriteToOutputStream(self, entry.getDataDescriptor());\n\t\t\tentry.state = Entry.FILE_DATA_DONE;\n\n\t\t\t// don't call pumpEntries() recursively.\n\t\t\t// (also, don't call process.nextTick recursively.)\n\t\t\tsetImmediate(function () {\n\t\t\t\tpumpEntries(self);\n\t\t\t});\n\t\t});\n\t\tpumpEntries(self);\n\t}\n};\n\n\nZipFile.prototype.addEmptyDirectory = function (metadataPath, options) {\n\tvar self = this;\n\tmetadataPath = validateMetadataPath(metadataPath, true);\n\tif (options == null) options = {};\n\tif (options.size != null) throw new Error(\"options.size not allowed\");\n\tif (options.compress != null) throw new Error(\"options.compress not allowed\");\n\tvar entry = new Entry(metadataPath, true, options);\n\tself.entries.push(entry);\n\tentry.setFileDataPumpFunction(function () {\n\t\twriteToOutputStream(self, entry.getDataDescriptor());\n\t\tentry.state = Entry.FILE_DATA_DONE;\n\t\tpumpEntries(self);\n\t});\n\tpumpEntries(self);\n};\n\nZipFile.prototype.end = function (options, finalSizeCallback) {\n\tif (typeof options === \"function\") {\n\t\tfinalSizeCallback = options;\n\t\toptions = null;\n\t}\n\tif (options == null) options = {};\n\tif (this.ended) return;\n\tthis.ended = true;\n\tthis.finalSizeCallback = finalSizeCallback;\n\tthis.forceZip64Eocd = !!options.forceZip64Format;\n\tpumpEntries(this);\n};\n\nfunction writeToOutputStream(self, buffer) {\n\tself.outputStream.write(buffer);\n\tself.outputStreamCursor += buffer.length;\n}\n\nfunction pumpFileDataReadStream(self, entry, readStream) {\n\tvar crc32Watcher = new Crc32Watcher();\n\tvar uncompressedSizeCounter = new ByteCounter();\n\tvar compressor = entry.compress ? new zlib.DeflateRaw() : new PassThrough();\n\tvar compressedSizeCounter = new ByteCounter();\n\treadStream.pipe(crc32Watcher)\n\t\t.pipe(uncompressedSizeCounter)\n\t\t.pipe(compressor)\n\t\t.pipe(compressedSizeCounter)\n\t\t.pipe(self.outputStream, {end: false});\n\tcompressedSizeCounter.on(\"end\", function () {\n\t\tentry.crc32 = crc32Watcher.crc32;\n\t\tif (entry.uncompressedSize == null) {\n\t\t\tentry.uncompressedSize = uncompressedSizeCounter.byteCount;\n\t\t} else {\n\t\t\tif (entry.uncompressedSize !== uncompressedSizeCounter.byteCount) return self.emit(\"error\", new Error(\"file data stream has unexpected number of bytes\"));\n\t\t}\n\t\tentry.compressedSize = compressedSizeCounter.byteCount;\n\t\tself.outputStreamCursor += entry.compressedSize;\n\t\twriteToOutputStream(self, entry.getDataDescriptor());\n\t\tentry.state = Entry.FILE_DATA_DONE;\n\t\tpumpEntries(self);\n\t});\n}\n\nfunction pumpEntries(self) {\n\tif (self.allDone) return;\n\t// first check if finalSize is finally known\n\tif (self.ended && self.finalSizeCallback != null) {\n\t\tvar finalSize = calculateFinalSize(self);\n\t\tif (finalSize != null) {\n\t\t\t// we have an answer\n\t\t\tself.finalSizeCallback(finalSize);\n\t\t\tself.finalSizeCallback = null;\n\t\t}\n\t}\n\n\t// pump entries\n\tvar entry = getFirstNotDoneEntry();\n\n\tfunction getFirstNotDoneEntry() {\n\t\tfor (var i = 0; i < self.entries.length; i++) {\n\t\t\tvar entry = self.entries[i];\n\t\t\tif (entry.state < Entry.FILE_DATA_DONE) return entry;\n\t\t}\n\t\treturn null;\n\t}\n\n\tif (entry != null) {\n\t\t// this entry is not done yet\n\t\tif (entry.state < Entry.READY_TO_PUMP_FILE_DATA) return; // input file not open yet\n\t\tif (entry.state === Entry.FILE_DATA_IN_PROGRESS) return; // we'll get there\n\t\t// start with local file header\n\t\tentry.relativeOffsetOfLocalHeader = self.outputStreamCursor;\n\t\tvar localFileHeader = entry.getLocalFileHeader();\n\t\twriteToOutputStream(self, localFileHeader);\n\t\tentry.doFileDataPump();\n\t} else {\n\t\t// all cought up on writing entries\n\t\tif (self.ended) {\n\t\t\t// head for the exit\n\t\t\tself.offsetOfStartOfCentralDirectory = self.outputStreamCursor;\n\t\t\tself.entries.forEach(function (entry) {\n\t\t\t\tvar centralDirectoryRecord = entry.getCentralDirectoryRecord();\n\t\t\t\twriteToOutputStream(self, centralDirectoryRecord);\n\t\t\t});\n\t\t\twriteToOutputStream(self, getEndOfCentralDirectoryRecord(self));\n\t\t\tself.outputStream.end();\n\t\t\tself.allDone = true;\n\t\t}\n\t}\n}\n\nfunction calculateFinalSize(self) {\n\tvar pretendOutputCursor = 0;\n\tvar centralDirectorySize = 0;\n\tfor (var i = 0; i < self.entries.length; i++) {\n\t\tvar entry = self.entries[i];\n\t\t// compression is too hard to predict\n\t\tif (entry.compress) return -1;\n\t\tif (entry.state >= Entry.READY_TO_PUMP_FILE_DATA) {\n\t\t\t// if addReadStream was called without providing the size, we can't predict the final size\n\t\t\tif (entry.uncompressedSize == null) return -1;\n\t\t} else {\n\t\t\t// if we're still waiting for fs.stat, we might learn the size someday\n\t\t\tif (entry.uncompressedSize == null) return null;\n\t\t}\n\t\t// we know this for sure, and this is important to know if we need ZIP64 format.\n\t\tentry.relativeOffsetOfLocalHeader = pretendOutputCursor;\n\t\tvar useZip64Format = entry.useZip64Format();\n\n\t\tpretendOutputCursor += LOCAL_FILE_HEADER_FIXED_SIZE + entry.utf8FileName.length;\n\t\tpretendOutputCursor += entry.uncompressedSize;\n\t\tif (!entry.crcAndFileSizeKnown) {\n\t\t\t// use a data descriptor\n\t\t\tif (useZip64Format) {\n\t\t\t\tpretendOutputCursor += ZIP64_DATA_DESCRIPTOR_SIZE;\n\t\t\t} else {\n\t\t\t\tpretendOutputCursor += DATA_DESCRIPTOR_SIZE;\n\t\t\t}\n\t\t}\n\n\t\tcentralDirectorySize += CENTRAL_DIRECTORY_RECORD_FIXED_SIZE + entry.utf8FileName.length;\n\t\tif (useZip64Format) {\n\t\t\tcentralDirectorySize += ZIP64_EXTENDED_INFORMATION_EXTRA_FIELD_SIZE;\n\t\t}\n\t}\n\n\tvar endOfCentralDirectorySize = 0;\n\tif (self.forceZip64Eocd ||\n\t\tself.entries.length >= 0xffff ||\n\t\tcentralDirectorySize >= 0xffff ||\n\t\tpretendOutputCursor >= 0xffffffff) {\n\t\t// use zip64 end of central directory stuff\n\t\tendOfCentralDirectorySize += ZIP64_END_OF_CENTRAL_DIRECTORY_RECORD_SIZE + ZIP64_END_OF_CENTRAL_DIRECTORY_LOCATOR_SIZE;\n\t}\n\tendOfCentralDirectorySize += END_OF_CENTRAL_DIRECTORY_RECORD_SIZE;\n\treturn pretendOutputCursor + centralDirectorySize + endOfCentralDirectorySize;\n}\n\nvar ZIP64_END_OF_CENTRAL_DIRECTORY_RECORD_SIZE = 56;\nvar ZIP64_END_OF_CENTRAL_DIRECTORY_LOCATOR_SIZE = 20;\nvar END_OF_CENTRAL_DIRECTORY_RECORD_SIZE = 22;\n\nfunction getEndOfCentralDirectoryRecord(self, actuallyJustTellMeHowLongItWouldBe) {\n\tvar needZip64Format = false;\n\tvar normalEntriesLength = self.entries.length;\n\tif (self.forceZip64Eocd || self.entries.length >= 0xffff) {\n\t\tnormalEntriesLength = 0xffff;\n\t\tneedZip64Format = true;\n\t}\n\tvar sizeOfCentralDirectory = self.outputStreamCursor - self.offsetOfStartOfCentralDirectory;\n\tvar normalSizeOfCentralDirectory = sizeOfCentralDirectory;\n\tif (self.forceZip64Eocd || sizeOfCentralDirectory >= 0xffffffff) {\n\t\tnormalSizeOfCentralDirectory = 0xffffffff;\n\t\tneedZip64Format = true;\n\t}\n\tvar normalOffsetOfStartOfCentralDirectory = self.offsetOfStartOfCentralDirectory;\n\tif (self.forceZip64Eocd || self.offsetOfStartOfCentralDirectory >= 0xffffffff) {\n\t\tnormalOffsetOfStartOfCentralDirectory = 0xffffffff;\n\t\tneedZip64Format = true;\n\t}\n\tif (actuallyJustTellMeHowLongItWouldBe) {\n\t\tif (needZip64Format) {\n\t\t\treturn (\n\t\t\t\tZIP64_END_OF_CENTRAL_DIRECTORY_RECORD_SIZE +\n\t\t\t\tZIP64_END_OF_CENTRAL_DIRECTORY_LOCATOR_SIZE +\n\t\t\t\tEND_OF_CENTRAL_DIRECTORY_RECORD_SIZE\n\t\t\t);\n\t\t} else {\n\t\t\treturn END_OF_CENTRAL_DIRECTORY_RECORD_SIZE;\n\t\t}\n\t}\n\n\tvar eocdrBuffer = new Buffer(END_OF_CENTRAL_DIRECTORY_RECORD_SIZE);\n\t// end of central dir signature                       4 bytes  (0x06054b50)\n\teocdrBuffer.writeUInt32LE(0x06054b50, 0);\n\t// number of this disk                                2 bytes\n\teocdrBuffer.writeUInt16LE(0, 4);\n\t// number of the disk with the start of the central directory  2 bytes\n\teocdrBuffer.writeUInt16LE(0, 6);\n\t// total number of entries in the central directory on this disk  2 bytes\n\teocdrBuffer.writeUInt16LE(normalEntriesLength, 8);\n\t// total number of entries in the central directory   2 bytes\n\teocdrBuffer.writeUInt16LE(normalEntriesLength, 10);\n\t// size of the central directory                      4 bytes\n\teocdrBuffer.writeUInt32LE(normalSizeOfCentralDirectory, 12);\n\t// offset of start of central directory with respect to the starting disk number  4 bytes\n\teocdrBuffer.writeUInt32LE(normalOffsetOfStartOfCentralDirectory, 16);\n\t// .ZIP file comment length                           2 bytes\n\teocdrBuffer.writeUInt16LE(0, 20);\n\t// .ZIP file comment                                  (variable size)\n\t// no comment\n\n\tif (!needZip64Format) return eocdrBuffer;\n\n\t// ZIP64 format\n\t// ZIP64 End of Central Directory Record\n\tvar zip64EocdrBuffer = new Buffer(ZIP64_END_OF_CENTRAL_DIRECTORY_RECORD_SIZE);\n\t// zip64 end of central dir signature                                             4 bytes  (0x06064b50)\n\tzip64EocdrBuffer.writeUInt32LE(0x06064b50, 0);\n\t// size of zip64 end of central directory record                                  8 bytes\n\twriteUInt64LE(zip64EocdrBuffer, ZIP64_END_OF_CENTRAL_DIRECTORY_RECORD_SIZE - 12, 4);\n\t// version made by                                                                2 bytes\n\tzip64EocdrBuffer.writeUInt16LE(VERSION_MADE_BY, 12);\n\t// version needed to extract                                                      2 bytes\n\tzip64EocdrBuffer.writeUInt16LE(VERSION_NEEDED_TO_EXTRACT_ZIP64, 14);\n\t// number of this disk                                                            4 bytes\n\tzip64EocdrBuffer.writeUInt32LE(0, 16);\n\t// number of the disk with the start of the central directory                     4 bytes\n\tzip64EocdrBuffer.writeUInt32LE(0, 20);\n\t// total number of entries in the central directory on this disk                  8 bytes\n\twriteUInt64LE(zip64EocdrBuffer, self.entries.length, 24);\n\t// total number of entries in the central directory                               8 bytes\n\twriteUInt64LE(zip64EocdrBuffer, self.entries.length, 32);\n\t// size of the central directory                                                  8 bytes\n\twriteUInt64LE(zip64EocdrBuffer, sizeOfCentralDirectory, 40);\n\t// offset of start of central directory with respect to the starting disk number  8 bytes\n\twriteUInt64LE(zip64EocdrBuffer, self.offsetOfStartOfCentralDirectory, 48);\n\t// zip64 extensible data sector                                                   (variable size)\n\t// nothing in the zip64 extensible data sector\n\n\n\t// ZIP64 End of Central Directory Locator\n\tvar zip64EocdlBuffer = new Buffer(ZIP64_END_OF_CENTRAL_DIRECTORY_LOCATOR_SIZE);\n\t// zip64 end of central dir locator signature                               4 bytes  (0x07064b50)\n\tzip64EocdlBuffer.writeUInt32LE(0x07064b50, 0);\n\t// number of the disk with the start of the zip64 end of central directory  4 bytes\n\tzip64EocdlBuffer.writeUInt32LE(0, 4);\n\t// relative offset of the zip64 end of central directory record             8 bytes\n\twriteUInt64LE(zip64EocdlBuffer, self.outputStreamCursor, 8);\n\t// total number of disks                                                    4 bytes\n\tzip64EocdlBuffer.writeUInt32LE(1, 16);\n\n\n\treturn Buffer.concat([\n\t\tzip64EocdrBuffer,\n\t\tzip64EocdlBuffer,\n\t\teocdrBuffer,\n\t]);\n}\n\nfunction validateMetadataPath(metadataPath, isDirectory) {\n\tif (metadataPath === \"\") throw new Error(\"empty metadataPath\");\n\tmetadataPath = metadataPath.replace(/\\\\/g, \"/\");\n\tif (/^[a-zA-Z]:/.test(metadataPath) || /^\\//.test(metadataPath)) throw new Error(\"absolute path: \" + metadataPath);\n\tif (metadataPath.split(\"/\").indexOf(\"..\") !== -1) throw new Error(\"invalid relative path: \" + metadataPath);\n\tvar looksLikeDirectory = /\\/$/.test(metadataPath);\n\tif (isDirectory) {\n\t\t// append a trailing '/' if necessary.\n\t\tif (!looksLikeDirectory) metadataPath += \"/\";\n\t} else {\n\t\tif (looksLikeDirectory) throw new Error(\"file path cannot end with '/': \" + metadataPath);\n\t}\n\treturn metadataPath;\n}\n\nvar defaultFileMode = parseInt(\"0100664\", 8);\nvar defaultDirectoryMode = parseInt(\"040775\", 8);\n\n// this class is not part of the public API\nfunction Entry(metadataPath, isDirectory, options) {\n\tthis.utf8FileName = new Buffer(metadataPath);\n\tif (this.utf8FileName.length > 0xffff) throw new Error(\"utf8 file name too long. \" + utf8FileName.length + \" > \" + 0xffff);\n\tthis.isDirectory = isDirectory;\n\tthis.state = Entry.WAITING_FOR_METADATA;\n\tthis.setLastModDate(options.mtime != null ? options.mtime : new Date());\n\tif (options.mode != null) {\n\t\tthis.setFileAttributesMode(options.mode);\n\t} else {\n\t\tthis.setFileAttributesMode(isDirectory ? defaultDirectoryMode : defaultFileMode);\n\t}\n\tif (isDirectory) {\n\t\tthis.crcAndFileSizeKnown = true;\n\t\tthis.crc32 = 0;\n\t\tthis.uncompressedSize = 0;\n\t\tthis.compressedSize = 0;\n\t} else {\n\t\t// unknown so far\n\t\tthis.crcAndFileSizeKnown = false;\n\t\tthis.crc32 = null;\n\t\tthis.uncompressedSize = null;\n\t\tthis.compressedSize = null;\n\t\tif (options.size != null) this.uncompressedSize = options.size;\n\t}\n\tif (isDirectory) {\n\t\tthis.compress = false;\n\t} else {\n\t\tthis.compress = true; // default\n\t\tif (options.compress != null) this.compress = !!options.compress;\n\t}\n\tthis.forceZip64Format = !!options.forceZip64Format;\n}\n\nEntry.WAITING_FOR_METADATA = 0;\nEntry.READY_TO_PUMP_FILE_DATA = 1;\nEntry.FILE_DATA_IN_PROGRESS = 2;\nEntry.FILE_DATA_DONE = 3;\nEntry.prototype.setLastModDate = function (date) {\n\tvar dosDateTime = dateToDosDateTime(date);\n\tthis.lastModFileTime = dosDateTime.time;\n\tthis.lastModFileDate = dosDateTime.date;\n};\nEntry.prototype.setFileAttributesMode = function (mode) {\n\tif ((mode & 0xffff) !== mode) throw new Error(\"invalid mode. expected: 0 <= \" + mode + \" <= \" + 0xffff);\n\t// http://unix.stackexchange.com/questions/14705/the-zip-formats-external-file-attribute/14727#14727\n\tthis.externalFileAttributes = (mode << 16) >>> 0;\n};\n// doFileDataPump() should not call pumpEntries() directly. see issue #9.\nEntry.prototype.setFileDataPumpFunction = function (doFileDataPump) {\n\tthis.doFileDataPump = doFileDataPump;\n\tthis.state = Entry.READY_TO_PUMP_FILE_DATA;\n};\nEntry.prototype.useZip64Format = function () {\n\treturn (\n\t\t(this.forceZip64Format) ||\n\t\t(this.uncompressedSize != null && this.uncompressedSize > 0xfffffffe) ||\n\t\t(this.compressedSize != null && this.compressedSize > 0xfffffffe) ||\n\t\t(this.relativeOffsetOfLocalHeader != null && this.relativeOffsetOfLocalHeader > 0xfffffffe)\n\t);\n}\nvar LOCAL_FILE_HEADER_FIXED_SIZE = 30;\nvar VERSION_NEEDED_TO_EXTRACT_UTF8 = 20;\nvar VERSION_NEEDED_TO_EXTRACT_ZIP64 = 45;\n// 3 = unix. 63 = spec version 6.3\nvar VERSION_MADE_BY = (3 << 8) | 63;\nvar FILE_NAME_IS_UTF8 = 1 << 11;\nvar UNKNOWN_CRC32_AND_FILE_SIZES = 1 << 3;\nEntry.prototype.getLocalFileHeader = function () {\n\tvar crc32 = 0;\n\tvar compressedSize = 0;\n\tvar uncompressedSize = 0;\n\tif (this.crcAndFileSizeKnown) {\n\t\tcrc32 = this.crc32;\n\t\tcompressedSize = this.compressedSize;\n\t\tuncompressedSize = this.uncompressedSize;\n\t}\n\n\tvar fixedSizeStuff = new Buffer(LOCAL_FILE_HEADER_FIXED_SIZE);\n\tvar generalPurposeBitFlag = FILE_NAME_IS_UTF8;\n\tif (!this.crcAndFileSizeKnown) generalPurposeBitFlag |= UNKNOWN_CRC32_AND_FILE_SIZES;\n\n\t// local file header signature     4 bytes  (0x04034b50)\n\tfixedSizeStuff.writeUInt32LE(0x04034b50, 0);\n\t// version needed to extract       2 bytes\n\tfixedSizeStuff.writeUInt16LE(VERSION_NEEDED_TO_EXTRACT_UTF8, 4);\n\t// general purpose bit flag        2 bytes\n\tfixedSizeStuff.writeUInt16LE(generalPurposeBitFlag, 6);\n\t// compression method              2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.getCompressionMethod(), 8);\n\t// last mod file time              2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.lastModFileTime, 10);\n\t// last mod file date              2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.lastModFileDate, 12);\n\t// crc-32                          4 bytes\n\tfixedSizeStuff.writeUInt32LE(crc32, 14);\n\t// compressed size                 4 bytes\n\tfixedSizeStuff.writeUInt32LE(compressedSize, 18);\n\t// uncompressed size               4 bytes\n\tfixedSizeStuff.writeUInt32LE(uncompressedSize, 22);\n\t// file name length                2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.utf8FileName.length, 26);\n\t// extra field length              2 bytes\n\tfixedSizeStuff.writeUInt16LE(0, 28);\n\treturn Buffer.concat([\n\t\tfixedSizeStuff,\n\t\t// file name (variable size)\n\t\tthis.utf8FileName,\n\t\t// extra field (variable size)\n\t\t// no extra fields\n\t]);\n};\nvar DATA_DESCRIPTOR_SIZE = 16;\nvar ZIP64_DATA_DESCRIPTOR_SIZE = 24;\nEntry.prototype.getDataDescriptor = function () {\n\tif (this.crcAndFileSizeKnown) {\n\t\t// the Mac Archive Utility requires this not be present unless we set general purpose bit 3\n\t\treturn new Buffer(0);\n\t}\n\tif (!this.useZip64Format()) {\n\t\tvar buffer = new Buffer(DATA_DESCRIPTOR_SIZE);\n\t\t// optional signature (required according to Archive Utility)\n\t\tbuffer.writeUInt32LE(0x08074b50, 0);\n\t\t// crc-32                          4 bytes\n\t\tbuffer.writeUInt32LE(this.crc32, 4);\n\t\t// compressed size                 4 bytes\n\t\tbuffer.writeUInt32LE(this.compressedSize, 8);\n\t\t// uncompressed size               4 bytes\n\t\tbuffer.writeUInt32LE(this.uncompressedSize, 12);\n\t\treturn buffer;\n\t} else {\n\t\t// ZIP64 format\n\t\tvar buffer = new Buffer(ZIP64_DATA_DESCRIPTOR_SIZE);\n\t\t// optional signature (unknown if anyone cares about this)\n\t\tbuffer.writeUInt32LE(0x08074b50, 0);\n\t\t// crc-32                          4 bytes\n\t\tbuffer.writeUInt32LE(this.crc32, 4);\n\t\t// compressed size                 8 bytes\n\t\twriteUInt64LE(buffer, this.compressedSize, 8);\n\t\t// uncompressed size               8 bytes\n\t\twriteUInt64LE(buffer, this.uncompressedSize, 16);\n\t\treturn buffer;\n\t}\n};\nvar CENTRAL_DIRECTORY_RECORD_FIXED_SIZE = 46;\nvar ZIP64_EXTENDED_INFORMATION_EXTRA_FIELD_SIZE = 28;\nEntry.prototype.getCentralDirectoryRecord = function () {\n\tvar fixedSizeStuff = new Buffer(CENTRAL_DIRECTORY_RECORD_FIXED_SIZE);\n\tvar generalPurposeBitFlag = FILE_NAME_IS_UTF8;\n\tif (!this.crcAndFileSizeKnown) generalPurposeBitFlag |= UNKNOWN_CRC32_AND_FILE_SIZES;\n\n\tvar normalCompressedSize = this.compressedSize;\n\tvar normalUncompressedSize = this.uncompressedSize;\n\tvar normalRelativeOffsetOfLocalHeader = this.relativeOffsetOfLocalHeader;\n\tvar versionNeededToExtract;\n\tvar zeiefBuffer;\n\tif (this.useZip64Format()) {\n\t\tnormalCompressedSize = 0xffffffff;\n\t\tnormalUncompressedSize = 0xffffffff;\n\t\tnormalRelativeOffsetOfLocalHeader = 0xffffffff;\n\t\tversionNeededToExtract = VERSION_NEEDED_TO_EXTRACT_ZIP64;\n\n\t\t// ZIP64 extended information extra field\n\t\tzeiefBuffer = new Buffer(ZIP64_EXTENDED_INFORMATION_EXTRA_FIELD_SIZE);\n\t\t// 0x0001                  2 bytes    Tag for this \"extra\" block type\n\t\tzeiefBuffer.writeUInt16LE(0x0001, 0);\n\t\t// Size                    2 bytes    Size of this \"extra\" block\n\t\tzeiefBuffer.writeUInt16LE(ZIP64_EXTENDED_INFORMATION_EXTRA_FIELD_SIZE - 4, 2);\n\t\t// Original Size           8 bytes    Original uncompressed file size\n\t\twriteUInt64LE(zeiefBuffer, this.uncompressedSize, 4);\n\t\t// Compressed Size         8 bytes    Size of compressed data\n\t\twriteUInt64LE(zeiefBuffer, this.compressedSize, 12);\n\t\t// Relative Header Offset  8 bytes    Offset of local header record\n\t\twriteUInt64LE(zeiefBuffer, this.relativeOffsetOfLocalHeader, 20);\n\t\t// Disk Start Number       4 bytes    Number of the disk on which this file starts\n\t\t// (omit)\n\t} else {\n\t\tversionNeededToExtract = VERSION_NEEDED_TO_EXTRACT_UTF8;\n\t\tzeiefBuffer = new Buffer(0);\n\t}\n\n\t// central file header signature   4 bytes  (0x02014b50)\n\tfixedSizeStuff.writeUInt32LE(0x02014b50, 0);\n\t// version made by                 2 bytes\n\tfixedSizeStuff.writeUInt16LE(VERSION_MADE_BY, 4);\n\t// version needed to extract       2 bytes\n\tfixedSizeStuff.writeUInt16LE(versionNeededToExtract, 6);\n\t// general purpose bit flag        2 bytes\n\tfixedSizeStuff.writeUInt16LE(generalPurposeBitFlag, 8);\n\t// compression method              2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.getCompressionMethod(), 10);\n\t// last mod file time              2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.lastModFileTime, 12);\n\t// last mod file date              2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.lastModFileDate, 14);\n\t// crc-32                          4 bytes\n\tfixedSizeStuff.writeUInt32LE(this.crc32, 16);\n\t// compressed size                 4 bytes\n\tfixedSizeStuff.writeUInt32LE(normalCompressedSize, 20);\n\t// uncompressed size               4 bytes\n\tfixedSizeStuff.writeUInt32LE(normalUncompressedSize, 24);\n\t// file name length                2 bytes\n\tfixedSizeStuff.writeUInt16LE(this.utf8FileName.length, 28);\n\t// extra field length              2 bytes\n\tfixedSizeStuff.writeUInt16LE(zeiefBuffer.length, 30);\n\t// file comment length             2 bytes\n\tfixedSizeStuff.writeUInt16LE(0, 32);\n\t// disk number start               2 bytes\n\tfixedSizeStuff.writeUInt16LE(0, 34);\n\t// internal file attributes        2 bytes\n\tfixedSizeStuff.writeUInt16LE(0, 36);\n\t// external file attributes        4 bytes\n\tfixedSizeStuff.writeUInt32LE(this.externalFileAttributes, 38);\n\t// relative offset of local header 4 bytes\n\tfixedSizeStuff.writeUInt32LE(normalRelativeOffsetOfLocalHeader, 42);\n\n\treturn Buffer.concat([\n\t\tfixedSizeStuff,\n\t\t// file name (variable size)\n\t\tthis.utf8FileName,\n\t\t// extra field (variable size)\n\t\tzeiefBuffer,\n\t\t// file comment (variable size)\n\t\t// empty comment\n\t]);\n};\nEntry.prototype.getCompressionMethod = function () {\n\tvar NO_COMPRESSION = 0;\n\tvar DEFLATE_COMPRESSION = 8;\n\treturn this.compress ? DEFLATE_COMPRESSION : NO_COMPRESSION;\n};\n\nfunction dateToDosDateTime(jsDate) {\n\tvar date = 0;\n\tdate |= jsDate.getDate() & 0x1f; // 1-31\n\tdate |= ((jsDate.getMonth() + 1) & 0xf) << 5; // 0-11, 1-12\n\tdate |= ((jsDate.getFullYear() - 1980) & 0x7f) << 9; // 0-128, 1980-2108\n\n\tvar time = 0;\n\ttime |= Math.floor(jsDate.getSeconds() / 2); // 0-59, 0-29 (lose odd numbers)\n\ttime |= (jsDate.getMinutes() & 0x3f) << 5; // 0-59\n\ttime |= (jsDate.getHours() & 0x1f) << 11; // 0-23\n\n\treturn {date: date, time: time};\n}\n\nfunction writeUInt64LE(buffer, n, offset) {\n\t// can't use bitshift here, because JavaScript only allows bitshiting on 32-bit integers.\n\tvar high = Math.floor(n / 0x100000000);\n\tvar low = n % 0x100000000;\n\tbuffer.writeUInt32LE(low, offset);\n\tbuffer.writeUInt32LE(high, offset + 4);\n}\n\nfunction defaultCallback(err) {\n\tif (err) throw err;\n}\n\nutil.inherits(ByteCounter, Transform);\n\nfunction ByteCounter(options) {\n\tTransform.call(this, options);\n\tthis.byteCount = 0;\n}\n\nByteCounter.prototype._transform = function (chunk, encoding, cb) {\n\tthis.byteCount += chunk.length;\n\tcb(null, chunk);\n};\n\nutil.inherits(Crc32Watcher, Transform);\n\nfunction Crc32Watcher(options) {\n\tTransform.call(this, options);\n\tthis.crc32 = 0;\n}\n\nCrc32Watcher.prototype._transform = function (chunk, encoding, cb) {\n\tthis.crc32 = crc32.unsigned(chunk, this.crc32);\n\tcb(null, chunk);\n};","const defaultForwardAddress = process.env.vmq_zeromq_forward_address || \"tcp://127.0.0.1:5001\";\nconst defaultSubAddress = process.env.vmq_zeromq_sub_address || \"tcp://127.0.0.1:5000\";\nconst defaultPubAddress = process.env.vmq_zeromq_pub_address || \"tcp://127.0.0.1:5001\";\n\nlet zmq = require(\"zeromq\");\n\nfunction registerKiller(children){\n    const events = [\"SIGINT\", \"SIGUSR1\", \"SIGUSR2\", \"uncaughtException\", \"SIGTERM\", \"SIGHUP\"];\n\n    events.forEach(function(event){\n        process.on(event, function(...args){\n            children.forEach(function(child){\n                console.log(\"Something bad happened.\", event, ...args);\n                try{\n                    child.close();\n                }catch(err){\n                    //..\n                    console.log(err);\n                }\n            });\n        });\n    });\n}\n\nfunction ZeromqForwarder(bindAddress){\n\n    let socket = zmq.socket(\"pub\");\n    let initialized = false;\n\n    function connect(){\n        socket.monitor();\n        socket.connect(bindAddress);\n\n        socket.on(\"connect\",(fd)=>{\n            console.log(`[Forwarder] connected on ${bindAddress}`);\n            initialized = true;\n            sendBuffered();\n        });\n    }\n\n    connect();\n\n    registerKiller([socket]);\n\n    const Queue = require(\"swarmutils\").Queue;\n    let buffered = new Queue();\n\n    let sendBuffered = ()=>{\n        while(buffered.length>0){\n            this.send(...buffered.pop());\n        }\n    };\n\n    this.send = function(channel, ...args){\n        if(initialized){\n            //console.log(\"[Forwarder] Putting message on socket\", args);\n            socket.send([channel, ...args], undefined, (...args)=>{\n                //console.log(\"[Forwarder] message sent\");\n            });\n        }else{\n            //console.log(\"[Forwarder] Saving it for later\");\n            buffered.push([channel, ...args]);\n        }\n    }\n}\n\nfunction ZeromqProxyNode(subAddress, pubAddress, signatureChecker){\n\n    const publishersNode = zmq.createSocket('xsub');\n    const subscribersNode = zmq.createSocket('xpub');\n\n    // By default xpub only signals new subscriptions\n    // Settings it to verbose = 1 , will signal on every new subscribe\n    // uncomment next lines if messages are lost\n    subscribersNode.setsockopt(zmq.ZMQ_XPUB_VERBOSE, 1);\n\n    publishersNode.on('message', deliverMessage);\n\n    function deliverMessage(channel, message){\n        //console.log(`[Proxy] - Received message on channel ${channel.toString()}`);\n        let ch = channelTranslationDictionary[channel.toString()];\n        if(ch){\n            //console.log(\"[Proxy] - Sending message on channel\", ch);\n            subscribersNode.send([Buffer.from(ch), message]);\n        }else{\n            //console.log(`[Proxy] - message dropped!`);\n        }\n        //subscribersNode.send([channel, message]);\n    }\n\n    let channelTranslationDictionary = {};\n\n    subscribersNode.on('message', manageSubscriptions);\n\n    function manageSubscriptions(subscription){\n        //console.log(\"[Proxy] - manage message\", subscription.toString());\n\n        let message = subscription.toString();\n        let type = subscription[0];\n        message = message.substr(1);\n\n        //console.log(`[Proxy] - Trying to send ${type==1?\"subscribe\":\"unsubscribe\"} type of message`);\n\n        if(typeof signatureChecker === \"undefined\"){\n            //console.log(\"[Proxy] - No signature checker defined then transparent proxy...\", subscription);\n            publishersNode.send(subscription);\n            return;\n        }\n\n        try{\n            //console.log(\"[Proxy] - let's deserialize and start analize\");\n            let deserializedData = JSON.parse(message);\n            //TODO: check deserializedData.signature\n            //console.log(\"[Proxy] - Start checking message signature\");\n            signatureChecker(deserializedData.channelName, deserializedData.signature, (err, res)=>{\n                if(err){\n                    //...\n                    //console.log(\"Err\", err);\n                }else{\n                    let newSub = Buffer.alloc(deserializedData.channelName.length+1);\n                    let ch = Buffer.from(deserializedData.channelName);\n                    if(type===1){\n                        newSub.write(\"01\", 0, 1, \"hex\");\n                    }else{\n                        newSub.write(\"00\", 0, 1, \"hex\");\n                    }\n\n                    ch.copy(newSub, 1);\n                    //console.log(\"[Proxy] - sending subscription\", /*\"\\n\\t\\t\", subscription.toString('hex'), \"\\n\\t\\t\", newSub.toString('hex'),*/ newSub);\n                    channelTranslationDictionary[deserializedData.channelName] = message;\n                    publishersNode.send(newSub);\n                    return;\n                }\n            });\n        }catch(err){\n            if(message.toString()!==\"\"){\n                //console.log(\"Something went wrong. Subscription will not be made.\", err);\n            }\n        }\n    }\n\n    try{\n        publishersNode.bindSync(pubAddress);\n        subscribersNode.bindSync(subAddress);\n        console.log(`\\nStarting ZeroMQ proxy on [subs:${subAddress}] [pubs:${pubAddress}]\\n`);\n    }catch(err){\n        console.log(\"Caught error on binding\", err);\n        throw new Error(\"No zeromq!!!\");\n    }\n\n    registerKiller([publishersNode, subscribersNode]);\n}\n\nfunction ZeromqConsumer(bindAddress, monitorFunction){\n\n    let socket = zmq.socket(\"sub\");\n\n    if(typeof monitorFunction === \"function\"){\n        let events = [\"connect\", \"connect_delay\", \"connect_retry\", \"listen\", \"bind_error\", \"accept\", \"accept_error\", \"close\", \"close_error\", \"disconnect\"];\n        socket.monitor();\n        events.forEach((eventType)=>{\n            socket.on(eventType, (...args)=>{\n                monitorFunction(eventType, ...args);\n            });\n        });\n    }\n\n    function connect(callback){\n        socket.connect(bindAddress);\n        socket.on(\"connect\", callback);\n    }\n\n    let subscriptions = {};\n    let connected = false;\n\n    this.subscribe = function(channelName, signature, callback){\n        let subscription = JSON.stringify({channelName, signature:signature});\n        if(!subscriptions[subscription]){\n            subscriptions[subscription] = [];\n        }\n\n        subscriptions[subscription].push(callback);\n\n        if(!connected){\n            connect(()=>{\n                connected = true;\n                for(var subscription in subscriptions){\n                    socket.subscribe(subscription);\n                }\n            });\n        }else{\n            socket.subscribe(subscription);\n        }\n    };\n\n    this.close = function(){\n        socket.close();\n    };\n\n    socket.on(\"message\", (channel, receivedMessage)=>{\n       let callbacks = subscriptions[channel];\n       if(!callbacks || callbacks.length === 0){\n           return console.log(`No subscriptions found for channel ${channel}. Message dropped!`);\n       }\n       for(let i = 0; i<callbacks.length; i++){\n           let cb = callbacks[i];\n           cb(channel, receivedMessage);\n       }\n    });\n}\n\nlet instance;\nmodule.exports.getForwarderInstance = function(address){\n    if(!instance){\n        address = address || defaultForwardAddress;\n        instance = new ZeromqForwarder(address);\n    }\n    return instance;\n};\n\nmodule.exports.createZeromqProxyNode = function(subAddress, pubAddress, signatureChecker){\n    subAddress = subAddress || defaultSubAddress;\n    pubAddress = pubAddress || defaultPubAddress;\n    return new ZeromqProxyNode(subAddress, pubAddress, signatureChecker);\n};\n\nmodule.exports.createZeromqConsumer = function(bindAddress, monitorFunction){\n    return new ZeromqConsumer(bindAddress, monitorFunction);\n};\n\nmodule.exports.registerKiller = registerKiller;"]}